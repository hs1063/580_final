{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sc\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0000C359D63E       3.0     3.0         3.0          3.0      3.0   \n",
       "1  000BAD50D026       3.0     3.0         3.0          3.0      3.0   \n",
       "2  00367BB2546B       3.0     3.0         3.0          3.0      3.0   \n",
       "\n",
       "   conventions  \n",
       "0          3.0  \n",
       "1          3.0  \n",
       "2          3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.read_csv(\"sample_submission.csv\")\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: Getting to know our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new column to reflect the length of article\n",
    "length = []\n",
    "for i in train['full_text']:\n",
    "    leng = len(i.split())\n",
    "    length.append(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_text'] = train[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex=True)\n",
    "test['full_text'] = test[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal  If u change the school policy...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>I believe using cellphones in class for educat...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working alone, students do not have to argue w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>\"A problem is a chance for you to do your best...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>Do you think that failure is the main thing fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "0     0016926B079C  I think that students would benefit from learn...   \n",
       "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2     00299B378633  Dear, Principal  If u change the school policy...   \n",
       "3     003885A45F42  The best time in life is when you become yours...   \n",
       "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "...            ...                                                ...   \n",
       "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
       "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
       "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
       "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
       "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0          3.5     3.5         3.0          3.0      4.0          3.0   \n",
       "1          2.5     2.5         3.0          2.0      2.0          2.5   \n",
       "2          3.0     3.5         3.0          3.0      3.0          2.5   \n",
       "3          4.5     4.5         4.5          4.5      4.0          5.0   \n",
       "4          2.5     3.0         3.0          3.0      2.5          2.5   \n",
       "...        ...     ...         ...          ...      ...          ...   \n",
       "3906       2.5     3.0         3.0          3.5      2.5          2.5   \n",
       "3907       4.0     4.0         4.0          4.0      3.5          3.0   \n",
       "3908       2.5     3.0         3.0          3.0      3.5          3.0   \n",
       "3909       4.0     4.5         4.5          4.0      4.5          4.5   \n",
       "3910       3.5     2.5         3.5          3.0      3.0          3.5   \n",
       "\n",
       "      text_length  \n",
       "0             261  \n",
       "1             533  \n",
       "2             320  \n",
       "3             728  \n",
       "4             234  \n",
       "...           ...  \n",
       "3906          179  \n",
       "3907          465  \n",
       "3908          257  \n",
       "3909          510  \n",
       "3910          638  \n",
       "\n",
       "[3911 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_length']=length\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id  cohesion  syntax  vocabulary  vocabulary  grammar  \\\n",
       "0     0016926B079C       3.5     3.5         3.0         3.0      4.0   \n",
       "1     0022683E9EA5       2.5     2.5         3.0         3.0      2.0   \n",
       "2     00299B378633       3.0     3.5         3.0         3.0      3.0   \n",
       "3     003885A45F42       4.5     4.5         4.5         4.5      4.0   \n",
       "4     0049B1DF5CCC       2.5     3.0         3.0         3.0      2.5   \n",
       "...            ...       ...     ...         ...         ...      ...   \n",
       "3906  FFD29828A873       2.5     3.0         3.0         3.0      2.5   \n",
       "3907  FFD9A83B0849       4.0     4.0         4.0         4.0      3.5   \n",
       "3908  FFDC4011AC9C       2.5     3.0         3.0         3.0      3.5   \n",
       "3909  FFE16D704B16       4.0     4.5         4.5         4.5      4.5   \n",
       "3910  FFED00D6E0BD       3.5     2.5         3.5         3.5      3.0   \n",
       "\n",
       "      conventions  \n",
       "0             3.0  \n",
       "1             2.5  \n",
       "2             2.5  \n",
       "3             5.0  \n",
       "4             2.5  \n",
       "...           ...  \n",
       "3906          2.5  \n",
       "3907          3.0  \n",
       "3908          3.0  \n",
       "3909          4.5  \n",
       "3910          3.5  \n",
       "\n",
       "[3911 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_df = train[['text_id','cohesion','syntax','vocabulary','vocabulary','grammar','conventions']]\n",
    "des_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Description for Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_11d82_row0_col1, #T_11d82_row0_col4, #T_11d82_row0_col5, #T_11d82_row0_col6, #T_11d82_row0_col7, #T_11d82_row0_col8, #T_11d82_row1_col1, #T_11d82_row1_col2, #T_11d82_row1_col4, #T_11d82_row1_col5, #T_11d82_row1_col6, #T_11d82_row1_col7, #T_11d82_row1_col8, #T_11d82_row2_col1, #T_11d82_row2_col3, #T_11d82_row2_col4, #T_11d82_row2_col6, #T_11d82_row2_col7, #T_11d82_row2_col8, #T_11d82_row3_col1, #T_11d82_row3_col3, #T_11d82_row3_col4, #T_11d82_row3_col6, #T_11d82_row3_col7, #T_11d82_row3_col8, #T_11d82_row4_col1, #T_11d82_row4_col4, #T_11d82_row4_col5, #T_11d82_row4_col6, #T_11d82_row4_col7, #T_11d82_row4_col8, #T_11d82_row5_col1, #T_11d82_row5_col4, #T_11d82_row5_col5, #T_11d82_row5_col6, #T_11d82_row5_col7, #T_11d82_row5_col8 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_11d82_row0_col2 {\n",
       "  background-color: #7dc87e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_11d82_row0_col3 {\n",
       "  background-color: #339c52;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_11d82_row1_col3 {\n",
       "  background-color: #6abf71;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_11d82_row2_col2, #T_11d82_row2_col5, #T_11d82_row3_col2, #T_11d82_row3_col5, #T_11d82_row4_col3 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_11d82_row4_col2 {\n",
       "  background-color: #f4fbf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_11d82_row5_col2 {\n",
       "  background-color: #c6e8bf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_11d82_row5_col3 {\n",
       "  background-color: #218944;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_11d82\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_11d82_level0_col0\" class=\"col_heading level0 col0\" >index</th>\n",
       "      <th id=\"T_11d82_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "      <th id=\"T_11d82_level0_col2\" class=\"col_heading level0 col2\" >mean</th>\n",
       "      <th id=\"T_11d82_level0_col3\" class=\"col_heading level0 col3\" >std</th>\n",
       "      <th id=\"T_11d82_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
       "      <th id=\"T_11d82_level0_col5\" class=\"col_heading level0 col5\" >25%</th>\n",
       "      <th id=\"T_11d82_level0_col6\" class=\"col_heading level0 col6\" >50%</th>\n",
       "      <th id=\"T_11d82_level0_col7\" class=\"col_heading level0 col7\" >75%</th>\n",
       "      <th id=\"T_11d82_level0_col8\" class=\"col_heading level0 col8\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_11d82_row0_col0\" class=\"data row0 col0\" >cohesion</td>\n",
       "      <td id=\"T_11d82_row0_col1\" class=\"data row0 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row0_col2\" class=\"data row0 col2\" >3.127077</td>\n",
       "      <td id=\"T_11d82_row0_col3\" class=\"data row0 col3\" >0.662542</td>\n",
       "      <td id=\"T_11d82_row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row0_col5\" class=\"data row0 col5\" >2.500000</td>\n",
       "      <td id=\"T_11d82_row0_col6\" class=\"data row0 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row0_col7\" class=\"data row0 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row0_col8\" class=\"data row0 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_11d82_row1_col0\" class=\"data row1 col0\" >syntax</td>\n",
       "      <td id=\"T_11d82_row1_col1\" class=\"data row1 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row1_col2\" class=\"data row1 col2\" >3.028254</td>\n",
       "      <td id=\"T_11d82_row1_col3\" class=\"data row1 col3\" >0.644399</td>\n",
       "      <td id=\"T_11d82_row1_col4\" class=\"data row1 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row1_col5\" class=\"data row1 col5\" >2.500000</td>\n",
       "      <td id=\"T_11d82_row1_col6\" class=\"data row1 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row1_col7\" class=\"data row1 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row1_col8\" class=\"data row1 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_11d82_row2_col0\" class=\"data row2 col0\" >vocabulary</td>\n",
       "      <td id=\"T_11d82_row2_col1\" class=\"data row2 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row2_col2\" class=\"data row2 col2\" >3.235745</td>\n",
       "      <td id=\"T_11d82_row2_col3\" class=\"data row2 col3\" >0.583148</td>\n",
       "      <td id=\"T_11d82_row2_col4\" class=\"data row2 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row2_col5\" class=\"data row2 col5\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row2_col6\" class=\"data row2 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row2_col7\" class=\"data row2 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row2_col8\" class=\"data row2 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_11d82_row3_col0\" class=\"data row3 col0\" >vocabulary</td>\n",
       "      <td id=\"T_11d82_row3_col1\" class=\"data row3 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row3_col2\" class=\"data row3 col2\" >3.235745</td>\n",
       "      <td id=\"T_11d82_row3_col3\" class=\"data row3 col3\" >0.583148</td>\n",
       "      <td id=\"T_11d82_row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row3_col5\" class=\"data row3 col5\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row3_col6\" class=\"data row3 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row3_col7\" class=\"data row3 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row3_col8\" class=\"data row3 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_11d82_row4_col0\" class=\"data row4 col0\" >grammar</td>\n",
       "      <td id=\"T_11d82_row4_col1\" class=\"data row4 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row4_col2\" class=\"data row4 col2\" >3.032856</td>\n",
       "      <td id=\"T_11d82_row4_col3\" class=\"data row4 col3\" >0.699841</td>\n",
       "      <td id=\"T_11d82_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row4_col5\" class=\"data row4 col5\" >2.500000</td>\n",
       "      <td id=\"T_11d82_row4_col6\" class=\"data row4 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row4_col7\" class=\"data row4 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row4_col8\" class=\"data row4 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11d82_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_11d82_row5_col0\" class=\"data row5 col0\" >conventions</td>\n",
       "      <td id=\"T_11d82_row5_col1\" class=\"data row5 col1\" >3911.000000</td>\n",
       "      <td id=\"T_11d82_row5_col2\" class=\"data row5 col2\" >3.081053</td>\n",
       "      <td id=\"T_11d82_row5_col3\" class=\"data row5 col3\" >0.671450</td>\n",
       "      <td id=\"T_11d82_row5_col4\" class=\"data row5 col4\" >1.000000</td>\n",
       "      <td id=\"T_11d82_row5_col5\" class=\"data row5 col5\" >2.500000</td>\n",
       "      <td id=\"T_11d82_row5_col6\" class=\"data row5 col6\" >3.000000</td>\n",
       "      <td id=\"T_11d82_row5_col7\" class=\"data row5 col7\" >3.500000</td>\n",
       "      <td id=\"T_11d82_row5_col8\" class=\"data row5 col8\" >5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff068723f70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_train = des_df.select_dtypes(['int','float']).describe().T\n",
    "#des_train = des_train.set_index('index')\n",
    "reset_train = des_df.select_dtypes(['int','float']).describe().T.reset_index(drop=False) \n",
    "reset_train.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows=3\n",
    "plot_cols=2\n",
    "fig = make_subplots(rows=plot_rows, cols=plot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yudichen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_train = train['full_text'][:50]\n",
    "\n",
    "text_tag = []\n",
    "for i in train['full_text']:\n",
    "    i = word_tokenize(i)\n",
    "    pos_tagger = nltk.pos_tag(i)\n",
    "    word_tag = []\n",
    "    for j in pos_tagger:\n",
    "        (word,tag) = j\n",
    "        word_tag.append(tag)\n",
    "    text_tag.append(word_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/yudichen/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.data import load\n",
    "nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "tagdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LS',\n",
       " 'TO',\n",
       " 'VBN',\n",
       " \"''\",\n",
       " 'WP',\n",
       " 'UH',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'VBZ',\n",
       " '--',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'DT',\n",
       " 'PRP',\n",
       " ':',\n",
       " 'WP$',\n",
       " 'NNPS',\n",
       " 'PRP$',\n",
       " 'WDT',\n",
       " '(',\n",
       " ')',\n",
       " '.',\n",
       " ',',\n",
       " '``',\n",
       " '$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'FW',\n",
       " 'RP',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'PDT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'NNP',\n",
       " 'EX',\n",
       " 'NNS',\n",
       " 'SYM',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'POS',\n",
       " '#']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(tagdict.keys())\n",
    "tags.append(\"#\")\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(tagdict.keys())\n",
    "freq = pd.DataFrame(index=range(0,len(train)),columns=tags)\n",
    "freq.iloc[:] = 0\n",
    "freq = freq.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "d = []\n",
    "for i in text_tag:\n",
    "    d.append(Counter(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    for key, value in d[i].items():\n",
    "        freq[key][i] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = [\"VB\",\"VBG\",\"VBD\",\"VBN\",\"VBP\",\"VBZ\"]\n",
    "wh = [\"WDT\",\"WP\",\"WRB\",\"PDT\",\"DT\",\"WP$\"] #determiner\n",
    "connection = [\"UH\",\"RP\",\"TO\",\"IN\",\"CC\",\"MD\",\"EX\"]\n",
    "adb = [\"RB\",\"RBR\",\"RBS\"]\n",
    "pronoun = [\"POS\",\"PRP\",\"PRP$\"]\n",
    "noun = [\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"LS\"]\n",
    "adj = [\"JJ\",\"JJR\",\"JJS\"]\n",
    "fw = [\"FW\"] #foreign word\n",
    "number = ['CD'] #number\n",
    "punc = [\"''\",\"--\",\"(\",\")\",\".\",\",\",\"``\",\"$\",\"#\",\"SYM\"]\n",
    "\n",
    "word_type = [verb,wh,connection,adb,pronoun, noun,adj,fw,number,punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Fruit Total']= df.iloc[:, -4:-1].sum(axis=1)\n",
    "train['verb'] = freq[verb].sum(axis=1)\n",
    "train['wh'] = freq[wh].sum(axis=1)\n",
    "train['connection'] = freq[connection].sum(axis=1)\n",
    "train['adb'] = freq[adb].sum(axis=1)\n",
    "train['pronoun'] = freq[pronoun].sum(axis=1)\n",
    "train['noun'] = freq[noun].sum(axis=1)\n",
    "train['adj'] = freq[adj].sum(axis=1)\n",
    "train['fw'] = freq[fw].sum(axis=1)\n",
    "train['number'] = freq[number].sum(axis=1)\n",
    "train['punc'] = freq[punc].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>text_length</th>\n",
       "      <th>verb</th>\n",
       "      <th>wh</th>\n",
       "      <th>connection</th>\n",
       "      <th>adb</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>noun</th>\n",
       "      <th>adj</th>\n",
       "      <th>fw</th>\n",
       "      <th>number</th>\n",
       "      <th>punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>261</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>533</td>\n",
       "      <td>131</td>\n",
       "      <td>53</td>\n",
       "      <td>137</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal  If u change the school policy...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>320</td>\n",
       "      <td>71</td>\n",
       "      <td>32</td>\n",
       "      <td>91</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>728</td>\n",
       "      <td>204</td>\n",
       "      <td>68</td>\n",
       "      <td>162</td>\n",
       "      <td>46</td>\n",
       "      <td>125</td>\n",
       "      <td>94</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>234</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>I believe using cellphones in class for educat...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>179</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working alone, students do not have to argue w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>465</td>\n",
       "      <td>93</td>\n",
       "      <td>49</td>\n",
       "      <td>132</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>\"A problem is a chance for you to do your best...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>257</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>510</td>\n",
       "      <td>102</td>\n",
       "      <td>42</td>\n",
       "      <td>121</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>Do you think that failure is the main thing fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>638</td>\n",
       "      <td>174</td>\n",
       "      <td>53</td>\n",
       "      <td>167</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "0     0016926B079C  I think that students would benefit from learn...   \n",
       "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2     00299B378633  Dear, Principal  If u change the school policy...   \n",
       "3     003885A45F42  The best time in life is when you become yours...   \n",
       "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "...            ...                                                ...   \n",
       "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
       "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
       "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
       "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
       "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0          3.5     3.5         3.0          3.0      4.0          3.0   \n",
       "1          2.5     2.5         3.0          2.0      2.0          2.5   \n",
       "2          3.0     3.5         3.0          3.0      3.0          2.5   \n",
       "3          4.5     4.5         4.5          4.5      4.0          5.0   \n",
       "4          2.5     3.0         3.0          3.0      2.5          2.5   \n",
       "...        ...     ...         ...          ...      ...          ...   \n",
       "3906       2.5     3.0         3.0          3.5      2.5          2.5   \n",
       "3907       4.0     4.0         4.0          4.0      3.5          3.0   \n",
       "3908       2.5     3.0         3.0          3.0      3.5          3.0   \n",
       "3909       4.0     4.5         4.5          4.0      4.5          4.5   \n",
       "3910       3.5     2.5         3.5          3.0      3.0          3.5   \n",
       "\n",
       "      text_length  verb  wh  connection  adb  pronoun  noun  adj  fw  number  \\\n",
       "0             261    63  21          69   13       32    47   19   0       0   \n",
       "1             533   131  53         137   25       57    89   42   0       2   \n",
       "2             320    71  32          91   15       32    68   21   0       0   \n",
       "3             728   204  68         162   46      125    94   56   0       2   \n",
       "4             234    51  34          42    5       30    59   12   0       1   \n",
       "...           ...   ...  ..         ...  ...      ...   ...  ...  ..     ...   \n",
       "3906          179    36  14          40    9       21    49    9   0       0   \n",
       "3907          465    93  49         132   27       17   103   41   0       5   \n",
       "3908          257    52  26          66   21       35    39   17   0       2   \n",
       "3909          510   102  42         121   30       68   108   46   0       2   \n",
       "3910          638   174  53         167   28       77   117   35   0       0   \n",
       "\n",
       "      punc  \n",
       "0       19  \n",
       "1       18  \n",
       "2       26  \n",
       "3       79  \n",
       "4        3  \n",
       "...    ...  \n",
       "3906    11  \n",
       "3907    32  \n",
       "3908    17  \n",
       "3909    39  \n",
       "3910    33  \n",
       "\n",
       "[3911 rows x 19 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in train.full_text:\n",
    "    j = word_tokenize(i)\n",
    "    text.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3911"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(text, vector_size=1000, window=10,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 0,\n",
       " '.': 1,\n",
       " ',': 2,\n",
       " 'the': 3,\n",
       " 'and': 4,\n",
       " 'you': 5,\n",
       " 'a': 6,\n",
       " 'that': 7,\n",
       " 'is': 8,\n",
       " 'in': 9,\n",
       " 'they': 10,\n",
       " 'of': 11,\n",
       " 'have': 12,\n",
       " 'be': 13,\n",
       " 'I': 14,\n",
       " 'can': 15,\n",
       " 'it': 16,\n",
       " 'do': 17,\n",
       " 'for': 18,\n",
       " 'because': 19,\n",
       " 'are': 20,\n",
       " 'not': 21,\n",
       " 'people': 22,\n",
       " 'school': 23,\n",
       " 'or': 24,\n",
       " 'students': 25,\n",
       " 'with': 26,\n",
       " 'will': 27,\n",
       " 'your': 28,\n",
       " 'we': 29,\n",
       " 'their': 30,\n",
       " \"n't\": 31,\n",
       " 'more': 32,\n",
       " 'if': 33,\n",
       " 'what': 34,\n",
       " 'time': 35,\n",
       " 'good': 36,\n",
       " 'get': 37,\n",
       " 'my': 38,\n",
       " 'on': 39,\n",
       " 'work': 40,\n",
       " 'but': 41,\n",
       " 'like': 42,\n",
       " 'want': 43,\n",
       " 'them': 44,\n",
       " 'life': 45,\n",
       " 'would': 46,\n",
       " 'help': 47,\n",
       " 'make': 48,\n",
       " 'i': 49,\n",
       " 'at': 50,\n",
       " 'when': 51,\n",
       " 'about': 52,\n",
       " 'this': 53,\n",
       " 'think': 54,\n",
       " \"'s\": 55,\n",
       " 'some': 56,\n",
       " 'so': 57,\n",
       " 'all': 58,\n",
       " 'from': 59,\n",
       " 'was': 60,\n",
       " 'how': 61,\n",
       " 'one': 62,\n",
       " 'other': 63,\n",
       " 'something': 64,\n",
       " 'there': 65,\n",
       " 'know': 66,\n",
       " 'need': 67,\n",
       " 'should': 68,\n",
       " 'things': 69,\n",
       " 'me': 70,\n",
       " 'he': 71,\n",
       " 'going': 72,\n",
       " 'person': 73,\n",
       " 'better': 74,\n",
       " 'go': 75,\n",
       " 'just': 76,\n",
       " 'by': 77,\n",
       " 'example': 78,\n",
       " 'take': 79,\n",
       " 'also': 80,\n",
       " 'as': 81,\n",
       " 'student': 82,\n",
       " 'always': 83,\n",
       " 'our': 84,\n",
       " 'doing': 85,\n",
       " 'learn': 86,\n",
       " 'way': 87,\n",
       " 'up': 88,\n",
       " 'who': 89,\n",
       " 'The': 90,\n",
       " 'day': 91,\n",
       " 'classes': 92,\n",
       " 'In': 93,\n",
       " 'out': 94,\n",
       " 'many': 95,\n",
       " 'could': 96,\n",
       " 'lot': 97,\n",
       " 'class': 98,\n",
       " 'home': 99,\n",
       " 'thing': 100,\n",
       " 'why': 101,\n",
       " 'an': 102,\n",
       " 'bad': 103,\n",
       " 'then': 104,\n",
       " 'really': 105,\n",
       " 'change': 106,\n",
       " 'hard': 107,\n",
       " 'If': 108,\n",
       " 'new': 109,\n",
       " 'For': 110,\n",
       " 'others': 111,\n",
       " 'she': 112,\n",
       " 'has': 113,\n",
       " 'give': 114,\n",
       " 'It': 115,\n",
       " 'try': 116,\n",
       " 'see': 117,\n",
       " 'job': 118,\n",
       " 'being': 119,\n",
       " 'important': 120,\n",
       " 'attitude': 121,\n",
       " 'own': 122,\n",
       " 'positive': 123,\n",
       " 'never': 124,\n",
       " 'best': 125,\n",
       " 'us': 126,\n",
       " 'reason': 127,\n",
       " 'career': 128,\n",
       " 'high': 129,\n",
       " 'someone': 130,\n",
       " 'say': 131,\n",
       " 'first': 132,\n",
       " 'did': 133,\n",
       " 'friends': 134,\n",
       " 'use': 135,\n",
       " 'working': 136,\n",
       " 'world': 137,\n",
       " 'even': 138,\n",
       " 'future': 139,\n",
       " 'feel': 140,\n",
       " 'than': 141,\n",
       " 'no': 142,\n",
       " 'different': 143,\n",
       " 'family': 144,\n",
       " 'had': 145,\n",
       " 'having': 146,\n",
       " 'most': 147,\n",
       " 'after': 148,\n",
       " 'very': 149,\n",
       " 'might': 150,\n",
       " 'much': 151,\n",
       " 'his': 152,\n",
       " 'online': 153,\n",
       " 'technology': 154,\n",
       " 'idea': 155,\n",
       " 'success': 156,\n",
       " 'any': 157,\n",
       " 'only': 158,\n",
       " 'yourself': 159,\n",
       " '?': 160,\n",
       " 'Some': 161,\n",
       " 'same': 162,\n",
       " 'teacher': 163,\n",
       " 'her': 164,\n",
       " 'They': 165,\n",
       " \"''\": 166,\n",
       " 'able': 167,\n",
       " '``': 168,\n",
       " 'every': 169,\n",
       " 'may': 170,\n",
       " 'agree': 171,\n",
       " 'does': 172,\n",
       " 'You': 173,\n",
       " 'start': 174,\n",
       " 'said': 175,\n",
       " 'believe': 176,\n",
       " 'dont': 177,\n",
       " 'homework': 178,\n",
       " 'When': 179,\n",
       " 'play': 180,\n",
       " 'group': 181,\n",
       " 'parents': 182,\n",
       " 'keep': 183,\n",
       " 'years': 184,\n",
       " 'its': 185,\n",
       " 'right': 186,\n",
       " 'learning': 187,\n",
       " 'failure': 188,\n",
       " 'great': 189,\n",
       " 'year': 190,\n",
       " ';': 191,\n",
       " 'Generic_Name': 192,\n",
       " 'were': 193,\n",
       " 'money': 194,\n",
       " 'This': 195,\n",
       " 'too': 196,\n",
       " 'now': 197,\n",
       " 'kids': 198,\n",
       " 'Students': 199,\n",
       " 'study': 200,\n",
       " 'fun': 201,\n",
       " 'everything': 202,\n",
       " 'Also': 203,\n",
       " 'everyone': 204,\n",
       " 'choose': 205,\n",
       " 'done': 206,\n",
       " 'trying': 207,\n",
       " 'hours': 208,\n",
       " 'talk': 209,\n",
       " 'those': 210,\n",
       " 'teachers': 211,\n",
       " 'come': 212,\n",
       " 'find': 213,\n",
       " 'schools': 214,\n",
       " 'which': 215,\n",
       " 'him': 216,\n",
       " 'where': 217,\n",
       " 'ask': 218,\n",
       " 'self': 219,\n",
       " 'anything': 220,\n",
       " 'accomplish': 221,\n",
       " 'each': 222,\n",
       " 'conclusion': 223,\n",
       " 'college': 224,\n",
       " 'ca': 225,\n",
       " 'stay': 226,\n",
       " 'But': 227,\n",
       " 'sometimes': 228,\n",
       " 'without': 229,\n",
       " 'got': 230,\n",
       " 'People': 231,\n",
       " 'am': 232,\n",
       " 'We': 233,\n",
       " 'young': 234,\n",
       " 'around': 235,\n",
       " 'problem': 236,\n",
       " 'getting': 237,\n",
       " 'food': 238,\n",
       " 'So': 239,\n",
       " 'become': 240,\n",
       " 'finish': 241,\n",
       " 'big': 242,\n",
       " 'experience': 243,\n",
       " 'And': 244,\n",
       " 'tell': 245,\n",
       " 'activities': 246,\n",
       " 'summer': 247,\n",
       " 'makes': 248,\n",
       " 'understand': 249,\n",
       " \"'re\": 250,\n",
       " 'My': 251,\n",
       " 'easy': 252,\n",
       " 'happy': 253,\n",
       " 'another': 254,\n",
       " 'grow': 255,\n",
       " 'successful': 256,\n",
       " 'well': 257,\n",
       " 'been': 258,\n",
       " 'friend': 259,\n",
       " 'show': 260,\n",
       " 'before': 261,\n",
       " 'graduate': 262,\n",
       " 'opinion': 263,\n",
       " 'making': 264,\n",
       " 'let': 265,\n",
       " 'problems': 266,\n",
       " 'goals': 267,\n",
       " 'helps': 268,\n",
       " 'live': 269,\n",
       " 'taking': 270,\n",
       " 'two': 271,\n",
       " 'ideas': 272,\n",
       " 'during': 273,\n",
       " 'early': 274,\n",
       " 'place': 275,\n",
       " 'character': 276,\n",
       " 'back': 277,\n",
       " 'A': 278,\n",
       " 'decision': 279,\n",
       " 'There': 280,\n",
       " 'alone': 281,\n",
       " 'impression': 282,\n",
       " 'put': 283,\n",
       " 'na': 284,\n",
       " 'mind': 285,\n",
       " 'love': 286,\n",
       " 'wrong': 287,\n",
       " 'still': 288,\n",
       " 'benefit': 289,\n",
       " ':': 290,\n",
       " 'attend': 291,\n",
       " 'age': 292,\n",
       " 'over': 293,\n",
       " 'already': 294,\n",
       " 'reasons': 295,\n",
       " 'else': 296,\n",
       " \"'m\": 297,\n",
       " 'three': 298,\n",
       " 'long': 299,\n",
       " 'fail': 300,\n",
       " 'That': 301,\n",
       " 'days': 302,\n",
       " 'look': 303,\n",
       " 'these': 304,\n",
       " 'phones': 305,\n",
       " 'care': 306,\n",
       " 'made': 307,\n",
       " 'break': 308,\n",
       " 'advice': 309,\n",
       " 'decisions': 310,\n",
       " 'grades': 311,\n",
       " 'knowledge': 312,\n",
       " 'goal': 313,\n",
       " 'stuff': 314,\n",
       " 'end': 315,\n",
       " 'into': 316,\n",
       " 'negative': 317,\n",
       " 'matter': 318,\n",
       " 'First': 319,\n",
       " 'through': 320,\n",
       " 'told': 321,\n",
       " 'pay': 322,\n",
       " 'test': 323,\n",
       " 'phone': 324,\n",
       " 'less': 325,\n",
       " 'ways': 326,\n",
       " 'wo': 327,\n",
       " 'times': 328,\n",
       " 'little': 329,\n",
       " 'Because': 330,\n",
       " 'maybe': 331,\n",
       " 'week': 332,\n",
       " 'nothing': 333,\n",
       " 'older': 334,\n",
       " 'enjoy': 335,\n",
       " 'opportunity': 336,\n",
       " 'lives': 337,\n",
       " 'grade': 338,\n",
       " 'However': 339,\n",
       " 'One': 340,\n",
       " 'To': 341,\n",
       " 'while': 342,\n",
       " 'enough': 343,\n",
       " 'wanted': 344,\n",
       " 'spend': 345,\n",
       " 'teach': 346,\n",
       " 'used': 347,\n",
       " 'next': 348,\n",
       " 'achieve': 349,\n",
       " 'cause': 350,\n",
       " 'pass': 351,\n",
       " 'Another': 352,\n",
       " 'video': 353,\n",
       " 'sports': 354,\n",
       " 'soccer': 355,\n",
       " 'ever': 356,\n",
       " 'energy': 357,\n",
       " 'impressions': 358,\n",
       " 'team': 359,\n",
       " 'again': 360,\n",
       " 'playing': 361,\n",
       " 'follow': 362,\n",
       " 'thats': 363,\n",
       " 'thinking': 364,\n",
       " 'education': 365,\n",
       " 'happen': 366,\n",
       " 'cell': 367,\n",
       " 'house': 368,\n",
       " 'wants': 369,\n",
       " 'focus': 370,\n",
       " 'part': 371,\n",
       " 'off': 372,\n",
       " 'chance': 373,\n",
       " 'stop': 374,\n",
       " 'choice': 375,\n",
       " 'instead': 376,\n",
       " 'information': 377,\n",
       " 'enthusiasm': 378,\n",
       " 'teenagers': 379,\n",
       " 'four': 380,\n",
       " 'down': 381,\n",
       " 'themselves': 382,\n",
       " 'He': 383,\n",
       " 'project': 384,\n",
       " 'kind': 385,\n",
       " 'mean': 386,\n",
       " 'influence': 387,\n",
       " 'went': 388,\n",
       " 'using': 389,\n",
       " 'outside': 390,\n",
       " 'skills': 391,\n",
       " 'everyday': 392,\n",
       " 'country': 393,\n",
       " 'nice': 394,\n",
       " 'point': 395,\n",
       " 'club': 396,\n",
       " 'statement': 397,\n",
       " \"'ll\": 398,\n",
       " 'younger': 399,\n",
       " 'jobs': 400,\n",
       " 'disagree': 401,\n",
       " 'games': 402,\n",
       " 'improve': 403,\n",
       " 'program': 404,\n",
       " 'extra': 405,\n",
       " 'eat': 406,\n",
       " 'stress': 407,\n",
       " 'mistakes': 408,\n",
       " 'key': 409,\n",
       " 'true': 410,\n",
       " 'decide': 411,\n",
       " 'mom': 412,\n",
       " 'sure': 413,\n",
       " 'community': 414,\n",
       " 'activity': 415,\n",
       " 'once': 416,\n",
       " 'trouble': 417,\n",
       " 'talking': 418,\n",
       " 'option': 419,\n",
       " 'As': 420,\n",
       " 'gon': 421,\n",
       " 'order': 422,\n",
       " 'Do': 423,\n",
       " 'difficult': 424,\n",
       " 'last': 425,\n",
       " 'support': 426,\n",
       " 'Many': 427,\n",
       " 'easier': 428,\n",
       " 'complete': 429,\n",
       " 'bring': 430,\n",
       " 'game': 431,\n",
       " 'Most': 432,\n",
       " 'together': 433,\n",
       " 'helping': 434,\n",
       " 'thought': 435,\n",
       " 'actually': 436,\n",
       " 'second': 437,\n",
       " 'tired': 438,\n",
       " 'away': 439,\n",
       " 'benefits': 440,\n",
       " 'means': 441,\n",
       " 'imagination': 442,\n",
       " 'comes': 443,\n",
       " 'started': 444,\n",
       " 'act': 445,\n",
       " 'buy': 446,\n",
       " 'old': 447,\n",
       " 'control': 448,\n",
       " 'giving': 449,\n",
       " 'type': 450,\n",
       " 'such': 451,\n",
       " 'opportunities': 452,\n",
       " 'attention': 453,\n",
       " '!': 454,\n",
       " 'saying': 455,\n",
       " 'Having': 456,\n",
       " 'myself': 457,\n",
       " 'effort': 458,\n",
       " 'whole': 459,\n",
       " 'visit': 460,\n",
       " 'human': 461,\n",
       " 'impossible': 462,\n",
       " 'lunch': 463,\n",
       " 'must': 464,\n",
       " 'helpful': 465,\n",
       " 'late': 466,\n",
       " 'free': 467,\n",
       " 'meet': 468,\n",
       " 'needs': 469,\n",
       " 'Sometimes': 470,\n",
       " 'company': 471,\n",
       " 'Second': 472,\n",
       " 'healthy': 473,\n",
       " 'Technology': 474,\n",
       " 'came': 475,\n",
       " 'ready': 476,\n",
       " 'later': 477,\n",
       " 'situation': 478,\n",
       " 'night': 479,\n",
       " 'body': 480,\n",
       " 'Although': 481,\n",
       " 'art': 482,\n",
       " 'loss': 483,\n",
       " 'practice': 484,\n",
       " 'sport': 485,\n",
       " 'dream': 486,\n",
       " 'sleep': 487,\n",
       " 'lose': 488,\n",
       " 'gives': 489,\n",
       " 'wan': 490,\n",
       " 'real': 491,\n",
       " 'hour': 492,\n",
       " 'since': 493,\n",
       " 'looking': 494,\n",
       " 'though': 495,\n",
       " 'music': 496,\n",
       " 'probably': 497,\n",
       " 'rest': 498,\n",
       " 'shows': 499,\n",
       " 'leave': 500,\n",
       " 'worry': 501,\n",
       " 'allow': 502,\n",
       " 'children': 503,\n",
       " 'groups': 504,\n",
       " 'anyone': 505,\n",
       " 'until': 506,\n",
       " 'effect': 507,\n",
       " 'social': 508,\n",
       " 'dreams': 509,\n",
       " 'save': 510,\n",
       " \"'ve\": 511,\n",
       " 'both': 512,\n",
       " 'experiences': 513,\n",
       " 'projects': 514,\n",
       " 'traits': 515,\n",
       " 'math': 516,\n",
       " 'remember': 517,\n",
       " 'least': 518,\n",
       " 'feeling': 519,\n",
       " 'beyond': 520,\n",
       " 'learned': 521,\n",
       " 'face': 522,\n",
       " 'ones': 523,\n",
       " 'read': 524,\n",
       " 'trust': 525,\n",
       " 'mastered': 526,\n",
       " 'almost': 527,\n",
       " 'car': 528,\n",
       " 'examples': 529,\n",
       " 'affect': 530,\n",
       " 'beneficial': 531,\n",
       " 'Finally': 532,\n",
       " 'park': 533,\n",
       " 'wont': 534,\n",
       " 'pick': 535,\n",
       " 'English': 536,\n",
       " 'courses': 537,\n",
       " 'peoples': 538,\n",
       " 'society': 539,\n",
       " 'What': 540,\n",
       " 'distance': 541,\n",
       " 'share': 542,\n",
       " 'reach': 543,\n",
       " 'Emerson': 544,\n",
       " 'faster': 545,\n",
       " 'After': 546,\n",
       " 'mistake': 547,\n",
       " 'knowing': 548,\n",
       " 'lead': 549,\n",
       " 'respect': 550,\n",
       " 'easily': 551,\n",
       " 'kid': 552,\n",
       " 'forget': 553,\n",
       " 'idle': 554,\n",
       " 'offer': 555,\n",
       " 'School': 556,\n",
       " 'honest': 557,\n",
       " 'Even': 558,\n",
       " 'succeed': 559,\n",
       " 'Being': 560,\n",
       " 'here': 561,\n",
       " 'gave': 562,\n",
       " 'harder': 563,\n",
       " 'All': 564,\n",
       " 'works': 565,\n",
       " 'active': 566,\n",
       " 'purpose': 567,\n",
       " 'opinions': 568,\n",
       " 'commit': 569,\n",
       " 'cant': 570,\n",
       " 'proud': 571,\n",
       " 'however': 572,\n",
       " 'Then': 573,\n",
       " 'took': 574,\n",
       " 'past': 575,\n",
       " 'curfew': 576,\n",
       " 'accomplishment': 577,\n",
       " 'places': 578,\n",
       " 'due': 579,\n",
       " 'classroom': 580,\n",
       " 'contact': 581,\n",
       " 'half': 582,\n",
       " 'whatever': 583,\n",
       " 'responsible': 584,\n",
       " 'science': 585,\n",
       " 'longer': 586,\n",
       " 'speak': 587,\n",
       " 'plan': 588,\n",
       " 'possible': 589,\n",
       " 'strong': 590,\n",
       " 'perfect': 591,\n",
       " 'computer': 592,\n",
       " 'Is': 593,\n",
       " 'kindness': 594,\n",
       " 'hand': 595,\n",
       " 'call': 596,\n",
       " 'set': 597,\n",
       " 'specific': 598,\n",
       " 'alot': 599,\n",
       " 'She': 600,\n",
       " 'guidance': 601,\n",
       " 'gets': 602,\n",
       " 'business': 603,\n",
       " 'families': 604,\n",
       " 'etc': 605,\n",
       " 'question': 606,\n",
       " 'create': 607,\n",
       " 'sad': 608,\n",
       " 'health': 609,\n",
       " 'lazy': 610,\n",
       " 'fast': 611,\n",
       " 'impact': 612,\n",
       " 'book': 613,\n",
       " 'Now': 614,\n",
       " 'Therefore': 615,\n",
       " 'asking': 616,\n",
       " 'hurt': 617,\n",
       " 'needed': 618,\n",
       " 'Generic_City': 619,\n",
       " 'confidence': 620,\n",
       " 'hope': 621,\n",
       " 'dad': 622,\n",
       " 'wrote': 623,\n",
       " 'today': 624,\n",
       " 'By': 625,\n",
       " 'conferencing': 626,\n",
       " 'words': 627,\n",
       " 'studying': 628,\n",
       " 'everybody': 629,\n",
       " 'listen': 630,\n",
       " 'fact': 631,\n",
       " 'choices': 632,\n",
       " 'enjoyable': 633,\n",
       " 'menu': 634,\n",
       " 'skill': 635,\n",
       " 'build': 636,\n",
       " 'prepare': 637,\n",
       " 'effects': 638,\n",
       " 'add': 639,\n",
       " 'lesson': 640,\n",
       " 'continue': 641,\n",
       " 'walk': 642,\n",
       " 'topic': 643,\n",
       " 'rather': 644,\n",
       " 'resources': 645,\n",
       " 'answer': 646,\n",
       " 'behavior': 647,\n",
       " 'decided': 648,\n",
       " 'Working': 649,\n",
       " 'smart': 650,\n",
       " 'brain': 651,\n",
       " 'failing': 652,\n",
       " '3': 653,\n",
       " 'miss': 654,\n",
       " 'explain': 655,\n",
       " 'programs': 656,\n",
       " 'subject': 657,\n",
       " 'mad': 658,\n",
       " 'doctor': 659,\n",
       " 'enter': 660,\n",
       " 'Not': 661,\n",
       " 'turn': 662,\n",
       " 'side': 663,\n",
       " 'talent': 664,\n",
       " 'prefer': 665,\n",
       " 'wonderful': 666,\n",
       " 'amazing': 667,\n",
       " 'coming': 668,\n",
       " 'fall': 669,\n",
       " 'books': 670,\n",
       " 'confident': 671,\n",
       " \"'\": 672,\n",
       " 'brother': 673,\n",
       " 'nobody': 674,\n",
       " 'favorite': 675,\n",
       " 'takes': 676,\n",
       " 'personality': 677,\n",
       " '10': 678,\n",
       " 'far': 679,\n",
       " 'At': 680,\n",
       " 'addition': 681,\n",
       " 'main': 682,\n",
       " 'internet': 683,\n",
       " 'solve': 684,\n",
       " 'position': 685,\n",
       " 'thoughts': 686,\n",
       " 'certain': 687,\n",
       " 'imagine': 688,\n",
       " 'These': 689,\n",
       " 'step': 690,\n",
       " 'case': 691,\n",
       " 'safe': 692,\n",
       " 'likely': 693,\n",
       " 'either': 694,\n",
       " 'move': 695,\n",
       " 'few': 696,\n",
       " 'telling': 697,\n",
       " 'sick': 698,\n",
       " 'child': 699,\n",
       " 'full': 700,\n",
       " 'Jefferson': 701,\n",
       " 'gain': 702,\n",
       " ')': 703,\n",
       " 'fight': 704,\n",
       " 'elective': 705,\n",
       " 'teaching': 706,\n",
       " 'sometime': 707,\n",
       " 'Thomas': 708,\n",
       " 'Like': 709,\n",
       " '2': 710,\n",
       " 'says': 711,\n",
       " 'Everyone': 712,\n",
       " 'interest': 713,\n",
       " 'role': 714,\n",
       " 'develop': 715,\n",
       " 'form': 716,\n",
       " 'greatest': 717,\n",
       " 'somebody': 718,\n",
       " 'usually': 719,\n",
       " 'educational': 720,\n",
       " 'multiple': 721,\n",
       " 'living': 722,\n",
       " 'famous': 723,\n",
       " 'quote': 724,\n",
       " 'extracurricular': 725,\n",
       " 'yes': 726,\n",
       " 'open': 727,\n",
       " 'assignments': 728,\n",
       " 'small': 729,\n",
       " '(': 730,\n",
       " 'goes': 731,\n",
       " 'morning': 732,\n",
       " 'vacation': 733,\n",
       " 'communicate': 734,\n",
       " 'comfortable': 735,\n",
       " 'course': 736,\n",
       " 'board': 737,\n",
       " 'result': 738,\n",
       " 'chose': 739,\n",
       " 'saw': 740,\n",
       " 'asked': 741,\n",
       " 'lots': 742,\n",
       " 'interested': 743,\n",
       " 'collage': 744,\n",
       " 'On': 745,\n",
       " 'watch': 746,\n",
       " 'short': 747,\n",
       " 'persons': 748,\n",
       " 'waste': 749,\n",
       " 'principal': 750,\n",
       " 'moment': 751,\n",
       " 'setting': 752,\n",
       " 'participate': 753,\n",
       " 'became': 754,\n",
       " 'knew': 755,\n",
       " 'Churchill': 756,\n",
       " 'head': 757,\n",
       " 'amount': 758,\n",
       " 'personal': 759,\n",
       " 'knows': 760,\n",
       " 'sister': 761,\n",
       " 'distracted': 762,\n",
       " 'interesting': 763,\n",
       " 'self-esteem': 764,\n",
       " 'schedule': 765,\n",
       " 'becuase': 766,\n",
       " 'tried': 767,\n",
       " 'write': 768,\n",
       " 'helped': 769,\n",
       " 'normal': 770,\n",
       " 'lost': 771,\n",
       " 'parent': 772,\n",
       " 'assignment': 773,\n",
       " 'service': 774,\n",
       " 'required': 775,\n",
       " 'writing': 776,\n",
       " 'word': 777,\n",
       " 'healthier': 778,\n",
       " 'thinks': 779,\n",
       " 'relax': 780,\n",
       " 'humans': 781,\n",
       " 'communication': 782,\n",
       " 'join': 783,\n",
       " 'language': 784,\n",
       " 'showing': 785,\n",
       " 'Ralph': 786,\n",
       " 'Your': 787,\n",
       " 'changing': 788,\n",
       " 'view': 789,\n",
       " 'constantly': 790,\n",
       " 'player': 791,\n",
       " 'experts': 792,\n",
       " 'ourselves': 793,\n",
       " 'low': 794,\n",
       " 'eating': 795,\n",
       " 'path': 796,\n",
       " 'anymore': 797,\n",
       " 'How': 798,\n",
       " 'argue': 799,\n",
       " 'Lastly': 800,\n",
       " 'advantage': 801,\n",
       " 'reading': 802,\n",
       " 'middle': 803,\n",
       " 'between': 804,\n",
       " 'daily': 805,\n",
       " 'Why': 806,\n",
       " 'realize': 807,\n",
       " 'man': 808,\n",
       " 'fix': 809,\n",
       " 'Every': 810,\n",
       " 'extending': 811,\n",
       " 'teens': 812,\n",
       " 'stronger': 813,\n",
       " 'seek': 814,\n",
       " 'Secondly': 815,\n",
       " 'High': 816,\n",
       " 'Student': 817,\n",
       " 'media': 818,\n",
       " 'win': 819,\n",
       " 'questions': 820,\n",
       " 'prepared': 821,\n",
       " 'careers': 822,\n",
       " 'Waldo': 823,\n",
       " 'given': 824,\n",
       " 'changed': 825,\n",
       " 'model': 826,\n",
       " 'Third': 827,\n",
       " 'task': 828,\n",
       " 'towards': 829,\n",
       " 'clean': 830,\n",
       " 'law': 831,\n",
       " 'depends': 832,\n",
       " 'influences': 833,\n",
       " 'check': 834,\n",
       " 'four-day': 835,\n",
       " 'found': 836,\n",
       " 'failed': 837,\n",
       " 'wake': 838,\n",
       " 'achievement': 839,\n",
       " 'Other': 840,\n",
       " 'master': 841,\n",
       " 'environment': 842,\n",
       " 'left': 843,\n",
       " 'Its': 844,\n",
       " 'single': 845,\n",
       " 'necessary': 846,\n",
       " 'run': 847,\n",
       " 'companies': 848,\n",
       " 'ten': 849,\n",
       " 'Have': 850,\n",
       " '%': 851,\n",
       " '4': 852,\n",
       " 'state': 853,\n",
       " 'story': 854,\n",
       " 'drama': 855,\n",
       " 'staying': 856,\n",
       " 'graduated': 857,\n",
       " 'didnt': 858,\n",
       " 'With': 859,\n",
       " 'explore': 860,\n",
       " 'mostly': 861,\n",
       " 'boring': 862,\n",
       " 'Those': 863,\n",
       " 'close': 864,\n",
       " 'No': 865,\n",
       " 'actions': 866,\n",
       " 'basketball': 867,\n",
       " 'allows': 868,\n",
       " 'consists': 869,\n",
       " 'adults': 870,\n",
       " 'often': 871,\n",
       " 'stressful': 872,\n",
       " 'aim': 873,\n",
       " 'happened': 874,\n",
       " 'Well': 875,\n",
       " 'months': 876,\n",
       " 'beautiful': 877,\n",
       " 'called': 878,\n",
       " 'seen': 879,\n",
       " 'happens': 880,\n",
       " 'members': 881,\n",
       " 'teenager': 882,\n",
       " 'felt': 883,\n",
       " 'bit': 884,\n",
       " 'worked': 885,\n",
       " 'choosing': 886,\n",
       " 'Example': 887,\n",
       " 'cool': 888,\n",
       " 'regular': 889,\n",
       " 'store': 890,\n",
       " 'scared': 891,\n",
       " 'father': 892,\n",
       " 'bored': 893,\n",
       " 'hear': 894,\n",
       " 'attending': 895,\n",
       " 'plays': 896,\n",
       " 'begin': 897,\n",
       " 'huge': 898,\n",
       " 'u': 899,\n",
       " 'instance': 900,\n",
       " 'okay': 901,\n",
       " 'girl': 902,\n",
       " 'growing': 903,\n",
       " 'paper': 904,\n",
       " 'based': 905,\n",
       " 'watching': 906,\n",
       " '1': 907,\n",
       " 'inactivity': 908,\n",
       " 'wait': 909,\n",
       " 'likes': 910,\n",
       " 'higher': 911,\n",
       " 'finished': 912,\n",
       " 'paying': 913,\n",
       " 'finally': 914,\n",
       " 'motivation': 915,\n",
       " 'guide': 916,\n",
       " 'changes': 917,\n",
       " 'force': 918,\n",
       " 'responsibility': 919,\n",
       " 'cafeteria': 920,\n",
       " 'mother': 921,\n",
       " 'busy': 922,\n",
       " 'winter': 923,\n",
       " 'earn': 924,\n",
       " 'Teachers': 925,\n",
       " 'diploma': 926,\n",
       " 'boss': 927,\n",
       " 'conserve': 928,\n",
       " 'Schools': 929,\n",
       " 'serve': 930,\n",
       " 'city': 931,\n",
       " 'outdoors': 932,\n",
       " 'name': 933,\n",
       " 'afraid': 934,\n",
       " 'computers': 935,\n",
       " 'pressure': 936,\n",
       " 'types': 937,\n",
       " 'correct': 938,\n",
       " 'An': 939,\n",
       " 'matters': 940,\n",
       " 'heart': 941,\n",
       " 'cellphones': 942,\n",
       " 'treat': 943,\n",
       " 'fine': 944,\n",
       " 'theres': 945,\n",
       " 'parks': 946,\n",
       " 'stressed': 947,\n",
       " 'inside': 948,\n",
       " 'forward': 949,\n",
       " 'deal': 950,\n",
       " 'judge': 951,\n",
       " 'shy': 952,\n",
       " 'process': 953,\n",
       " 'hate': 954,\n",
       " 'receive': 955,\n",
       " 'Winston': 956,\n",
       " 'simple': 957,\n",
       " 'options': 958,\n",
       " 'studies': 959,\n",
       " 'Dear': 960,\n",
       " 'clubs': 961,\n",
       " 'ago': 962,\n",
       " 'Imagination': 963,\n",
       " 'understanding': 964,\n",
       " 'professional': 965,\n",
       " 'shop': 966,\n",
       " 'Last': 967,\n",
       " 'history': 968,\n",
       " 'adult': 969,\n",
       " 'extend': 970,\n",
       " 'university': 971,\n",
       " 'especially': 972,\n",
       " 'involved': 973,\n",
       " 'behind': 974,\n",
       " 'tasks': 975,\n",
       " 'accomplished': 976,\n",
       " 'tend': 977,\n",
       " 'productive': 978,\n",
       " 'ability': 979,\n",
       " '...': 980,\n",
       " 'manager': 981,\n",
       " 'Just': 982,\n",
       " 'Furthermore': 983,\n",
       " 'worth': 984,\n",
       " 'ride': 985,\n",
       " 'action': 986,\n",
       " 'countries': 987,\n",
       " 'challenge': 988,\n",
       " 'im': 989,\n",
       " 'struggle': 990,\n",
       " 'provide': 991,\n",
       " 'identify': 992,\n",
       " 'special': 993,\n",
       " 'water': 994,\n",
       " 'five': 995,\n",
       " 'allowed': 996,\n",
       " 'While': 997,\n",
       " 'room': 998,\n",
       " 'situations': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_vec(doc):\n",
    "    doc_vector = []\n",
    "    for i in doc:\n",
    "        word_vec = []\n",
    "        for j in i:\n",
    "            if j in word2vec.wv.index_to_key:\n",
    "                vec = word2vec.wv.get_vector(j)\n",
    "                word_vec.append(vec)\n",
    "        doc_vec = np.mean(word_vec,axis=0)\n",
    "        doc_vector.append(doc_vec)\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_list=[]\n",
    "text_df = pd.DataFrame({'text':text})\n",
    "text_df['doc_vec'] = text_df.apply(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(text_df['doc_vec'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train[['cohesion','syntax','vocabulary','phraseology','grammar','conventions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_estimators=500, random_state=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=500,max_depth=10, random_state=0)\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.30203059, 3.23184278, 3.33131656, 3.30710024, 3.35401458,\n",
       "        3.25549156],\n",
       "       [2.49019276, 2.36190613, 2.77376823, 2.37300509, 2.24219912,\n",
       "        2.42495688],\n",
       "       [3.02054067, 3.0645779 , 3.12953803, 3.05014905, 3.01789748,\n",
       "        2.95755926],\n",
       "       ...,\n",
       "       [2.93962723, 2.98180142, 3.16110128, 3.07827699, 3.17600514,\n",
       "        3.00820637],\n",
       "       [3.59000109, 3.63996559, 3.79425631, 3.61957787, 3.66021975,\n",
       "        3.6749586 ],\n",
       "       [3.20076999, 2.8210421 , 3.24318051, 3.00487587, 2.85530377,\n",
       "        3.14644587]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.int32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") at layer \"embedding_3\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m merged \u001b[39m=\u001b[39m Dropout(\u001b[39m0.1\u001b[39m)(merged)\n\u001b[1;32m     20\u001b[0m preds \u001b[39m=\u001b[39m Dense(\u001b[39m6\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)(merged)\n\u001b[0;32m---> 22\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39;49msequence_1_input, outputs\u001b[39m=\u001b[39;49mpreds)\n\u001b[1;32m     23\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbrmsprop\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m         optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m         metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[1;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/functional.py:232\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_coordinates\u001b[39m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    231\u001b[0m \u001b[39m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(\n\u001b[1;32m    233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs)\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_nodes \u001b[39m=\u001b[39m nodes\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_depth \u001b[39m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/functional.py:998\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39mkeras_inputs):\n\u001b[1;32m    997\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(x) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m computable_tensors:\n\u001b[0;32m--> 998\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    999\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraph disconnected: cannot obtain value for tensor \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1000\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mat layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. The following previous layers \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1001\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwere accessed without issue: \u001b[39m\u001b[39m{\u001b[39;00mlayers_with_complete_input\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1002\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39moutputs):\n\u001b[1;32m   1003\u001b[0m   computable_tensors\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.int32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") at layer \"embedding_3\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(3911, 1000,\n",
    "        weights=[x_train],\n",
    "        input_length=100,\n",
    "        trainable=False)\n",
    "lstm_layer = LSTM(128, dropout=0.1, recurrent_dropout=0.1)\n",
    "\n",
    "sequence_1_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "merged = Dropout(0.1)(y1)\n",
    "\n",
    "merged = Dense(12, activation='softmax')(merged)\n",
    "merged = Dropout(0.1)(merged)\n",
    "\n",
    "preds = Dense(6, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=sequence_1_input, outputs=preds)\n",
    "model.compile(loss='brmsprop',\n",
    "        optimizer='adam',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1000) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4z/rb211ylj27qc1wmrxcb4fngr0000gn/T/__autograph_generated_filem2aucrpe.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/yudichen/opt/anaconda3/envs/anly580/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1000) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('anly580')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ff0a887e51bafc0349a407f1ce4c16c0e41ff79bf0dd446943afae632e557d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
