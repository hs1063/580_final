{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DataCollatorWithPadding\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nfrom datasets import Dataset\n\nimport os\nimport gc\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:27.725673Z","iopub.execute_input":"2022-11-29T22:06:27.726766Z","iopub.status.idle":"2022-11-29T22:06:45.524005Z","shell.execute_reply.started":"2022-11-29T22:06:27.726594Z","shell.execute_reply":"2022-11-29T22:06:45.522750Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n        'folds': 5,\n        'seed': 101,\n        'robertabase': '../input/huggingface-roberta-variants/roberta-base/roberta-base',\n        'robertalarge': '../input/huggingface-roberta-variants/roberta-large/roberta-large',\n        #'debertav3base': '../input/debertav3base',\n        #'debertav3large': '../input/deberta-v3-large/deberta-v3-large/',\n        'xlmrobertabase': '../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base',\n        'distilrobertabase': '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base',\n        #'debertav3large_npy': '../input/fb3-save-pretrained-embeddings/debertav3large_FB3.npy',\n        #'distilrobertabase_npy': '../input/fb3-save-pretrained-embeddings/distilrobertabase_FB3.npy',\n\n        'batch_size': 4,\n        'max_len': 512\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:45.526215Z","iopub.execute_input":"2022-11-29T22:06:45.526964Z","iopub.status.idle":"2022-11-29T22:06:45.535760Z","shell.execute_reply.started":"2022-11-29T22:06:45.526924Z","shell.execute_reply":"2022-11-29T22:06:45.534747Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read in data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:45.538261Z","iopub.execute_input":"2022-11-29T22:06:45.539025Z","iopub.status.idle":"2022-11-29T22:06:45.715149Z","shell.execute_reply.started":"2022-11-29T22:06:45.538988Z","shell.execute_reply":"2022-11-29T22:06:45.714105Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv(\"/kaggle/input/large580/train_20000.csv\")\n#msk = np.random.rand(len(df)) <= 0.9\n#tgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = df[msk].dropna()\n#test = df[~msk].dropna()\n#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:45.718340Z","iopub.execute_input":"2022-11-29T22:06:45.718993Z","iopub.status.idle":"2022-11-29T22:06:45.723260Z","shell.execute_reply.started":"2022-11-29T22:06:45.718955Z","shell.execute_reply":"2022-11-29T22:06:45.722249Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\n#test = pd.read_csv(\"/kaggle/input/580data/test.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test_balanced.csv\")\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = train[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\n#test = test[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\nprint(train.shape)\nprint(test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:45.726549Z","iopub.execute_input":"2022-11-29T22:06:45.727233Z","iopub.status.idle":"2022-11-29T22:06:46.023047Z","shell.execute_reply.started":"2022-11-29T22:06:45.727197Z","shell.execute_reply":"2022-11-29T22:06:46.021994Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(3911, 8)\n(783, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.024724Z","iopub.execute_input":"2022-11-29T22:06:46.025583Z","iopub.status.idle":"2022-11-29T22:06:46.062128Z","shell.execute_reply.started":"2022-11-29T22:06:46.025544Z","shell.execute_reply":"2022-11-29T22:06:46.061066Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0       text_id  \\\n0           272  13C400DD9794   \n1          3051  D9BC7F4F22F0   \n2           800  3E170458E9A1   \n3          3206  E0BFF1488787   \n4          2664  C50BE3C76571   \n..          ...           ...   \n778        2207  A4A90A401002   \n779        2747  CA11FD3CAC43   \n780         155  0BB9FAE6E27B   \n781        3464  ED0A8E614649   \n782        2318  ACA1A45EE438   \n\n                                             full_text  cohesion  syntax  \\\n0    The year book is for to not forget anything an...       2.0     2.0   \n1    Well what i think about praising for a student...       2.5     2.5   \n2    I\\n\\ndisagree that first impressions are almos...       2.0     2.0   \n3    I disagree with schools having a program with ...       2.5     2.0   \n4    I dont like becuase the student forget all inf...       3.0     2.5   \n..                                                 ...       ...     ...   \n778  People who value self-reliance define it as th...       3.0     3.5   \n779  Many people have been told about the fact that...       4.5     4.0   \n780  Setting A Good Example\\n\\nHave you thought of ...       3.5     4.0   \n781  Techonology has becoming powerful that let stu...       4.5     3.5   \n782  I strongly disagree with extending the school ...       4.0     3.0   \n\n     vocabulary  phraseology  grammar  conventions  average  bin  \n0           2.0          2.0      2.0          2.0      2.0    0  \n1           2.5          3.0      2.5          2.0      2.5    0  \n2           2.0          2.0      2.0          2.5      2.1    0  \n3           2.5          2.0      2.0          2.5      2.3    0  \n4           2.0          2.0      2.0          2.5      2.4    0  \n..          ...          ...      ...          ...      ...  ...  \n778         3.5          4.0      3.5          4.0      3.6    2  \n779         3.5          4.0      3.5          3.5      3.9    2  \n780         4.5          4.0      3.5          3.5      3.9    2  \n781         4.0          4.0      4.0          3.5      3.9    2  \n782         3.0          4.0      4.0          4.0      3.6    2  \n\n[783 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>average</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272</td>\n      <td>13C400DD9794</td>\n      <td>The year book is for to not forget anything an...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3051</td>\n      <td>D9BC7F4F22F0</td>\n      <td>Well what i think about praising for a student...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>800</td>\n      <td>3E170458E9A1</td>\n      <td>I\\n\\ndisagree that first impressions are almos...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3206</td>\n      <td>E0BFF1488787</td>\n      <td>I disagree with schools having a program with ...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2664</td>\n      <td>C50BE3C76571</td>\n      <td>I dont like becuase the student forget all inf...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>2207</td>\n      <td>A4A90A401002</td>\n      <td>People who value self-reliance define it as th...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>2747</td>\n      <td>CA11FD3CAC43</td>\n      <td>Many people have been told about the fact that...</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>155</td>\n      <td>0BB9FAE6E27B</td>\n      <td>Setting A Good Example\\n\\nHave you thought of ...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3464</td>\n      <td>ED0A8E614649</td>\n      <td>Techonology has becoming powerful that let stu...</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>2318</td>\n      <td>ACA1A45EE438</td>\n      <td>I strongly disagree with extending the school ...</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"my_list = train.columns.values.tolist()\nmy_list","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.063982Z","iopub.execute_input":"2022-11-29T22:06:46.064744Z","iopub.status.idle":"2022-11-29T22:06:46.072328Z","shell.execute_reply.started":"2022-11-29T22:06:46.064699Z","shell.execute_reply":"2022-11-29T22:06:46.071124Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['text_id',\n 'full_text',\n 'cohesion',\n 'syntax',\n 'vocabulary',\n 'phraseology',\n 'grammar',\n 'conventions']"},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.074090Z","iopub.execute_input":"2022-11-29T22:06:46.074847Z","iopub.status.idle":"2022-11-29T22:06:46.098332Z","shell.execute_reply.started":"2022-11-29T22:06:46.074810Z","shell.execute_reply":"2022-11-29T22:06:46.097104Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     0016926B079C  I think that students would benefit from learn...   \n1     0022683E9EA5  When a problem is a change you have to let it ...   \n2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n3     003885A45F42  The best time in life is when you become yours...   \n4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n...            ...                                                ...   \n3906  FFD29828A873  I believe using cellphones in class for educat...   \n3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n0          3.5     3.5         3.0          3.0      4.0          3.0  \n1          2.5     2.5         3.0          2.0      2.0          2.5  \n2          3.0     3.5         3.0          3.0      3.0          2.5  \n3          4.5     4.5         4.5          4.5      4.0          5.0  \n4          2.5     3.0         3.0          3.0      2.5          2.5  \n...        ...     ...         ...          ...      ...          ...  \n3906       2.5     3.0         3.0          3.5      2.5          2.5  \n3907       4.0     4.0         4.0          4.0      3.5          3.0  \n3908       2.5     3.0         3.0          3.0      3.5          3.0  \n3909       4.0     4.5         4.5          4.0      4.5          4.5  \n3910       3.5     2.5         3.5          3.0      3.0          3.5  \n\n[3911 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FFD29828A873</td>\n      <td>I believe using cellphones in class for educat...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>FFD9A83B0849</td>\n      <td>Working alone, students do not have to argue w...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>FFDC4011AC9C</td>\n      <td>\"A problem is a chance for you to do your best...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>FFE16D704B16</td>\n      <td>Many people disagree with Albert Schweitzer's ...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>FFED00D6E0BD</td>\n      <td>Do you think that failure is the main thing fo...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create folds","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'kfold'] = -1 # Create a new column `fold` containing `-1`s.\ntrain = train.sample(frac=1).reset_index(drop=True) # Shuffle the rows.\ndata_labels = train[tgtCols].values","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.100000Z","iopub.execute_input":"2022-11-29T22:06:46.100448Z","iopub.status.idle":"2022-11-29T22:06:46.121990Z","shell.execute_reply.started":"2022-11-29T22:06:46.100411Z","shell.execute_reply":"2022-11-29T22:06:46.120948Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.128936Z","iopub.execute_input":"2022-11-29T22:06:46.129418Z","iopub.status.idle":"2022-11-29T22:06:46.151759Z","shell.execute_reply.started":"2022-11-29T22:06:46.129392Z","shell.execute_reply":"2022-11-29T22:06:46.150864Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor f, (t, v) in enumerate(mskf.split(X=train, y=data_labels)):\n    train.loc[v, 'kfold'] = f + 1","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.153151Z","iopub.execute_input":"2022-11-29T22:06:46.153486Z","iopub.status.idle":"2022-11-29T22:06:46.295034Z","shell.execute_reply.started":"2022-11-29T22:06:46.153453Z","shell.execute_reply":"2022-11-29T22:06:46.294063Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.296710Z","iopub.execute_input":"2022-11-29T22:06:46.297116Z","iopub.status.idle":"2022-11-29T22:06:46.320305Z","shell.execute_reply.started":"2022-11-29T22:06:46.297058Z","shell.execute_reply":"2022-11-29T22:06:46.319122Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     FE3F2F729D98  To whom read it.\\n\\nFirst impressions are poss...   \n1     78018FB48420  Students should not be able to graduate early....   \n2     6792C2E73B6A  Some people agree with the statement ''success...   \n3     CEF302996231  Dear Dr. Generic_Name,\\n\\nThank you for taking...   \n4     D581D89A822A  Should people make their own decisions, or sho...   \n...            ...                                                ...   \n3906  FDE0B653AD74  When you play activities or an instrument, don...   \n3907  00ED2563D0B1  Philosopher, physician, and humanitarian Alber...   \n3908  B9F6B348FC3A  In my experience I don't disagree, that Emerso...   \n3909  E65D5A2616D2  Imagine an old proverb said honestly was the b...   \n3910  62F578BA97ED  The negative effects of Technology allows peop...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  kfold  \n0          2.5     2.5         2.5          2.0      2.5          2.5      5  \n1          3.5     4.5         4.0          4.5      4.5          4.5      1  \n2          2.0     2.0         2.5          2.5      2.0          2.5      3  \n3          3.0     3.0         3.0          2.5      3.0          3.0      4  \n4          3.5     3.0         3.5          3.0      3.5          4.0      2  \n...        ...     ...         ...          ...      ...          ...    ...  \n3906       4.0     3.5         3.5          4.0      4.0          3.5      4  \n3907       3.5     3.0         3.5          3.5      3.5          4.0      3  \n3908       2.0     2.0         3.0          3.0      2.0          2.5      5  \n3909       3.0     3.0         3.5          4.0      3.5          3.5      1  \n3910       3.5     2.5         2.5          3.0      2.5          3.0      1  \n\n[3911 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FE3F2F729D98</td>\n      <td>To whom read it.\\n\\nFirst impressions are poss...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>78018FB48420</td>\n      <td>Students should not be able to graduate early....</td>\n      <td>3.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6792C2E73B6A</td>\n      <td>Some people agree with the statement ''success...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CEF302996231</td>\n      <td>Dear Dr. Generic_Name,\\n\\nThank you for taking...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>D581D89A822A</td>\n      <td>Should people make their own decisions, or sho...</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FDE0B653AD74</td>\n      <td>When you play activities or an instrument, don...</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>00ED2563D0B1</td>\n      <td>Philosopher, physician, and humanitarian Alber...</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>B9F6B348FC3A</td>\n      <td>In my experience I don't disagree, that Emerso...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>E65D5A2616D2</td>\n      <td>Imagine an old proverb said honestly was the b...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>62F578BA97ED</td>\n      <td>The negative effects of Technology allows peop...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['kfold'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.321940Z","iopub.execute_input":"2022-11-29T22:06:46.322335Z","iopub.status.idle":"2022-11-29T22:06:46.340039Z","shell.execute_reply.started":"2022-11-29T22:06:46.322296Z","shell.execute_reply":"2022-11-29T22:06:46.338752Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1    783\n2    782\n3    782\n4    782\n5    782\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data process functions","metadata":{}},{"cell_type":"code","source":"def self_encode(texts, chkpt):\n    \n    tokenizer = transformers.AutoTokenizer.from_pretrained(CONFIG[chkpt])\n    tokenizer.save_pretrained('./tokenizer/')\n\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=CONFIG['max_len'], \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.341791Z","iopub.execute_input":"2022-11-29T22:06:46.342354Z","iopub.status.idle":"2022-11-29T22:06:46.352327Z","shell.execute_reply.started":"2022-11-29T22:06:46.342313Z","shell.execute_reply":"2022-11-29T22:06:46.350907Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def pickle_dump(path, saveobj):\n    import pickle\n    handler = open(path,\"wb\")\n    pickle.dump(saveobj,handler)\n#     print(\"File pickled\")\n    handler.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.353983Z","iopub.execute_input":"2022-11-29T22:06:46.355283Z","iopub.status.idle":"2022-11-29T22:06:46.365622Z","shell.execute_reply.started":"2022-11-29T22:06:46.355245Z","shell.execute_reply":"2022-11-29T22:06:46.364523Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def pickle_load(path):\n    import pickle\n    file = open(path,'rb')\n    loader = pickle.load(file)\n    file.close()\n    return loader","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.367132Z","iopub.execute_input":"2022-11-29T22:06:46.367842Z","iopub.status.idle":"2022-11-29T22:06:46.383993Z","shell.execute_reply.started":"2022-11-29T22:06:46.367800Z","shell.execute_reply":"2022-11-29T22:06:46.382994Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Transformer embeddings","metadata":{}},{"cell_type":"code","source":"def pretrain_embeddings(chkpt, df):\n    cfg = transformers.AutoConfig.from_pretrained(CONFIG[chkpt], output_hidden_states=True)\n    cfg.hidden_dropout_prob = 0\n    cfg.attention_probs_dropout_prob = 0\n    cfg.save_pretrained('./tokenizer/')\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"attention_masks\"\n    )\n    \n    try:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg)\n    except:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg, from_pt=True)\n        \n    output = model(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = output.hidden_states\n    mean_pool = []\n    for hidden_s in hidden_states[-1:]:\n        #def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(attention_masks, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(hidden_s * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        tmp = embedding_sum / mask_sum\n        mean_pool.append(tmp)\n    output = tf.stack(mean_pool,axis=2)\n   \n    #output = tf.stack(\n    #    [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidd20000en_states[-1:]], \n    #    axis=2)\n    \n    output = tf.squeeze(output, axis=-1)\n    \n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n\n    model.compile(optimizer=\"adam\",\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    print(model.summary())\n    dataset = self_encode(df['full_text'], chkpt)\n    preds = model.predict(dataset, batch_size=CONFIG['batch_size'])\n    \n    del model, dataset\n    _ = gc.collect()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.387894Z","iopub.execute_input":"2022-11-29T22:06:46.388291Z","iopub.status.idle":"2022-11-29T22:06:46.403776Z","shell.execute_reply.started":"2022-11-29T22:06:46.388260Z","shell.execute_reply":"2022-11-29T22:06:46.402655Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"\ntrain_data = pretrain_embeddings('distilrobertabase', train)\n\n#train_data = np.concatenate([train_data, pretrain_embeddings('bertbasecased', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertabase', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertalarge', train)], axis=1)\n\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:06:46.406573Z","iopub.execute_input":"2022-11-29T22:06:46.407630Z","iopub.status.idle":"2022-11-29T22:21:16.659258Z","shell.execute_reply.started":"2022-11-29T22:06:46.407588Z","shell.execute_reply":"2022-11-29T22:21:16.658108Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-11-29 22:06:46.717990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.718969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.720020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.720783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.721526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.722346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.723812: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-29 22:06:46.981168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.982034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.982868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.983646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.984404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:46.985156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.633060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.633923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.634711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.635444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.636167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.636844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-29 22:06:56.641256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 22:06:56.641936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast (TFOpLambda)            (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 512, 1)       0           tf.cast[0][0]                    \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 512, 768)     0           tf_roberta_model[0][6]           \n                                                                 tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 768)          0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\ntf.math.maximum (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv (TFOpLambda)    (None, 768)          0           tf.math.reduce_sum[0][0]         \n                                                                 tf.math.maximum[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 768, 1)       0           tf.math.truediv[0][0]            \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 768)          0           tf.stack[0][0]                   \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"2022-11-29 22:07:19.123540: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_1 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 512, 1)       0           tf.cast_1[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_1 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_1[0][12]        \n                                                                 tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_2 (TFOpLambd (None, 768)          0           tf.math.multiply_1[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_1 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_1 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_2[0][0]       \n                                                                 tf.math.maximum_1[0][0]          \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_1[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_1 (TFOpLam (None, 768)          0           tf.stack_1[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_2 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_2 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_2 (TFOpLambda)   (None, 512, 1)       0           tf.cast_2[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_2 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_2[0][24]        \n                                                                 tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_5 (TFOpLambd (None, 1)            0           tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_4 (TFOpLambd (None, 1024)         0           tf.math.multiply_2[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_2 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_5[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_2 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_4[0][0]       \n                                                                 tf.math.maximum_2[0][0]          \n__________________________________________________________________________________________________\ntf.stack_2 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_2[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_2 (TFOpLam (None, 1024)         0           tf.stack_2[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3911, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"scores = []\nrmse_scores = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n\n    trn_idx = train[train['kfold']==fold].index.values\n    val_idx = train[train['kfold']!=fold].index.values\n    print(f\"trn_idx len is {len(trn_idx)}\")\n\n    X_train = train_data[trn_idx,:]\n    X_valid = train_data[val_idx,:]\n\n    y_train = train[train['kfold']==fold][tgtCols].copy()\n    y_valid = train[train['kfold']!=fold][tgtCols].copy()\n\n    val_preds = np.zeros((len(val_idx),6))\n\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        clf = SVR(C=10)\n        clf.fit(X_train, y_train[tgt].values)\n        pickle_dump(f\"./SVR_tgt{tgt}_fold{fold}.pkl\", clf)\n        val_preds[:,i] = clf.predict(X_valid)\n   \n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:21:16.660993Z","iopub.execute_input":"2022-11-29T22:21:16.661731Z","iopub.status.idle":"2022-11-29T22:23:13.371773Z","shell.execute_reply.started":"2022-11-29T22:21:16.661686Z","shell.execute_reply":"2022-11-29T22:23:13.370659Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ntrn_idx len is 783\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4682714783046971\n-----------------------------------\nOverall CV RMSE = 0.4751344197501293\n-----------------------------------\n## Fold 2\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.46985900406714975\n-----------------------------------\nOverall CV RMSE = 0.4727904779900445\n-----------------------------------\n## Fold 3\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4717039325208523\n-----------------------------------\nOverall CV RMSE = 0.47230438934714375\n-----------------------------------\n## Fold 4\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4719328973306533\n-----------------------------------\nOverall CV RMSE = 0.47228393388882633\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_data\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:23:13.373339Z","iopub.execute_input":"2022-11-29T22:23:13.373986Z","iopub.status.idle":"2022-11-29T22:23:13.607013Z","shell.execute_reply.started":"2022-11-29T22:23:13.373944Z","shell.execute_reply":"2022-11-29T22:23:13.606100Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model inference on Balanced Test","metadata":{}},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:23:13.608981Z","iopub.execute_input":"2022-11-29T22:23:13.609378Z","iopub.status.idle":"2022-11-29T22:26:30.362828Z","shell.execute_reply.started":"2022-11-29T22:23:13.609341Z","shell.execute_reply":"2022-11-29T22:26:30.361908Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_3 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_3 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_3 (TFOpLambda)   (None, 512, 1)       0           tf.cast_3[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_3 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_3[0][6]         \n                                                                 tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_7 (TFOpLambd (None, 1)            0           tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_6 (TFOpLambd (None, 768)          0           tf.math.multiply_3[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_3 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_7[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_3 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_6[0][0]       \n                                                                 tf.math.maximum_3[0][0]          \n__________________________________________________________________________________________________\ntf.stack_3 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_3[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_3 (TFOpLam (None, 768)          0           tf.stack_3[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_4 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_4 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_4 (TFOpLambda)   (None, 512, 1)       0           tf.cast_4[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_4 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_4[0][12]        \n                                                                 tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_9 (TFOpLambd (None, 1)            0           tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_8 (TFOpLambd (None, 768)          0           tf.math.multiply_4[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_4 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_9[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_4 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_8[0][0]       \n                                                                 tf.math.maximum_4[0][0]          \n__________________________________________________________________________________________________\ntf.stack_4 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_4[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_4 (TFOpLam (None, 768)          0           tf.stack_4[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_5 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_5 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_5 (TFOpLambda)   (None, 512, 1)       0           tf.cast_5[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_5 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_5[0][24]        \n                                                                 tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_11 (TFOpLamb (None, 1)            0           tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_10 (TFOpLamb (None, 1024)         0           tf.math.multiply_5[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_5 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_11[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_5 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_10[0][0]      \n                                                                 tf.math.maximum_5[0][0]          \n__________________________________________________________________________________________________\ntf.stack_5 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_5[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_5 (TFOpLam (None, 1024)         0           tf.stack_5[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(783, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:30.364295Z","iopub.execute_input":"2022-11-29T22:26:30.364770Z","iopub.status.idle":"2022-11-29T22:26:56.733929Z","shell.execute_reply.started":"2022-11-29T22:26:30.364734Z","shell.execute_reply":"2022-11-29T22:26:56.732804Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.47207027621653386\n-----------------------------------\nOverall CV RMSE = 0.47228764919280547\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.47216186214045425\n-----------------------------------\nOverall CV RMSE = 0.4722990099788883\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4722272806575403\n-----------------------------------\nOverall CV RMSE = 0.4723125566530724\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.47227634454535466\n-----------------------------------\nOverall CV RMSE = 0.4723262755860853\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.735570Z","iopub.execute_input":"2022-11-29T22:26:56.735949Z","iopub.status.idle":"2022-11-29T22:26:56.741869Z","shell.execute_reply.started":"2022-11-29T22:26:56.735913Z","shell.execute_reply":"2022-11-29T22:26:56.740648Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.743665Z","iopub.execute_input":"2022-11-29T22:26:56.744044Z","iopub.status.idle":"2022-11-29T22:26:56.763211Z","shell.execute_reply.started":"2022-11-29T22:26:56.744006Z","shell.execute_reply":"2022-11-29T22:26:56.762004Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     index       text_id\n0        0  13C400DD9794\n1        1  D9BC7F4F22F0\n2        2  3E170458E9A1\n3        3  E0BFF1488787\n4        4  C50BE3C76571\n..     ...           ...\n778    778  A4A90A401002\n779    779  CA11FD3CAC43\n780    780  0BB9FAE6E27B\n781    781  ED0A8E614649\n782    782  ACA1A45EE438\n\n[783 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>13C400DD9794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D9BC7F4F22F0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3E170458E9A1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>E0BFF1488787</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>C50BE3C76571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>778</td>\n      <td>A4A90A401002</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>779</td>\n      <td>CA11FD3CAC43</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>780</td>\n      <td>0BB9FAE6E27B</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>781</td>\n      <td>ED0A8E614649</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>782</td>\n      <td>ACA1A45EE438</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.766200Z","iopub.execute_input":"2022-11-29T22:26:56.767245Z","iopub.status.idle":"2022-11-29T22:26:56.785664Z","shell.execute_reply.started":"2022-11-29T22:26:56.767199Z","shell.execute_reply":"2022-11-29T22:26:56.784161Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"     cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0    1.816185  1.748447    2.234873     1.884909  1.797422     1.916126\n1    2.741063  2.605668    2.957189     2.761612  2.505799     2.403018\n2    1.935736  1.798175    2.323907     1.925007  1.722809     2.008836\n3    2.612268  2.473251    2.660657     2.777010  2.856524     2.679932\n4    2.256999  2.153023    2.318002     2.013254  1.997944     2.102921\n..        ...       ...         ...          ...       ...          ...\n778  3.622394  3.563503    3.730496     3.708827  3.590345     3.687552\n779  3.798472  3.681177    3.750709     3.684108  3.553883     3.786724\n780  3.518054  3.622119    3.810292     3.599986  3.503747     3.647713\n781  3.781951  3.593794    3.808436     3.634491  3.458773     3.511313\n782  3.569919  3.513071    3.316947     3.558721  3.740588     3.623699\n\n[783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.816185</td>\n      <td>1.748447</td>\n      <td>2.234873</td>\n      <td>1.884909</td>\n      <td>1.797422</td>\n      <td>1.916126</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.741063</td>\n      <td>2.605668</td>\n      <td>2.957189</td>\n      <td>2.761612</td>\n      <td>2.505799</td>\n      <td>2.403018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.935736</td>\n      <td>1.798175</td>\n      <td>2.323907</td>\n      <td>1.925007</td>\n      <td>1.722809</td>\n      <td>2.008836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.612268</td>\n      <td>2.473251</td>\n      <td>2.660657</td>\n      <td>2.777010</td>\n      <td>2.856524</td>\n      <td>2.679932</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.256999</td>\n      <td>2.153023</td>\n      <td>2.318002</td>\n      <td>2.013254</td>\n      <td>1.997944</td>\n      <td>2.102921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>3.622394</td>\n      <td>3.563503</td>\n      <td>3.730496</td>\n      <td>3.708827</td>\n      <td>3.590345</td>\n      <td>3.687552</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>3.798472</td>\n      <td>3.681177</td>\n      <td>3.750709</td>\n      <td>3.684108</td>\n      <td>3.553883</td>\n      <td>3.786724</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>3.518054</td>\n      <td>3.622119</td>\n      <td>3.810292</td>\n      <td>3.599986</td>\n      <td>3.503747</td>\n      <td>3.647713</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3.781951</td>\n      <td>3.593794</td>\n      <td>3.808436</td>\n      <td>3.634491</td>\n      <td>3.458773</td>\n      <td>3.511313</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>3.569919</td>\n      <td>3.513071</td>\n      <td>3.316947</td>\n      <td>3.558721</td>\n      <td>3.740588</td>\n      <td>3.623699</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.787684Z","iopub.execute_input":"2022-11-29T22:26:56.788176Z","iopub.status.idle":"2022-11-29T22:26:56.812032Z","shell.execute_reply.started":"2022-11-29T22:26:56.788048Z","shell.execute_reply":"2022-11-29T22:26:56.811119Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"          text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0    13C400DD9794  1.816185  1.748447    2.234873     1.884909  1.797422   \n1    D9BC7F4F22F0  2.741063  2.605668    2.957189     2.761612  2.505799   \n2    3E170458E9A1  1.935736  1.798175    2.323907     1.925007  1.722809   \n3    E0BFF1488787  2.612268  2.473251    2.660657     2.777010  2.856524   \n4    C50BE3C76571  2.256999  2.153023    2.318002     2.013254  1.997944   \n..            ...       ...       ...         ...          ...       ...   \n778  A4A90A401002  3.622394  3.563503    3.730496     3.708827  3.590345   \n779  CA11FD3CAC43  3.798472  3.681177    3.750709     3.684108  3.553883   \n780  0BB9FAE6E27B  3.518054  3.622119    3.810292     3.599986  3.503747   \n781  ED0A8E614649  3.781951  3.593794    3.808436     3.634491  3.458773   \n782  ACA1A45EE438  3.569919  3.513071    3.316947     3.558721  3.740588   \n\n     conventions  \n0       1.916126  \n1       2.403018  \n2       2.008836  \n3       2.679932  \n4       2.102921  \n..           ...  \n778     3.687552  \n779     3.786724  \n780     3.647713  \n781     3.511313  \n782     3.623699  \n\n[783 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13C400DD9794</td>\n      <td>1.816185</td>\n      <td>1.748447</td>\n      <td>2.234873</td>\n      <td>1.884909</td>\n      <td>1.797422</td>\n      <td>1.916126</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D9BC7F4F22F0</td>\n      <td>2.741063</td>\n      <td>2.605668</td>\n      <td>2.957189</td>\n      <td>2.761612</td>\n      <td>2.505799</td>\n      <td>2.403018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3E170458E9A1</td>\n      <td>1.935736</td>\n      <td>1.798175</td>\n      <td>2.323907</td>\n      <td>1.925007</td>\n      <td>1.722809</td>\n      <td>2.008836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E0BFF1488787</td>\n      <td>2.612268</td>\n      <td>2.473251</td>\n      <td>2.660657</td>\n      <td>2.777010</td>\n      <td>2.856524</td>\n      <td>2.679932</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C50BE3C76571</td>\n      <td>2.256999</td>\n      <td>2.153023</td>\n      <td>2.318002</td>\n      <td>2.013254</td>\n      <td>1.997944</td>\n      <td>2.102921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>A4A90A401002</td>\n      <td>3.622394</td>\n      <td>3.563503</td>\n      <td>3.730496</td>\n      <td>3.708827</td>\n      <td>3.590345</td>\n      <td>3.687552</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>CA11FD3CAC43</td>\n      <td>3.798472</td>\n      <td>3.681177</td>\n      <td>3.750709</td>\n      <td>3.684108</td>\n      <td>3.553883</td>\n      <td>3.786724</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>0BB9FAE6E27B</td>\n      <td>3.518054</td>\n      <td>3.622119</td>\n      <td>3.810292</td>\n      <td>3.599986</td>\n      <td>3.503747</td>\n      <td>3.647713</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>ED0A8E614649</td>\n      <td>3.781951</td>\n      <td>3.593794</td>\n      <td>3.808436</td>\n      <td>3.634491</td>\n      <td>3.458773</td>\n      <td>3.511313</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>ACA1A45EE438</td>\n      <td>3.569919</td>\n      <td>3.513071</td>\n      <td>3.316947</td>\n      <td>3.558721</td>\n      <td>3.740588</td>\n      <td>3.623699</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running the final text dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/580data/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.813652Z","iopub.execute_input":"2022-11-29T22:26:56.814053Z","iopub.status.idle":"2022-11-29T22:26:56.829962Z","shell.execute_reply.started":"2022-11-29T22:26:56.814017Z","shell.execute_reply":"2022-11-29T22:26:56.829134Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:26:56.835990Z","iopub.execute_input":"2022-11-29T22:26:56.836269Z","iopub.status.idle":"2022-11-29T22:27:38.035102Z","shell.execute_reply.started":"2022-11-29T22:26:56.836244Z","shell.execute_reply":"2022-11-29T22:27:38.034029Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_6 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_6 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_6 (TFOpLambda)   (None, 512, 1)       0           tf.cast_6[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_6 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_6[0][6]         \n                                                                 tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_13 (TFOpLamb (None, 1)            0           tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_12 (TFOpLamb (None, 768)          0           tf.math.multiply_6[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_6 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_13[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_6 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_12[0][0]      \n                                                                 tf.math.maximum_6[0][0]          \n__________________________________________________________________________________________________\ntf.stack_6 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_6[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_6 (TFOpLam (None, 768)          0           tf.stack_6[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_7 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_7 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_7 (TFOpLambda)   (None, 512, 1)       0           tf.cast_7[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_7 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_7[0][12]        \n                                                                 tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_15 (TFOpLamb (None, 1)            0           tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_14 (TFOpLamb (None, 768)          0           tf.math.multiply_7[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_7 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_15[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_7 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_14[0][0]      \n                                                                 tf.math.maximum_7[0][0]          \n__________________________________________________________________________________________________\ntf.stack_7 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_7[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_7 (TFOpLam (None, 768)          0           tf.stack_7[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_8 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_8 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_8 (TFOpLambda)   (None, 512, 1)       0           tf.cast_8[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_8 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_8[0][24]        \n                                                                 tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_17 (TFOpLamb (None, 1)            0           tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_16 (TFOpLamb (None, 1024)         0           tf.math.multiply_8[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_8 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_17[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_8 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_16[0][0]      \n                                                                 tf.math.maximum_8[0][0]          \n__________________________________________________________________________________________________\ntf.stack_8 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_8[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_8 (TFOpLam (None, 1024)         0           tf.stack_8[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(8, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:38.036504Z","iopub.execute_input":"2022-11-29T22:27:38.037247Z","iopub.status.idle":"2022-11-29T22:27:39.380384Z","shell.execute_reply.started":"2022-11-29T22:27:38.037206Z","shell.execute_reply":"2022-11-29T22:27:39.379399Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.47231450534698816\n-----------------------------------\nOverall CV RMSE = 0.472339402591171\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.472345033988295\n-----------------------------------\nOverall CV RMSE = 0.47235167059599165\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4723700119675461\n-----------------------------------\nOverall CV RMSE = 0.47236302030472926\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4723908269502552\n-----------------------------------\nOverall CV RMSE = 0.47237347973421273\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.382023Z","iopub.execute_input":"2022-11-29T22:27:39.382408Z","iopub.status.idle":"2022-11-29T22:27:39.387787Z","shell.execute_reply.started":"2022-11-29T22:27:39.382372Z","shell.execute_reply":"2022-11-29T22:27:39.386624Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.389499Z","iopub.execute_input":"2022-11-29T22:27:39.390202Z","iopub.status.idle":"2022-11-29T22:27:39.411119Z","shell.execute_reply.started":"2022-11-29T22:27:39.390154Z","shell.execute_reply":"2022-11-29T22:27:39.409873Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0  2.847516  2.767603    2.990523     2.889130  2.576317     2.593019\n1  2.724639  2.471339    2.718179     2.438099  2.157643     2.610832\n2  3.447244  3.366904    3.545405     3.535074  3.348391     3.309278\n3  3.332546  3.299008    3.441460     3.325426  3.447684     3.073018\n4  3.748011  3.749285    3.879655     3.733077  3.678509     3.407902\n5  3.690385  3.607072    3.933969     3.575780  3.568065     3.728966\n6  3.866299  3.822295    3.981464     3.891308  3.855148     3.776293\n7  4.067658  3.877154    4.020447     3.846368  3.737488     3.865833","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.847516</td>\n      <td>2.767603</td>\n      <td>2.990523</td>\n      <td>2.889130</td>\n      <td>2.576317</td>\n      <td>2.593019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.724639</td>\n      <td>2.471339</td>\n      <td>2.718179</td>\n      <td>2.438099</td>\n      <td>2.157643</td>\n      <td>2.610832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.447244</td>\n      <td>3.366904</td>\n      <td>3.545405</td>\n      <td>3.535074</td>\n      <td>3.348391</td>\n      <td>3.309278</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.332546</td>\n      <td>3.299008</td>\n      <td>3.441460</td>\n      <td>3.325426</td>\n      <td>3.447684</td>\n      <td>3.073018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.748011</td>\n      <td>3.749285</td>\n      <td>3.879655</td>\n      <td>3.733077</td>\n      <td>3.678509</td>\n      <td>3.407902</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.690385</td>\n      <td>3.607072</td>\n      <td>3.933969</td>\n      <td>3.575780</td>\n      <td>3.568065</td>\n      <td>3.728966</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.866299</td>\n      <td>3.822295</td>\n      <td>3.981464</td>\n      <td>3.891308</td>\n      <td>3.855148</td>\n      <td>3.776293</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4.067658</td>\n      <td>3.877154</td>\n      <td>4.020447</td>\n      <td>3.846368</td>\n      <td>3.737488</td>\n      <td>3.865833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.412826Z","iopub.execute_input":"2022-11-29T22:27:39.413222Z","iopub.status.idle":"2022-11-29T22:27:39.427501Z","shell.execute_reply.started":"2022-11-29T22:27:39.413188Z","shell.execute_reply":"2022-11-29T22:27:39.426126Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   index       text_id\n0      0  0000C359D63E\n1      1  000BAD50D026\n2      2  00367BB2546B\n3      3            hp\n4      4           tkm\n5      5   high school\n6      6      college1\n7      7      college2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0000C359D63E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000BAD50D026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>00367BB2546B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>hp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>tkm</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>high school</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>college1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>college2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.429056Z","iopub.execute_input":"2022-11-29T22:27:39.429450Z","iopub.status.idle":"2022-11-29T22:27:39.459937Z","shell.execute_reply.started":"2022-11-29T22:27:39.429399Z","shell.execute_reply":"2022-11-29T22:27:39.458867Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.847516  2.767603    2.990523     2.889130  2.576317   \n1  000BAD50D026  2.724639  2.471339    2.718179     2.438099  2.157643   \n2  00367BB2546B  3.447244  3.366904    3.545405     3.535074  3.348391   \n3            hp  3.332546  3.299008    3.441460     3.325426  3.447684   \n4           tkm  3.748011  3.749285    3.879655     3.733077  3.678509   \n5   high school  3.690385  3.607072    3.933969     3.575780  3.568065   \n6      college1  3.866299  3.822295    3.981464     3.891308  3.855148   \n7      college2  4.067658  3.877154    4.020447     3.846368  3.737488   \n\n   conventions  \n0     2.593019  \n1     2.610832  \n2     3.309278  \n3     3.073018  \n4     3.407902  \n5     3.728966  \n6     3.776293  \n7     3.865833  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.847516</td>\n      <td>2.767603</td>\n      <td>2.990523</td>\n      <td>2.889130</td>\n      <td>2.576317</td>\n      <td>2.593019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.724639</td>\n      <td>2.471339</td>\n      <td>2.718179</td>\n      <td>2.438099</td>\n      <td>2.157643</td>\n      <td>2.610832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.447244</td>\n      <td>3.366904</td>\n      <td>3.545405</td>\n      <td>3.535074</td>\n      <td>3.348391</td>\n      <td>3.309278</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp</td>\n      <td>3.332546</td>\n      <td>3.299008</td>\n      <td>3.441460</td>\n      <td>3.325426</td>\n      <td>3.447684</td>\n      <td>3.073018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tkm</td>\n      <td>3.748011</td>\n      <td>3.749285</td>\n      <td>3.879655</td>\n      <td>3.733077</td>\n      <td>3.678509</td>\n      <td>3.407902</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>high school</td>\n      <td>3.690385</td>\n      <td>3.607072</td>\n      <td>3.933969</td>\n      <td>3.575780</td>\n      <td>3.568065</td>\n      <td>3.728966</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>college1</td>\n      <td>3.866299</td>\n      <td>3.822295</td>\n      <td>3.981464</td>\n      <td>3.891308</td>\n      <td>3.855148</td>\n      <td>3.776293</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>college2</td>\n      <td>4.067658</td>\n      <td>3.877154</td>\n      <td>4.020447</td>\n      <td>3.846368</td>\n      <td>3.737488</td>\n      <td>3.865833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running SVR after TF-IDF","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error as mse\nimport math\nfrom sklearn.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.461694Z","iopub.execute_input":"2022-11-29T22:27:39.462121Z","iopub.status.idle":"2022-11-29T22:27:39.565634Z","shell.execute_reply.started":"2022-11-29T22:27:39.462069Z","shell.execute_reply":"2022-11-29T22:27:39.564734Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Running for the train full_text with training all\n# fit the six test as test\nfull_df = np.concatenate((train.full_text.values,test.full_text.values))","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.567046Z","iopub.execute_input":"2022-11-29T22:27:39.567403Z","iopub.status.idle":"2022-11-29T22:27:39.573125Z","shell.execute_reply.started":"2022-11-29T22:27:39.567368Z","shell.execute_reply":"2022-11-29T22:27:39.571923Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tfidf_featurizer = TfidfVectorizer(max_features=10000, max_df=0.95, stop_words='english')\nX_tfidf = tfidf_featurizer.fit_transform(full_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:39.574796Z","iopub.execute_input":"2022-11-29T22:27:39.576317Z","iopub.status.idle":"2022-11-29T22:27:40.507995Z","shell.execute_reply.started":"2022-11-29T22:27:39.576282Z","shell.execute_reply":"2022-11-29T22:27:40.506972Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# SPLIT DATA\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf[0:len(train.full_text)], \n                                                    train[tgtCols].values,\n                                                    test_size=0.10,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.509421Z","iopub.execute_input":"2022-11-29T22:27:40.509871Z","iopub.status.idle":"2022-11-29T22:27:40.521595Z","shell.execute_reply.started":"2022-11-29T22:27:40.509828Z","shell.execute_reply":"2022-11-29T22:27:40.520647Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.523013Z","iopub.execute_input":"2022-11-29T22:27:40.523434Z","iopub.status.idle":"2022-11-29T22:27:40.534315Z","shell.execute_reply.started":"2022-11-29T22:27:40.523396Z","shell.execute_reply":"2022-11-29T22:27:40.533145Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"(3519, 10000)\n(392, 10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = {'C' : 10, \n                'epsilon': 0.1, \n                'gamma' : 1, \n                'kernel' : 'rbf'} ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.535848Z","iopub.execute_input":"2022-11-29T22:27:40.536277Z","iopub.status.idle":"2022-11-29T22:27:40.545111Z","shell.execute_reply.started":"2022-11-29T22:27:40.536241Z","shell.execute_reply":"2022-11-29T22:27:40.544121Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"data_test = X_tfidf[len(train.full_text):]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.546550Z","iopub.execute_input":"2022-11-29T22:27:40.546940Z","iopub.status.idle":"2022-11-29T22:27:40.557416Z","shell.execute_reply.started":"2022-11-29T22:27:40.546903Z","shell.execute_reply":"2022-11-29T22:27:40.556378Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#  \ndf_sum = pd.DataFrame([],index=test.text_id,columns= tgtCols)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.558853Z","iopub.execute_input":"2022-11-29T22:27:40.559241Z","iopub.status.idle":"2022-11-29T22:27:40.571441Z","shell.execute_reply.started":"2022-11-29T22:27:40.559205Z","shell.execute_reply":"2022-11-29T22:27:40.570476Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nrerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(X_test)\n  rerror.append(mse(rf_preds,y_test[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:27:40.574557Z","iopub.execute_input":"2022-11-29T22:27:40.574834Z","iopub.status.idle":"2022-11-29T22:28:41.724042Z","shell.execute_reply.started":"2022-11-29T22:27:40.574810Z","shell.execute_reply":"2022-11-29T22:28:41.722822Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.5608407952277368\n","output_type":"stream"}]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(data_test)\n  df_sum[tgtCols[k]] = rf_preds\n  #error.append(rmse(rf_preds,y_test[:,k],squared=False))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:28:41.725470Z","iopub.execute_input":"2022-11-29T22:28:41.726356Z","iopub.status.idle":"2022-11-29T22:29:37.261610Z","shell.execute_reply.started":"2022-11-29T22:28:41.726323Z","shell.execute_reply":"2022-11-29T22:29:37.260502Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-29T22:29:37.264301Z","iopub.execute_input":"2022-11-29T22:29:37.265035Z","iopub.status.idle":"2022-11-29T22:29:37.279799Z","shell.execute_reply.started":"2022-11-29T22:29:37.264995Z","shell.execute_reply":"2022-11-29T22:29:37.278748Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"              cohesion    syntax  vocabulary  phraseology   grammar  \\\ntext_id                                                               \n0000C359D63E  2.903885  2.846374    3.243762     3.129120  2.709364   \n000BAD50D026  3.051334  2.783242    2.934718     2.746411  2.696641   \n00367BB2546B  3.452976  3.466839    3.510834     3.404067  3.320165   \nhp            2.699314  2.648640    2.981226     2.842798  2.789414   \ntkm           2.816422  2.771121    3.019191     2.854721  2.870556   \nhigh school   2.934556  2.777547    3.218054     2.970385  2.847546   \ncollege1      3.002360  3.004760    3.292190     3.087244  3.038965   \ncollege2      3.086213  2.954979    3.282283     3.009380  2.999821   \n\n              conventions  \ntext_id                    \n0000C359D63E     2.811444  \n000BAD50D026     2.949309  \n00367BB2546B     3.382930  \nhp               2.725232  \ntkm              2.780690  \nhigh school      2.853670  \ncollege1         2.894806  \ncollege2         2.996158  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n    <tr>\n      <th>text_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000C359D63E</th>\n      <td>2.903885</td>\n      <td>2.846374</td>\n      <td>3.243762</td>\n      <td>3.129120</td>\n      <td>2.709364</td>\n      <td>2.811444</td>\n    </tr>\n    <tr>\n      <th>000BAD50D026</th>\n      <td>3.051334</td>\n      <td>2.783242</td>\n      <td>2.934718</td>\n      <td>2.746411</td>\n      <td>2.696641</td>\n      <td>2.949309</td>\n    </tr>\n    <tr>\n      <th>00367BB2546B</th>\n      <td>3.452976</td>\n      <td>3.466839</td>\n      <td>3.510834</td>\n      <td>3.404067</td>\n      <td>3.320165</td>\n      <td>3.382930</td>\n    </tr>\n    <tr>\n      <th>hp</th>\n      <td>2.699314</td>\n      <td>2.648640</td>\n      <td>2.981226</td>\n      <td>2.842798</td>\n      <td>2.789414</td>\n      <td>2.725232</td>\n    </tr>\n    <tr>\n      <th>tkm</th>\n      <td>2.816422</td>\n      <td>2.771121</td>\n      <td>3.019191</td>\n      <td>2.854721</td>\n      <td>2.870556</td>\n      <td>2.780690</td>\n    </tr>\n    <tr>\n      <th>high school</th>\n      <td>2.934556</td>\n      <td>2.777547</td>\n      <td>3.218054</td>\n      <td>2.970385</td>\n      <td>2.847546</td>\n      <td>2.853670</td>\n    </tr>\n    <tr>\n      <th>college1</th>\n      <td>3.002360</td>\n      <td>3.004760</td>\n      <td>3.292190</td>\n      <td>3.087244</td>\n      <td>3.038965</td>\n      <td>2.894806</td>\n    </tr>\n    <tr>\n      <th>college2</th>\n      <td>3.086213</td>\n      <td>2.954979</td>\n      <td>3.282283</td>\n      <td>3.009380</td>\n      <td>2.999821</td>\n      <td>2.996158</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}