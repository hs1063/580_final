{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DataCollatorWithPadding\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nfrom datasets import Dataset\n\nimport os\nimport gc\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:17.065276Z","iopub.execute_input":"2022-11-29T18:01:17.066296Z","iopub.status.idle":"2022-11-29T18:01:20.720135Z","shell.execute_reply.started":"2022-11-29T18:01:17.066207Z","shell.execute_reply":"2022-11-29T18:01:20.719093Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n        'folds': 5,\n        'seed': 101,\n        'robertabase': '../input/huggingface-roberta-variants/roberta-base/roberta-base',\n        'robertalarge': '../input/huggingface-roberta-variants/roberta-large/roberta-large',\n        #'debertav3base': '../input/debertav3base',\n        #'debertav3large': '../input/deberta-v3-large/deberta-v3-large/',\n        'xlmrobertabase': '../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base',\n        'distilrobertabase': '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base',\n        #'debertav3large_npy': '../input/fb3-save-pretrained-embeddings/debertav3large_FB3.npy',\n        #'distilrobertabase_npy': '../input/fb3-save-pretrained-embeddings/distilrobertabase_FB3.npy',\n\n        'batch_size': 4,\n        'max_len': 512\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.726685Z","iopub.execute_input":"2022-11-29T18:01:20.727169Z","iopub.status.idle":"2022-11-29T18:01:20.734543Z","shell.execute_reply.started":"2022-11-29T18:01:20.727122Z","shell.execute_reply":"2022-11-29T18:01:20.733355Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read in data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.736152Z","iopub.execute_input":"2022-11-29T18:01:20.736972Z","iopub.status.idle":"2022-11-29T18:01:20.782214Z","shell.execute_reply.started":"2022-11-29T18:01:20.736934Z","shell.execute_reply":"2022-11-29T18:01:20.781386Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv(\"/kaggle/input/large580/train_20000.csv\")\n#msk = np.random.rand(len(df)) <= 0.9\n#tgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = df[msk].dropna()\n#test = df[~msk].dropna()\n#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.786917Z","iopub.execute_input":"2022-11-29T18:01:20.787194Z","iopub.status.idle":"2022-11-29T18:01:20.792066Z","shell.execute_reply.started":"2022-11-29T18:01:20.787169Z","shell.execute_reply":"2022-11-29T18:01:20.791089Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test.csv\")\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = train[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\n#test = test[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\nprint(train.shape)\nprint(test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.793540Z","iopub.execute_input":"2022-11-29T18:01:20.794218Z","iopub.status.idle":"2022-11-29T18:01:20.902491Z","shell.execute_reply.started":"2022-11-29T18:01:20.794177Z","shell.execute_reply":"2022-11-29T18:01:20.901494Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(3911, 8)\n(9, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.904312Z","iopub.execute_input":"2022-11-29T18:01:20.905188Z","iopub.status.idle":"2022-11-29T18:01:20.924130Z","shell.execute_reply.started":"2022-11-29T18:01:20.905147Z","shell.execute_reply":"2022-11-29T18:01:20.922947Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0       text_id                                          full_text\n0           0  0000C359D63E  when a person has no experience on a job their...\n1           1  000BAD50D026  Do you think students would benefit from being...\n2           2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...\n3           3            hp  Dumbledore and Professor McGonagall bent forwa...\n4           4           tkm  Being Southerners, it was a source of shame to...\n5           5            va  To improve the compositionality of the semanti...\n6           6            ll  The first Wednesday in every month was a Perfe...\n7           7            sp  Thou see'st these lovers seek a place to fight...\n8           8            bp  Fifteen years later, in 1980, Jintong emerges ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text_id</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>hp</td>\n      <td>Dumbledore and Professor McGonagall bent forwa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>tkm</td>\n      <td>Being Southerners, it was a source of shame to...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>va</td>\n      <td>To improve the compositionality of the semanti...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>ll</td>\n      <td>The first Wednesday in every month was a Perfe...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>sp</td>\n      <td>Thou see'st these lovers seek a place to fight...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>bp</td>\n      <td>Fifteen years later, in 1980, Jintong emerges ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"my_list = train.columns.values.tolist()\nmy_list","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.925686Z","iopub.execute_input":"2022-11-29T18:01:20.926137Z","iopub.status.idle":"2022-11-29T18:01:20.934070Z","shell.execute_reply.started":"2022-11-29T18:01:20.926102Z","shell.execute_reply":"2022-11-29T18:01:20.932828Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['text_id',\n 'full_text',\n 'cohesion',\n 'syntax',\n 'vocabulary',\n 'phraseology',\n 'grammar',\n 'conventions']"},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.935898Z","iopub.execute_input":"2022-11-29T18:01:20.936286Z","iopub.status.idle":"2022-11-29T18:01:20.962268Z","shell.execute_reply.started":"2022-11-29T18:01:20.936240Z","shell.execute_reply":"2022-11-29T18:01:20.961076Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     0016926B079C  I think that students would benefit from learn...   \n1     0022683E9EA5  When a problem is a change you have to let it ...   \n2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n3     003885A45F42  The best time in life is when you become yours...   \n4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n...            ...                                                ...   \n3906  FFD29828A873  I believe using cellphones in class for educat...   \n3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n0          3.5     3.5         3.0          3.0      4.0          3.0  \n1          2.5     2.5         3.0          2.0      2.0          2.5  \n2          3.0     3.5         3.0          3.0      3.0          2.5  \n3          4.5     4.5         4.5          4.5      4.0          5.0  \n4          2.5     3.0         3.0          3.0      2.5          2.5  \n...        ...     ...         ...          ...      ...          ...  \n3906       2.5     3.0         3.0          3.5      2.5          2.5  \n3907       4.0     4.0         4.0          4.0      3.5          3.0  \n3908       2.5     3.0         3.0          3.0      3.5          3.0  \n3909       4.0     4.5         4.5          4.0      4.5          4.5  \n3910       3.5     2.5         3.5          3.0      3.0          3.5  \n\n[3911 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FFD29828A873</td>\n      <td>I believe using cellphones in class for educat...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>FFD9A83B0849</td>\n      <td>Working alone, students do not have to argue w...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>FFDC4011AC9C</td>\n      <td>\"A problem is a chance for you to do your best...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>FFE16D704B16</td>\n      <td>Many people disagree with Albert Schweitzer's ...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>FFED00D6E0BD</td>\n      <td>Do you think that failure is the main thing fo...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create folds","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'kfold'] = -1 # Create a new column `fold` containing `-1`s.\ntrain = train.sample(frac=1).reset_index(drop=True) # Shuffle the rows.\ndata_labels = train[tgtCols].values","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.964040Z","iopub.execute_input":"2022-11-29T18:01:20.964772Z","iopub.status.idle":"2022-11-29T18:01:20.981181Z","shell.execute_reply.started":"2022-11-29T18:01:20.964728Z","shell.execute_reply":"2022-11-29T18:01:20.980081Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:20.983635Z","iopub.execute_input":"2022-11-29T18:01:20.984704Z","iopub.status.idle":"2022-11-29T18:01:21.010048Z","shell.execute_reply.started":"2022-11-29T18:01:20.984571Z","shell.execute_reply":"2022-11-29T18:01:21.009239Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor f, (t, v) in enumerate(mskf.split(X=train, y=data_labels)):\n    train.loc[v, 'kfold'] = f + 1","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.013508Z","iopub.execute_input":"2022-11-29T18:01:21.013814Z","iopub.status.idle":"2022-11-29T18:01:21.164809Z","shell.execute_reply.started":"2022-11-29T18:01:21.013787Z","shell.execute_reply":"2022-11-29T18:01:21.163666Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.166484Z","iopub.execute_input":"2022-11-29T18:01:21.166885Z","iopub.status.idle":"2022-11-29T18:01:21.191913Z","shell.execute_reply.started":"2022-11-29T18:01:21.166844Z","shell.execute_reply":"2022-11-29T18:01:21.190454Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     94EC7DF6EA74  People these days dont go outdoors as much as ...   \n1     B204869FA146  Is technology a positive or negative effect on...   \n2     C47E98E69AFB  I'm a gree because if we are enthusiasm is pro...   \n3     405CEC6E7F5D  Do you ever wonder if we should choose our own...   \n4     0E03218FDD2F  Educators say that students should have shorte...   \n...            ...                                                ...   \n3906  3651697D855B  FAILURE PLAYS IN THE PURSUIT OF SUCCESS.\\n\\nI ...   \n3907  1928846BB272  I believe that is good idea for the students t...   \n3908  2157AE4AFAA6  I agree that people make their own decisions t...   \n3909  30B9B18CCCC2  I believe technology is good thing because you...   \n3910  0E6BB199BF93  The principal is saying that the students must...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  kfold  \n0          2.5     2.5         3.0          3.0      3.0          3.0      1  \n1          3.5     3.5         3.5          3.5      3.5          3.5      2  \n2          2.5     2.0         2.5          2.5      2.5          2.5      3  \n3          3.0     3.5         4.0          3.5      3.5          3.5      4  \n4          4.0     4.5         4.0          5.0      5.0          5.0      5  \n...        ...     ...         ...          ...      ...          ...    ...  \n3906       3.5     3.0         4.0          3.5      3.0          3.5      2  \n3907       3.0     2.5         3.0          2.0      2.5          3.0      5  \n3908       4.0     4.0         3.5          3.5      3.0          3.0      4  \n3909       2.5     2.5         2.0          3.0      2.5          2.0      3  \n3910       2.0     3.0         3.0          3.0      2.5          3.0      4  \n\n[3911 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>94EC7DF6EA74</td>\n      <td>People these days dont go outdoors as much as ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B204869FA146</td>\n      <td>Is technology a positive or negative effect on...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C47E98E69AFB</td>\n      <td>I'm a gree because if we are enthusiasm is pro...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>405CEC6E7F5D</td>\n      <td>Do you ever wonder if we should choose our own...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0E03218FDD2F</td>\n      <td>Educators say that students should have shorte...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>3651697D855B</td>\n      <td>FAILURE PLAYS IN THE PURSUIT OF SUCCESS.\\n\\nI ...</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>1928846BB272</td>\n      <td>I believe that is good idea for the students t...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>2157AE4AFAA6</td>\n      <td>I agree that people make their own decisions t...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>30B9B18CCCC2</td>\n      <td>I believe technology is good thing because you...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>0E6BB199BF93</td>\n      <td>The principal is saying that the students must...</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['kfold'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.199118Z","iopub.execute_input":"2022-11-29T18:01:21.199612Z","iopub.status.idle":"2022-11-29T18:01:21.213914Z","shell.execute_reply.started":"2022-11-29T18:01:21.199576Z","shell.execute_reply":"2022-11-29T18:01:21.212691Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1    782\n2    782\n3    782\n4    783\n5    782\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data process functions","metadata":{}},{"cell_type":"code","source":"def hf_encode(texts, chkpt):\n    \n    tokenizer = transformers.AutoTokenizer.from_pretrained(CONFIG[chkpt])\n    tokenizer.save_pretrained('./tokenizer/')\n\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=CONFIG['max_len'], \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.215835Z","iopub.execute_input":"2022-11-29T18:01:21.216502Z","iopub.status.idle":"2022-11-29T18:01:21.226320Z","shell.execute_reply.started":"2022-11-29T18:01:21.216465Z","shell.execute_reply":"2022-11-29T18:01:21.224925Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def pickle_dump(path, saveobj):\n    import pickle\n    filehandler = open(path,\"wb\")\n    pickle.dump(saveobj,filehandler)\n#     print(\"File pickled\")\n    filehandler.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.227866Z","iopub.execute_input":"2022-11-29T18:01:21.228520Z","iopub.status.idle":"2022-11-29T18:01:21.237606Z","shell.execute_reply.started":"2022-11-29T18:01:21.228478Z","shell.execute_reply":"2022-11-29T18:01:21.236592Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def pickle_load(path):\n    import pickle\n    file = open(path,'rb')\n    loadobj = pickle.load(file)\n    file.close()\n    return loadobj","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.239364Z","iopub.execute_input":"2022-11-29T18:01:21.239771Z","iopub.status.idle":"2022-11-29T18:01:21.249688Z","shell.execute_reply.started":"2022-11-29T18:01:21.239737Z","shell.execute_reply":"2022-11-29T18:01:21.248694Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Transformer embeddings","metadata":{}},{"cell_type":"code","source":"def pretrain_embeddings(chkpt, df):\n    cfg = transformers.AutoConfig.from_pretrained(CONFIG[chkpt], output_hidden_states=True)\n    cfg.hidden_dropout_prob = 0\n    cfg.attention_probs_dropout_prob = 0\n    cfg.save_pretrained('./tokenizer/')\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"attention_masks\"\n    )\n    \n    try:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg)\n    except:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg, from_pt=True)\n        \n    output = model(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = output.hidden_states\n    mean_pool = []\n    for hidden_s in hidden_states[-1:]:\n        #def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(attention_masks, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(hidden_s * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        tmp = embedding_sum / mask_sum\n        mean_pool.append(tmp)\n    output = tf.stack(mean_pool,axis=2)\n   \n    #output = tf.stack(\n    #    [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidd20000en_states[-1:]], \n    #    axis=2)\n    \n    output = tf.squeeze(output, axis=-1)\n    \n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n\n    model.compile(optimizer=\"adam\",\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    print(model.summary())\n    dataset = hf_encode(df['full_text'], chkpt)\n    preds = model.predict(dataset, batch_size=CONFIG['batch_size'])\n    \n    del model, dataset\n    _ = gc.collect()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.251433Z","iopub.execute_input":"2022-11-29T18:01:21.251849Z","iopub.status.idle":"2022-11-29T18:01:21.267338Z","shell.execute_reply.started":"2022-11-29T18:01:21.251813Z","shell.execute_reply":"2022-11-29T18:01:21.266365Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"#train_dataset = pretrain_embeddings('debertav3large', train)\n#train_dataset = np.concatenate([train_dataset, pretrain_embeddings('distilrobertabase', train)], axis=1)\n#train_dataset = np.concatenate([train_dataset, pretrain_embeddings('robertabase', train)], axis=1)\n#train_dataset = np.concatenate([train_dataset, pretrain_embeddings('robertalarge', train)], axis=1)\n#train_dataset = np.concatenate([train_dataset, pretrain_embeddings('debertav3base', train)], axis=1)\n#train_dataset.shape\n\n#train_dataset = np.load(CONFIG['debertav3large_npy'])\n#train_dataset = np.concatenate([train_dataset, np.load(CONFIG['distilrobertabase_npy'])], axis=1)\n\n#train_dataset.shape\n\ntrain_dataset = pretrain_embeddings('distilrobertabase', train)\n\n#test_dataset = np.concatenate([test_dataset, pretrain_embeddings('bertbasecased', test)], axis=1)\ntrain_dataset = np.concatenate([train_dataset, pretrain_embeddings('robertabase', train)], axis=1)\ntrain_dataset = np.concatenate([train_dataset, pretrain_embeddings('robertalarge', train)], axis=1)\n\ntrain_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:01:21.270806Z","iopub.execute_input":"2022-11-29T18:01:21.271287Z","iopub.status.idle":"2022-11-29T18:16:43.999165Z","shell.execute_reply.started":"2022-11-29T18:01:21.271244Z","shell.execute_reply":"2022-11-29T18:16:43.998150Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-11-29 18:01:21.525088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.526165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.527375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.528234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.529050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.529836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.531606: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-29 18:01:21.798414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.799311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.800088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.800818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.801592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:21.802365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.783463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.784408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.785248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.785995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.786732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.787435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-29 18:01:28.790859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 18:01:28.791593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast (TFOpLambda)            (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 512, 1)       0           tf.cast[0][0]                    \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 512, 768)     0           tf_roberta_model[0][6]           \n                                                                 tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 768)          0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\ntf.math.maximum (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv (TFOpLambda)    (None, 768)          0           tf.math.reduce_sum[0][0]         \n                                                                 tf.math.maximum[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 768, 1)       0           tf.math.truediv[0][0]            \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 768)          0           tf.stack[0][0]                   \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"2022-11-29 18:01:48.293260: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_1 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 512, 1)       0           tf.cast_1[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_1 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_1[0][12]        \n                                                                 tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_2 (TFOpLambd (None, 768)          0           tf.math.multiply_1[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_1 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_1 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_2[0][0]       \n                                                                 tf.math.maximum_1[0][0]          \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_1[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_1 (TFOpLam (None, 768)          0           tf.stack_1[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_2 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_2 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_2 (TFOpLambda)   (None, 512, 1)       0           tf.cast_2[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_2 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_2[0][24]        \n                                                                 tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_5 (TFOpLambd (None, 1)            0           tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_4 (TFOpLambd (None, 1024)         0           tf.math.multiply_2[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_2 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_5[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_2 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_4[0][0]       \n                                                                 tf.math.maximum_2[0][0]          \n__________________________________________________________________________________________________\ntf.stack_2 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_2[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_2 (TFOpLam (None, 1024)         0           tf.stack_2[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3911, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"scores = []\nrmse_scores = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('#'*25)\n    print(f'## Fold {fold}')\n    print('#'*25)\n\n    trn_idx = train[train['kfold']==fold].index.values\n    val_idx = train[train['kfold']!=fold].index.values\n    print(f\"trn_idx len is {len(trn_idx)}\")\n\n    X_train = train_dataset[trn_idx,:]\n    X_valid = train_dataset[val_idx,:]\n\n    y_train = train[train['kfold']==fold][tgtCols].copy()\n    y_valid = train[train['kfold']!=fold][tgtCols].copy()\n\n    val_preds = np.zeros((len(val_idx),6))\n\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        clf = SVR(C=1)\n        clf.fit(X_train, y_train[tgt].values)\n        pickle_dump(f\"./SVR_tgt{tgt}_fold{fold}.pkl\", clf)\n        val_preds[:,i] = clf.predict(X_valid)\n   \n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('#'*25)\n    print('Overall CV RMSE =',np.mean(scores))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:16:44.003577Z","iopub.execute_input":"2022-11-29T18:16:44.004899Z","iopub.status.idle":"2022-11-29T18:19:05.181884Z","shell.execute_reply.started":"2022-11-29T18:16:44.004861Z","shell.execute_reply":"2022-11-29T18:19:05.180603Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"#########################\n## Fold 1\n#########################\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.49369876658596223\n#########################\nOverall CV RMSE = 0.5003134915992332\n#########################\n## Fold 2\n#########################\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.4951160696311996\n#########################\nOverall CV RMSE = 0.49792241248174846\n#########################\n## Fold 3\n#########################\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4961517005707978\n#########################\nOverall CV RMSE = 0.4973920479731967\n#########################\n## Fold 4\n#########################\ntrn_idx len is 783\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4962169228261981\n#########################\nOverall CV RMSE = 0.4971057524276959\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_dataset\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:05.184203Z","iopub.execute_input":"2022-11-29T18:19:05.184934Z","iopub.status.idle":"2022-11-29T18:19:05.422328Z","shell.execute_reply.started":"2022-11-29T18:19:05.184890Z","shell.execute_reply":"2022-11-29T18:19:05.421302Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model inference","metadata":{}},{"cell_type":"code","source":"test_dataset = pretrain_embeddings('distilrobertabase', test)\n\n#test_dataset = np.concatenate([test_dataset, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_dataset = np.concatenate([test_dataset, pretrain_embeddings('robertabase', test)], axis=1)\ntest_dataset = np.concatenate([test_dataset, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:05.424075Z","iopub.execute_input":"2022-11-29T18:19:05.424420Z","iopub.status.idle":"2022-11-29T18:19:48.306236Z","shell.execute_reply.started":"2022-11-29T18:19:05.424386Z","shell.execute_reply":"2022-11-29T18:19:48.304910Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_3 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_3 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_3 (TFOpLambda)   (None, 512, 1)       0           tf.cast_3[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_3 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_3[0][6]         \n                                                                 tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_7 (TFOpLambd (None, 1)            0           tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_6 (TFOpLambd (None, 768)          0           tf.math.multiply_3[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_3 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_7[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_3 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_6[0][0]       \n                                                                 tf.math.maximum_3[0][0]          \n__________________________________________________________________________________________________\ntf.stack_3 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_3[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_3 (TFOpLam (None, 768)          0           tf.stack_3[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_4 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_4 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_4 (TFOpLambda)   (None, 512, 1)       0           tf.cast_4[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_4 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_4[0][12]        \n                                                                 tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_9 (TFOpLambd (None, 1)            0           tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_8 (TFOpLambd (None, 768)          0           tf.math.multiply_4[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_4 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_9[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_4 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_8[0][0]       \n                                                                 tf.math.maximum_4[0][0]          \n__________________________________________________________________________________________________\ntf.stack_4 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_4[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_4 (TFOpLam (None, 768)          0           tf.stack_4[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_5 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_5 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_5 (TFOpLambda)   (None, 512, 1)       0           tf.cast_5[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_5 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_5[0][24]        \n                                                                 tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_11 (TFOpLamb (None, 1)            0           tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_10 (TFOpLamb (None, 1024)         0           tf.math.multiply_5[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_5 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_11[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_5 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_10[0][0]      \n                                                                 tf.math.maximum_5[0][0]          \n__________________________________________________________________________________________________\ntf.stack_5 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_5[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_5 (TFOpLam (None, 1024)         0           tf.stack_5[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(9, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('#'*25)\n    print(f'## Fold {fold}')\n    print('#'*25)\n    \n    test_preds = np.zeros((len(test_dataset),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_dataset)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('#'*25)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:48.307724Z","iopub.execute_input":"2022-11-29T18:19:48.310702Z","iopub.status.idle":"2022-11-29T18:19:49.788815Z","shell.execute_reply.started":"2022-11-29T18:19:48.310672Z","shell.execute_reply":"2022-11-29T18:19:49.787810Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"#########################\n## Fold 1\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4962560561794383\n#########################\nOverall CV RMSE = 0.49693927187921205\n#########################\n## Fold 2\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.4962821450815984\n#########################\nOverall CV RMSE = 0.49683161164700007\n#########################\n## Fold 3\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4963007800117128\n#########################\nOverall CV RMSE = 0.4967568860930437\n#########################\n## Fold 4\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4963147562092985\n#########################\nOverall CV RMSE = 0.4967023280817002\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.790506Z","iopub.execute_input":"2022-11-29T18:19:49.790912Z","iopub.status.idle":"2022-11-29T18:19:49.799190Z","shell.execute_reply.started":"2022-11-29T18:19:49.790873Z","shell.execute_reply":"2022-11-29T18:19:49.798106Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.800761Z","iopub.execute_input":"2022-11-29T18:19:49.802086Z","iopub.status.idle":"2022-11-29T18:19:49.817724Z","shell.execute_reply.started":"2022-11-29T18:19:49.802023Z","shell.execute_reply":"2022-11-29T18:19:49.816633Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   index       text_id\n0      0  0000C359D63E\n1      1  000BAD50D026\n2      2  00367BB2546B\n3      3            hp\n4      4           tkm\n5      5            va\n6      6            ll\n7      7            sp\n8      8            bp","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0000C359D63E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000BAD50D026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>00367BB2546B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>hp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>tkm</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>va</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>ll</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>sp</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>bp</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.819291Z","iopub.execute_input":"2022-11-29T18:19:49.819659Z","iopub.status.idle":"2022-11-29T18:19:49.835685Z","shell.execute_reply.started":"2022-11-29T18:19:49.819623Z","shell.execute_reply":"2022-11-29T18:19:49.834441Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0  2.868558  2.723777    3.030499     2.867313  2.655197     2.683695\n1  2.809209  2.584355    2.831141     2.611344  2.397681     2.666667\n2  3.354055  3.251415    3.450730     3.396637  3.267125     3.292837\n3  3.310319  3.251588    3.468873     3.384124  3.322744     3.133408\n4  3.539252  3.475078    3.670111     3.583570  3.504443     3.409015\n5  3.620723  3.510035    3.749914     3.576289  3.472366     3.497090\n6  3.449240  3.376074    3.614669     3.495952  3.402741     3.243361\n7  2.987999  2.878710    3.231297     2.989895  2.841649     2.683772\n8  3.516936  3.425442    3.695985     3.536321  3.416549     3.346942","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.868558</td>\n      <td>2.723777</td>\n      <td>3.030499</td>\n      <td>2.867313</td>\n      <td>2.655197</td>\n      <td>2.683695</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.809209</td>\n      <td>2.584355</td>\n      <td>2.831141</td>\n      <td>2.611344</td>\n      <td>2.397681</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.354055</td>\n      <td>3.251415</td>\n      <td>3.450730</td>\n      <td>3.396637</td>\n      <td>3.267125</td>\n      <td>3.292837</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.310319</td>\n      <td>3.251588</td>\n      <td>3.468873</td>\n      <td>3.384124</td>\n      <td>3.322744</td>\n      <td>3.133408</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.539252</td>\n      <td>3.475078</td>\n      <td>3.670111</td>\n      <td>3.583570</td>\n      <td>3.504443</td>\n      <td>3.409015</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.620723</td>\n      <td>3.510035</td>\n      <td>3.749914</td>\n      <td>3.576289</td>\n      <td>3.472366</td>\n      <td>3.497090</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.449240</td>\n      <td>3.376074</td>\n      <td>3.614669</td>\n      <td>3.495952</td>\n      <td>3.402741</td>\n      <td>3.243361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.987999</td>\n      <td>2.878710</td>\n      <td>3.231297</td>\n      <td>2.989895</td>\n      <td>2.841649</td>\n      <td>2.683772</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.516936</td>\n      <td>3.425442</td>\n      <td>3.695985</td>\n      <td>3.536321</td>\n      <td>3.416549</td>\n      <td>3.346942</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.837255Z","iopub.execute_input":"2022-11-29T18:19:49.838534Z","iopub.status.idle":"2022-11-29T18:19:49.859762Z","shell.execute_reply.started":"2022-11-29T18:19:49.838494Z","shell.execute_reply":"2022-11-29T18:19:49.858706Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.868558  2.723777    3.030499     2.867313  2.655197   \n1  000BAD50D026  2.809209  2.584355    2.831141     2.611344  2.397681   \n2  00367BB2546B  3.354055  3.251415    3.450730     3.396637  3.267125   \n3            hp  3.310319  3.251588    3.468873     3.384124  3.322744   \n4           tkm  3.539252  3.475078    3.670111     3.583570  3.504443   \n5            va  3.620723  3.510035    3.749914     3.576289  3.472366   \n6            ll  3.449240  3.376074    3.614669     3.495952  3.402741   \n7            sp  2.987999  2.878710    3.231297     2.989895  2.841649   \n8            bp  3.516936  3.425442    3.695985     3.536321  3.416549   \n\n   conventions  \n0     2.683695  \n1     2.666667  \n2     3.292837  \n3     3.133408  \n4     3.409015  \n5     3.497090  \n6     3.243361  \n7     2.683772  \n8     3.346942  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.868558</td>\n      <td>2.723777</td>\n      <td>3.030499</td>\n      <td>2.867313</td>\n      <td>2.655197</td>\n      <td>2.683695</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.809209</td>\n      <td>2.584355</td>\n      <td>2.831141</td>\n      <td>2.611344</td>\n      <td>2.397681</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.354055</td>\n      <td>3.251415</td>\n      <td>3.450730</td>\n      <td>3.396637</td>\n      <td>3.267125</td>\n      <td>3.292837</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp</td>\n      <td>3.310319</td>\n      <td>3.251588</td>\n      <td>3.468873</td>\n      <td>3.384124</td>\n      <td>3.322744</td>\n      <td>3.133408</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tkm</td>\n      <td>3.539252</td>\n      <td>3.475078</td>\n      <td>3.670111</td>\n      <td>3.583570</td>\n      <td>3.504443</td>\n      <td>3.409015</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>va</td>\n      <td>3.620723</td>\n      <td>3.510035</td>\n      <td>3.749914</td>\n      <td>3.576289</td>\n      <td>3.472366</td>\n      <td>3.497090</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ll</td>\n      <td>3.449240</td>\n      <td>3.376074</td>\n      <td>3.614669</td>\n      <td>3.495952</td>\n      <td>3.402741</td>\n      <td>3.243361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sp</td>\n      <td>2.987999</td>\n      <td>2.878710</td>\n      <td>3.231297</td>\n      <td>2.989895</td>\n      <td>2.841649</td>\n      <td>2.683772</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>bp</td>\n      <td>3.516936</td>\n      <td>3.425442</td>\n      <td>3.695985</td>\n      <td>3.536321</td>\n      <td>3.416549</td>\n      <td>3.346942</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running SVR after TF-IDF","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error as mse\nimport math\nfrom sklearn.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.861507Z","iopub.execute_input":"2022-11-29T18:19:49.861925Z","iopub.status.idle":"2022-11-29T18:19:49.939949Z","shell.execute_reply.started":"2022-11-29T18:19:49.861888Z","shell.execute_reply":"2022-11-29T18:19:49.939049Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Running for the train full_text with training all\n# fit the six test as test\nfull_df = np.concatenate((train.full_text.values,test.full_text.values))","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.941508Z","iopub.execute_input":"2022-11-29T18:19:49.941889Z","iopub.status.idle":"2022-11-29T18:19:49.947058Z","shell.execute_reply.started":"2022-11-29T18:19:49.941852Z","shell.execute_reply":"2022-11-29T18:19:49.945960Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"tfidf_featurizer = TfidfVectorizer(max_features=10000, max_df=0.95, stop_words='english')\nX_tfidf = tfidf_featurizer.fit_transform(full_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:49.948533Z","iopub.execute_input":"2022-11-29T18:19:49.949148Z","iopub.status.idle":"2022-11-29T18:19:51.070838Z","shell.execute_reply.started":"2022-11-29T18:19:49.949111Z","shell.execute_reply":"2022-11-29T18:19:51.069761Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# SPLIT DATA\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf[0:len(train.full_text)], \n                                                    train[tgtCols].values,\n                                                    test_size=0.10,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.075807Z","iopub.execute_input":"2022-11-29T18:19:51.078009Z","iopub.status.idle":"2022-11-29T18:19:51.092215Z","shell.execute_reply.started":"2022-11-29T18:19:51.077970Z","shell.execute_reply":"2022-11-29T18:19:51.091268Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.096982Z","iopub.execute_input":"2022-11-29T18:19:51.099432Z","iopub.status.idle":"2022-11-29T18:19:51.107761Z","shell.execute_reply.started":"2022-11-29T18:19:51.099397Z","shell.execute_reply":"2022-11-29T18:19:51.106895Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"(3519, 10000)\n(392, 10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = {'C' : 5, \n                'epsilon': 0.1, \n                'gamma' : 1, \n                'kernel' : 'rbf'} ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.111957Z","iopub.execute_input":"2022-11-29T18:19:51.114329Z","iopub.status.idle":"2022-11-29T18:19:51.120425Z","shell.execute_reply.started":"2022-11-29T18:19:51.114285Z","shell.execute_reply":"2022-11-29T18:19:51.119457Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"data_test = X_tfidf[len(train.full_text):]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.122811Z","iopub.execute_input":"2022-11-29T18:19:51.123448Z","iopub.status.idle":"2022-11-29T18:19:51.132577Z","shell.execute_reply.started":"2022-11-29T18:19:51.123414Z","shell.execute_reply":"2022-11-29T18:19:51.131575Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#  \ndf_sum = pd.DataFrame([],index=test.text_id,columns= tgtCols)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.133970Z","iopub.execute_input":"2022-11-29T18:19:51.134736Z","iopub.status.idle":"2022-11-29T18:19:51.147782Z","shell.execute_reply.started":"2022-11-29T18:19:51.134695Z","shell.execute_reply":"2022-11-29T18:19:51.146932Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nrerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(X_test)\n  rerror.append(mse(rf_preds,y_test[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:19:51.149904Z","iopub.execute_input":"2022-11-29T18:19:51.150515Z","iopub.status.idle":"2022-11-29T18:20:54.121674Z","shell.execute_reply.started":"2022-11-29T18:19:51.150481Z","shell.execute_reply":"2022-11-29T18:20:54.120547Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.5395478005692772\n","output_type":"stream"}]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(data_test)\n  df_sum[tgtCols[k]] = rf_preds\n  #error.append(rmse(rf_preds,y_test[:,k],squared=False))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:20:54.123476Z","iopub.execute_input":"2022-11-29T18:20:54.123903Z","iopub.status.idle":"2022-11-29T18:21:51.259663Z","shell.execute_reply.started":"2022-11-29T18:20:54.123854Z","shell.execute_reply":"2022-11-29T18:21:51.258633Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-29T18:21:51.261332Z","iopub.execute_input":"2022-11-29T18:21:51.262081Z","iopub.status.idle":"2022-11-29T18:21:51.282843Z","shell.execute_reply.started":"2022-11-29T18:21:51.262042Z","shell.execute_reply":"2022-11-29T18:21:51.281884Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"              cohesion    syntax  vocabulary  phraseology   grammar  \\\ntext_id                                                               \n0000C359D63E  2.884783  2.878270    3.206788     3.080244  2.690300   \n000BAD50D026  3.011864  2.715047    2.910967     2.601530  2.606945   \n00367BB2546B  3.379000  3.427497    3.500803     3.390947  3.323504   \nhp            2.739642  2.697657    2.989489     2.872468  2.830054   \ntkm           2.824272  2.766787    2.995233     2.877292  2.892813   \nva            3.124648  2.946333    3.352755     3.092867  3.102044   \nll            2.965974  2.968808    3.134421     3.019536  3.063529   \nsp            2.741590  2.750508    2.991412     2.947629  2.959438   \nbp            2.837431  2.776432    3.090797     2.986388  2.916751   \n\n              conventions  \ntext_id                    \n0000C359D63E     2.805317  \n000BAD50D026     2.941732  \n00367BB2546B     3.313027  \nhp               2.769279  \ntkm              2.754630  \nva               3.007873  \nll               2.894689  \nsp               2.751547  \nbp               2.871064  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n    <tr>\n      <th>text_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000C359D63E</th>\n      <td>2.884783</td>\n      <td>2.878270</td>\n      <td>3.206788</td>\n      <td>3.080244</td>\n      <td>2.690300</td>\n      <td>2.805317</td>\n    </tr>\n    <tr>\n      <th>000BAD50D026</th>\n      <td>3.011864</td>\n      <td>2.715047</td>\n      <td>2.910967</td>\n      <td>2.601530</td>\n      <td>2.606945</td>\n      <td>2.941732</td>\n    </tr>\n    <tr>\n      <th>00367BB2546B</th>\n      <td>3.379000</td>\n      <td>3.427497</td>\n      <td>3.500803</td>\n      <td>3.390947</td>\n      <td>3.323504</td>\n      <td>3.313027</td>\n    </tr>\n    <tr>\n      <th>hp</th>\n      <td>2.739642</td>\n      <td>2.697657</td>\n      <td>2.989489</td>\n      <td>2.872468</td>\n      <td>2.830054</td>\n      <td>2.769279</td>\n    </tr>\n    <tr>\n      <th>tkm</th>\n      <td>2.824272</td>\n      <td>2.766787</td>\n      <td>2.995233</td>\n      <td>2.877292</td>\n      <td>2.892813</td>\n      <td>2.754630</td>\n    </tr>\n    <tr>\n      <th>va</th>\n      <td>3.124648</td>\n      <td>2.946333</td>\n      <td>3.352755</td>\n      <td>3.092867</td>\n      <td>3.102044</td>\n      <td>3.007873</td>\n    </tr>\n    <tr>\n      <th>ll</th>\n      <td>2.965974</td>\n      <td>2.968808</td>\n      <td>3.134421</td>\n      <td>3.019536</td>\n      <td>3.063529</td>\n      <td>2.894689</td>\n    </tr>\n    <tr>\n      <th>sp</th>\n      <td>2.741590</td>\n      <td>2.750508</td>\n      <td>2.991412</td>\n      <td>2.947629</td>\n      <td>2.959438</td>\n      <td>2.751547</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>2.837431</td>\n      <td>2.776432</td>\n      <td>3.090797</td>\n      <td>2.986388</td>\n      <td>2.916751</td>\n      <td>2.871064</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}