{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DataCollatorWithPadding\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nfrom datasets import Dataset\n\nimport os\nimport gc\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:50.798296Z","iopub.execute_input":"2022-11-29T19:21:50.798611Z","iopub.status.idle":"2022-11-29T19:21:53.746669Z","shell.execute_reply.started":"2022-11-29T19:21:50.798536Z","shell.execute_reply":"2022-11-29T19:21:53.745700Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n        'folds': 5,\n        'seed': 101,\n        'robertabase': '../input/huggingface-roberta-variants/roberta-base/roberta-base',\n        'robertalarge': '../input/huggingface-roberta-variants/roberta-large/roberta-large',\n        #'debertav3base': '../input/debertav3base',\n        #'debertav3large': '../input/deberta-v3-large/deberta-v3-large/',\n        'xlmrobertabase': '../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base',\n        'distilrobertabase': '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base',\n        #'debertav3large_npy': '../input/fb3-save-pretrained-embeddings/debertav3large_FB3.npy',\n        #'distilrobertabase_npy': '../input/fb3-save-pretrained-embeddings/distilrobertabase_FB3.npy',\n\n        'batch_size': 4,\n        'max_len': 512\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.748285Z","iopub.execute_input":"2022-11-29T19:21:53.749063Z","iopub.status.idle":"2022-11-29T19:21:53.755351Z","shell.execute_reply.started":"2022-11-29T19:21:53.749024Z","shell.execute_reply":"2022-11-29T19:21:53.754179Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read in data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.757171Z","iopub.execute_input":"2022-11-29T19:21:53.757692Z","iopub.status.idle":"2022-11-29T19:21:53.793253Z","shell.execute_reply.started":"2022-11-29T19:21:53.757652Z","shell.execute_reply":"2022-11-29T19:21:53.792377Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv(\"/kaggle/input/large580/train_20000.csv\")\n#msk = np.random.rand(len(df)) <= 0.9\n#tgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = df[msk].dropna()\n#test = df[~msk].dropna()\n#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.796448Z","iopub.execute_input":"2022-11-29T19:21:53.796995Z","iopub.status.idle":"2022-11-29T19:21:53.801493Z","shell.execute_reply.started":"2022-11-29T19:21:53.796968Z","shell.execute_reply":"2022-11-29T19:21:53.800429Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\n#test = pd.read_csv(\"/kaggle/input/580data/test.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test_balanced.csv\")\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = train[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\n#test = test[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\nprint(train.shape)\nprint(test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.803155Z","iopub.execute_input":"2022-11-29T19:21:53.803844Z","iopub.status.idle":"2022-11-29T19:21:53.925395Z","shell.execute_reply.started":"2022-11-29T19:21:53.803808Z","shell.execute_reply":"2022-11-29T19:21:53.924414Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(3911, 8)\n(783, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.928485Z","iopub.execute_input":"2022-11-29T19:21:53.928791Z","iopub.status.idle":"2022-11-29T19:21:53.959308Z","shell.execute_reply.started":"2022-11-29T19:21:53.928763Z","shell.execute_reply":"2022-11-29T19:21:53.958093Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0       text_id  \\\n0           272  13C400DD9794   \n1          3051  D9BC7F4F22F0   \n2           800  3E170458E9A1   \n3          3206  E0BFF1488787   \n4          2664  C50BE3C76571   \n..          ...           ...   \n778        2207  A4A90A401002   \n779        2747  CA11FD3CAC43   \n780         155  0BB9FAE6E27B   \n781        3464  ED0A8E614649   \n782        2318  ACA1A45EE438   \n\n                                             full_text  cohesion  syntax  \\\n0    The year book is for to not forget anything an...       2.0     2.0   \n1    Well what i think about praising for a student...       2.5     2.5   \n2    I\\n\\ndisagree that first impressions are almos...       2.0     2.0   \n3    I disagree with schools having a program with ...       2.5     2.0   \n4    I dont like becuase the student forget all inf...       3.0     2.5   \n..                                                 ...       ...     ...   \n778  People who value self-reliance define it as th...       3.0     3.5   \n779  Many people have been told about the fact that...       4.5     4.0   \n780  Setting A Good Example\\n\\nHave you thought of ...       3.5     4.0   \n781  Techonology has becoming powerful that let stu...       4.5     3.5   \n782  I strongly disagree with extending the school ...       4.0     3.0   \n\n     vocabulary  phraseology  grammar  conventions  average  bin  \n0           2.0          2.0      2.0          2.0      2.0    0  \n1           2.5          3.0      2.5          2.0      2.5    0  \n2           2.0          2.0      2.0          2.5      2.1    0  \n3           2.5          2.0      2.0          2.5      2.3    0  \n4           2.0          2.0      2.0          2.5      2.4    0  \n..          ...          ...      ...          ...      ...  ...  \n778         3.5          4.0      3.5          4.0      3.6    2  \n779         3.5          4.0      3.5          3.5      3.9    2  \n780         4.5          4.0      3.5          3.5      3.9    2  \n781         4.0          4.0      4.0          3.5      3.9    2  \n782         3.0          4.0      4.0          4.0      3.6    2  \n\n[783 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>average</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272</td>\n      <td>13C400DD9794</td>\n      <td>The year book is for to not forget anything an...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3051</td>\n      <td>D9BC7F4F22F0</td>\n      <td>Well what i think about praising for a student...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>800</td>\n      <td>3E170458E9A1</td>\n      <td>I\\n\\ndisagree that first impressions are almos...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3206</td>\n      <td>E0BFF1488787</td>\n      <td>I disagree with schools having a program with ...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2664</td>\n      <td>C50BE3C76571</td>\n      <td>I dont like becuase the student forget all inf...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>2207</td>\n      <td>A4A90A401002</td>\n      <td>People who value self-reliance define it as th...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>2747</td>\n      <td>CA11FD3CAC43</td>\n      <td>Many people have been told about the fact that...</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>155</td>\n      <td>0BB9FAE6E27B</td>\n      <td>Setting A Good Example\\n\\nHave you thought of ...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3464</td>\n      <td>ED0A8E614649</td>\n      <td>Techonology has becoming powerful that let stu...</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>2318</td>\n      <td>ACA1A45EE438</td>\n      <td>I strongly disagree with extending the school ...</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"my_list = train.columns.values.tolist()\nmy_list","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.961205Z","iopub.execute_input":"2022-11-29T19:21:53.961606Z","iopub.status.idle":"2022-11-29T19:21:53.971619Z","shell.execute_reply.started":"2022-11-29T19:21:53.961547Z","shell.execute_reply":"2022-11-29T19:21:53.970462Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['text_id',\n 'full_text',\n 'cohesion',\n 'syntax',\n 'vocabulary',\n 'phraseology',\n 'grammar',\n 'conventions']"},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.973174Z","iopub.execute_input":"2022-11-29T19:21:53.973710Z","iopub.status.idle":"2022-11-29T19:21:53.996932Z","shell.execute_reply.started":"2022-11-29T19:21:53.973672Z","shell.execute_reply":"2022-11-29T19:21:53.995549Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     0016926B079C  I think that students would benefit from learn...   \n1     0022683E9EA5  When a problem is a change you have to let it ...   \n2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n3     003885A45F42  The best time in life is when you become yours...   \n4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n...            ...                                                ...   \n3906  FFD29828A873  I believe using cellphones in class for educat...   \n3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n0          3.5     3.5         3.0          3.0      4.0          3.0  \n1          2.5     2.5         3.0          2.0      2.0          2.5  \n2          3.0     3.5         3.0          3.0      3.0          2.5  \n3          4.5     4.5         4.5          4.5      4.0          5.0  \n4          2.5     3.0         3.0          3.0      2.5          2.5  \n...        ...     ...         ...          ...      ...          ...  \n3906       2.5     3.0         3.0          3.5      2.5          2.5  \n3907       4.0     4.0         4.0          4.0      3.5          3.0  \n3908       2.5     3.0         3.0          3.0      3.5          3.0  \n3909       4.0     4.5         4.5          4.0      4.5          4.5  \n3910       3.5     2.5         3.5          3.0      3.0          3.5  \n\n[3911 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FFD29828A873</td>\n      <td>I believe using cellphones in class for educat...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>FFD9A83B0849</td>\n      <td>Working alone, students do not have to argue w...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>FFDC4011AC9C</td>\n      <td>\"A problem is a chance for you to do your best...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>FFE16D704B16</td>\n      <td>Many people disagree with Albert Schweitzer's ...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>FFED00D6E0BD</td>\n      <td>Do you think that failure is the main thing fo...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create folds","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'kfold'] = -1 # Create a new column `fold` containing `-1`s.\ntrain = train.sample(frac=1).reset_index(drop=True) # Shuffle the rows.\ndata_labels = train[tgtCols].values","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:53.998839Z","iopub.execute_input":"2022-11-29T19:21:53.999619Z","iopub.status.idle":"2022-11-29T19:21:54.011990Z","shell.execute_reply.started":"2022-11-29T19:21:53.999548Z","shell.execute_reply":"2022-11-29T19:21:54.010658Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.014104Z","iopub.execute_input":"2022-11-29T19:21:54.015080Z","iopub.status.idle":"2022-11-29T19:21:54.027139Z","shell.execute_reply.started":"2022-11-29T19:21:54.015035Z","shell.execute_reply":"2022-11-29T19:21:54.025820Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor f, (t, v) in enumerate(mskf.split(X=train, y=data_labels)):\n    train.loc[v, 'kfold'] = f + 1","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.028365Z","iopub.execute_input":"2022-11-29T19:21:54.030663Z","iopub.status.idle":"2022-11-29T19:21:54.217178Z","shell.execute_reply.started":"2022-11-29T19:21:54.030614Z","shell.execute_reply":"2022-11-29T19:21:54.216003Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.218618Z","iopub.execute_input":"2022-11-29T19:21:54.219057Z","iopub.status.idle":"2022-11-29T19:21:54.243910Z","shell.execute_reply.started":"2022-11-29T19:21:54.219009Z","shell.execute_reply":"2022-11-29T19:21:54.242546Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     EEE6067CF9B5  Some schools have programs that older kids can...   \n1     E1ACA6A0198E  Hi, my name is Generic_Name and I am intereste...   \n2     1202062A4FA5  Just like some businesses schools should adopt...   \n3     424005E31A04  Do people ever told that having a positive att...   \n4     ED40DCB2F669  Do you think is a good idea for student to ide...   \n...            ...                                                ...   \n3906  E8257C027079  Is true that many students would like to gradu...   \n3907  4800E073664A  I do agree with what Ralph Emerson wrote. Bein...   \n3908  D36CCF111F86  A positive attitude is more helpful to others ...   \n3909  7373B4F44528  Have you ever accomplished something in your l...   \n3910  A394468CDEC1  Do you think getting advice from more that one...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  kfold  \n0          2.0     2.0         2.5          2.5      2.5          2.5      1  \n1          3.5     3.5         3.5          4.0      4.5          3.5      4  \n2          4.0     3.5         3.5          3.5      2.5          3.5      5  \n3          3.0     4.0         4.0          3.0      3.0          3.0      3  \n4          3.0     3.0         3.5          3.5      3.5          3.5      2  \n...        ...     ...         ...          ...      ...          ...    ...  \n3906       3.0     3.0         3.0          3.0      3.5          3.0      1  \n3907       3.5     4.0         4.0          4.5      4.5          4.5      5  \n3908       3.5     4.0         4.0          3.5      4.0          3.0      3  \n3909       4.0     4.0         4.0          4.0      3.5          3.5      2  \n3910       3.5     4.0         3.5          4.0      3.5          3.5      3  \n\n[3911 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EEE6067CF9B5</td>\n      <td>Some schools have programs that older kids can...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E1ACA6A0198E</td>\n      <td>Hi, my name is Generic_Name and I am intereste...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1202062A4FA5</td>\n      <td>Just like some businesses schools should adopt...</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>424005E31A04</td>\n      <td>Do people ever told that having a positive att...</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ED40DCB2F669</td>\n      <td>Do you think is a good idea for student to ide...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>E8257C027079</td>\n      <td>Is true that many students would like to gradu...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>4800E073664A</td>\n      <td>I do agree with what Ralph Emerson wrote. Bein...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>D36CCF111F86</td>\n      <td>A positive attitude is more helpful to others ...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>7373B4F44528</td>\n      <td>Have you ever accomplished something in your l...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>A394468CDEC1</td>\n      <td>Do you think getting advice from more that one...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['kfold'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.250975Z","iopub.execute_input":"2022-11-29T19:21:54.251273Z","iopub.status.idle":"2022-11-29T19:21:54.260145Z","shell.execute_reply.started":"2022-11-29T19:21:54.251245Z","shell.execute_reply":"2022-11-29T19:21:54.259017Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1    782\n2    782\n3    783\n4    782\n5    782\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data process functions","metadata":{}},{"cell_type":"code","source":"def self_encode(texts, chkpt):\n    \n    tokenizer = transformers.AutoTokenizer.from_pretrained(CONFIG[chkpt])\n    tokenizer.save_pretrained('./tokenizer/')\n\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=CONFIG['max_len'], \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.261571Z","iopub.execute_input":"2022-11-29T19:21:54.262632Z","iopub.status.idle":"2022-11-29T19:21:54.273028Z","shell.execute_reply.started":"2022-11-29T19:21:54.262593Z","shell.execute_reply":"2022-11-29T19:21:54.271946Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def pickle_dump(path, saveobj):\n    import pickle\n    handler = open(path,\"wb\")\n    pickle.dump(saveobj,handler)\n#     print(\"File pickled\")\n    handler.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.274965Z","iopub.execute_input":"2022-11-29T19:21:54.275564Z","iopub.status.idle":"2022-11-29T19:21:54.290967Z","shell.execute_reply.started":"2022-11-29T19:21:54.275523Z","shell.execute_reply":"2022-11-29T19:21:54.290019Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def pickle_load(path):\n    import pickle\n    file = open(path,'rb')\n    loader = pickle.load(file)\n    file.close()\n    return loader","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.294464Z","iopub.execute_input":"2022-11-29T19:21:54.294788Z","iopub.status.idle":"2022-11-29T19:21:54.303200Z","shell.execute_reply.started":"2022-11-29T19:21:54.294762Z","shell.execute_reply":"2022-11-29T19:21:54.302324Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Transformer embeddings","metadata":{}},{"cell_type":"code","source":"def pretrain_embeddings(chkpt, df):\n    cfg = transformers.AutoConfig.from_pretrained(CONFIG[chkpt], output_hidden_states=True)\n    cfg.hidden_dropout_prob = 0\n    cfg.attention_probs_dropout_prob = 0\n    cfg.save_pretrained('./tokenizer/')\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"attention_masks\"\n    )\n    \n    try:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg)\n    except:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg, from_pt=True)\n        \n    output = model(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = output.hidden_states\n    mean_pool = []\n    for hidden_s in hidden_states[-1:]:\n        #def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(attention_masks, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(hidden_s * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        tmp = embedding_sum / mask_sum\n        mean_pool.append(tmp)\n    output = tf.stack(mean_pool,axis=2)\n   \n    #output = tf.stack(\n    #    [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidd20000en_states[-1:]], \n    #    axis=2)\n    \n    output = tf.squeeze(output, axis=-1)\n    \n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n\n    model.compile(optimizer=\"adam\",\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    print(model.summary())\n    dataset = self_encode(df['full_text'], chkpt)\n    preds = model.predict(dataset, batch_size=CONFIG['batch_size'])\n    \n    del model, dataset\n    _ = gc.collect()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.304728Z","iopub.execute_input":"2022-11-29T19:21:54.305360Z","iopub.status.idle":"2022-11-29T19:21:54.319664Z","shell.execute_reply.started":"2022-11-29T19:21:54.305324Z","shell.execute_reply":"2022-11-29T19:21:54.318651Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"\ntrain_data = pretrain_embeddings('distilrobertabase', train)\n\n#train_data = np.concatenate([train_data, pretrain_embeddings('bertbasecased', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertabase', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertalarge', train)], axis=1)\n\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:21:54.322241Z","iopub.execute_input":"2022-11-29T19:21:54.323834Z","iopub.status.idle":"2022-11-29T19:36:35.627950Z","shell.execute_reply.started":"2022-11-29T19:21:54.323798Z","shell.execute_reply":"2022-11-29T19:36:35.626934Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-11-29 19:21:54.478286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.479255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.480261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.481030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.481776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.482567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.483924: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-29 19:21:54.717358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.718267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.719111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.719846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.720545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:54.721240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.834644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.835604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.836444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.837254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.838043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.838691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-29 19:21:58.839206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:21:58.839886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast (TFOpLambda)            (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 512, 1)       0           tf.cast[0][0]                    \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 512, 768)     0           tf_roberta_model[0][6]           \n                                                                 tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 768)          0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\ntf.math.maximum (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv (TFOpLambda)    (None, 768)          0           tf.math.reduce_sum[0][0]         \n                                                                 tf.math.maximum[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 768, 1)       0           tf.math.truediv[0][0]            \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 768)          0           tf.stack[0][0]                   \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"2022-11-29 19:22:16.843338: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_1 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 512, 1)       0           tf.cast_1[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_1 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_1[0][12]        \n                                                                 tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_2 (TFOpLambd (None, 768)          0           tf.math.multiply_1[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_1 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_1 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_2[0][0]       \n                                                                 tf.math.maximum_1[0][0]          \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_1[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_1 (TFOpLam (None, 768)          0           tf.stack_1[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_2 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_2 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_2 (TFOpLambda)   (None, 512, 1)       0           tf.cast_2[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_2 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_2[0][24]        \n                                                                 tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_5 (TFOpLambd (None, 1)            0           tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_4 (TFOpLambd (None, 1024)         0           tf.math.multiply_2[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_2 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_5[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_2 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_4[0][0]       \n                                                                 tf.math.maximum_2[0][0]          \n__________________________________________________________________________________________________\ntf.stack_2 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_2[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_2 (TFOpLam (None, 1024)         0           tf.stack_2[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3911, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"scores = []\nrmse_scores = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n\n    trn_idx = train[train['kfold']==fold].index.values\n    val_idx = train[train['kfold']!=fold].index.values\n    print(f\"trn_idx len is {len(trn_idx)}\")\n\n    X_train = train_data[trn_idx,:]\n    X_valid = train_data[val_idx,:]\n\n    y_train = train[train['kfold']==fold][tgtCols].copy()\n    y_valid = train[train['kfold']!=fold][tgtCols].copy()\n\n    val_preds = np.zeros((len(val_idx),6))\n\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        clf = SVR(C=10)\n        clf.fit(X_train, y_train[tgt].values)\n        pickle_dump(f\"./SVR_tgt{tgt}_fold{fold}.pkl\", clf)\n        val_preds[:,i] = clf.predict(X_valid)\n   \n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:36:35.632430Z","iopub.execute_input":"2022-11-29T19:36:35.635303Z","iopub.status.idle":"2022-11-29T19:38:52.195906Z","shell.execute_reply.started":"2022-11-29T19:36:35.635263Z","shell.execute_reply":"2022-11-29T19:38:52.194357Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.46942960118423777\n-----------------------------------\nOverall CV RMSE = 0.47624303859100076\n-----------------------------------\n## Fold 2\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.4709666049802175\n-----------------------------------\nOverall CV RMSE = 0.47409965851822705\n-----------------------------------\n## Fold 3\n-----------------------------------\ntrn_idx len is 783\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.47143713770279333\n-----------------------------------\nOverall CV RMSE = 0.47327702899598695\n-----------------------------------\n## Fold 4\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4705403365135503\n-----------------------------------\nOverall CV RMSE = 0.47277805977151416\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_data\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:38:52.200946Z","iopub.execute_input":"2022-11-29T19:38:52.203263Z","iopub.status.idle":"2022-11-29T19:38:52.497910Z","shell.execute_reply.started":"2022-11-29T19:38:52.203224Z","shell.execute_reply":"2022-11-29T19:38:52.496305Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model inference on Balanced Test","metadata":{}},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:38:52.502908Z","iopub.execute_input":"2022-11-29T19:38:52.505175Z","iopub.status.idle":"2022-11-29T19:42:57.829078Z","shell.execute_reply.started":"2022-11-29T19:38:52.505137Z","shell.execute_reply":"2022-11-29T19:42:57.827879Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_3 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_3 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_3 (TFOpLambda)   (None, 512, 1)       0           tf.cast_3[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_3 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_3[0][6]         \n                                                                 tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_7 (TFOpLambd (None, 1)            0           tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_6 (TFOpLambd (None, 768)          0           tf.math.multiply_3[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_3 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_7[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_3 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_6[0][0]       \n                                                                 tf.math.maximum_3[0][0]          \n__________________________________________________________________________________________________\ntf.stack_3 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_3[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_3 (TFOpLam (None, 768)          0           tf.stack_3[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_4 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_4 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_4 (TFOpLambda)   (None, 512, 1)       0           tf.cast_4[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_4 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_4[0][12]        \n                                                                 tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_9 (TFOpLambd (None, 1)            0           tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_8 (TFOpLambd (None, 768)          0           tf.math.multiply_4[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_4 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_9[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_4 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_8[0][0]       \n                                                                 tf.math.maximum_4[0][0]          \n__________________________________________________________________________________________________\ntf.stack_4 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_4[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_4 (TFOpLam (None, 768)          0           tf.stack_4[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_5 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_5 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_5 (TFOpLambda)   (None, 512, 1)       0           tf.cast_5[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_5 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_5[0][24]        \n                                                                 tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_11 (TFOpLamb (None, 1)            0           tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_10 (TFOpLamb (None, 1024)         0           tf.math.multiply_5[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_5 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_11[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_5 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_10[0][0]      \n                                                                 tf.math.maximum_5[0][0]          \n__________________________________________________________________________________________________\ntf.stack_5 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_5[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_5 (TFOpLam (None, 1024)         0           tf.stack_5[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(783, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:42:57.830692Z","iopub.execute_input":"2022-11-29T19:42:57.831069Z","iopub.status.idle":"2022-11-29T19:43:23.897350Z","shell.execute_reply.started":"2022-11-29T19:42:57.831031Z","shell.execute_reply":"2022-11-29T19:43:23.896312Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4700022558000045\n-----------------------------------\nOverall CV RMSE = 0.47232602128401374\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.46964353532430736\n-----------------------------------\nOverall CV RMSE = 0.4719438744066839\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.46938730641309495\n-----------------------------------\nOverall CV RMSE = 0.47162300162818527\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4691951347296858\n-----------------------------------\nOverall CV RMSE = 0.47135160665316295\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.898853Z","iopub.execute_input":"2022-11-29T19:43:23.899409Z","iopub.status.idle":"2022-11-29T19:43:23.905791Z","shell.execute_reply.started":"2022-11-29T19:43:23.899372Z","shell.execute_reply":"2022-11-29T19:43:23.904667Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.907647Z","iopub.execute_input":"2022-11-29T19:43:23.908055Z","iopub.status.idle":"2022-11-29T19:43:23.925710Z","shell.execute_reply.started":"2022-11-29T19:43:23.908018Z","shell.execute_reply":"2022-11-29T19:43:23.924612Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     index       text_id\n0        0  13C400DD9794\n1        1  D9BC7F4F22F0\n2        2  3E170458E9A1\n3        3  E0BFF1488787\n4        4  C50BE3C76571\n..     ...           ...\n778    778  A4A90A401002\n779    779  CA11FD3CAC43\n780    780  0BB9FAE6E27B\n781    781  ED0A8E614649\n782    782  ACA1A45EE438\n\n[783 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>13C400DD9794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D9BC7F4F22F0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3E170458E9A1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>E0BFF1488787</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>C50BE3C76571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>778</td>\n      <td>A4A90A401002</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>779</td>\n      <td>CA11FD3CAC43</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>780</td>\n      <td>0BB9FAE6E27B</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>781</td>\n      <td>ED0A8E614649</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>782</td>\n      <td>ACA1A45EE438</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.926940Z","iopub.execute_input":"2022-11-29T19:43:23.927556Z","iopub.status.idle":"2022-11-29T19:43:23.949745Z","shell.execute_reply.started":"2022-11-29T19:43:23.927513Z","shell.execute_reply":"2022-11-29T19:43:23.948699Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"     cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0    1.757025  1.790037    2.166585     1.914273  1.781655     1.946130\n1    2.702610  2.611169    2.959629     2.753312  2.462531     2.370763\n2    1.904241  1.829573    2.326083     1.954620  1.693608     2.035925\n3    2.583194  2.477424    2.640626     2.696552  2.777020     2.668506\n4    2.226696  2.125092    2.337645     2.011562  1.953099     2.063797\n..        ...       ...         ...          ...       ...          ...\n778  3.609177  3.507446    3.748541     3.751760  3.554485     3.658903\n779  3.817947  3.590100    3.737780     3.649301  3.512346     3.772147\n780  3.458492  3.569832    3.785442     3.649335  3.493684     3.614173\n781  3.763970  3.576688    3.776576     3.664949  3.421184     3.507264\n782  3.593573  3.508369    3.370538     3.575652  3.683389     3.656973\n\n[783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.757025</td>\n      <td>1.790037</td>\n      <td>2.166585</td>\n      <td>1.914273</td>\n      <td>1.781655</td>\n      <td>1.946130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.702610</td>\n      <td>2.611169</td>\n      <td>2.959629</td>\n      <td>2.753312</td>\n      <td>2.462531</td>\n      <td>2.370763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.904241</td>\n      <td>1.829573</td>\n      <td>2.326083</td>\n      <td>1.954620</td>\n      <td>1.693608</td>\n      <td>2.035925</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.583194</td>\n      <td>2.477424</td>\n      <td>2.640626</td>\n      <td>2.696552</td>\n      <td>2.777020</td>\n      <td>2.668506</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.226696</td>\n      <td>2.125092</td>\n      <td>2.337645</td>\n      <td>2.011562</td>\n      <td>1.953099</td>\n      <td>2.063797</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>3.609177</td>\n      <td>3.507446</td>\n      <td>3.748541</td>\n      <td>3.751760</td>\n      <td>3.554485</td>\n      <td>3.658903</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>3.817947</td>\n      <td>3.590100</td>\n      <td>3.737780</td>\n      <td>3.649301</td>\n      <td>3.512346</td>\n      <td>3.772147</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>3.458492</td>\n      <td>3.569832</td>\n      <td>3.785442</td>\n      <td>3.649335</td>\n      <td>3.493684</td>\n      <td>3.614173</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3.763970</td>\n      <td>3.576688</td>\n      <td>3.776576</td>\n      <td>3.664949</td>\n      <td>3.421184</td>\n      <td>3.507264</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>3.593573</td>\n      <td>3.508369</td>\n      <td>3.370538</td>\n      <td>3.575652</td>\n      <td>3.683389</td>\n      <td>3.656973</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.951088Z","iopub.execute_input":"2022-11-29T19:43:23.951660Z","iopub.status.idle":"2022-11-29T19:43:23.973761Z","shell.execute_reply.started":"2022-11-29T19:43:23.951617Z","shell.execute_reply":"2022-11-29T19:43:23.972887Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"          text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0    13C400DD9794  1.757025  1.790037    2.166585     1.914273  1.781655   \n1    D9BC7F4F22F0  2.702610  2.611169    2.959629     2.753312  2.462531   \n2    3E170458E9A1  1.904241  1.829573    2.326083     1.954620  1.693608   \n3    E0BFF1488787  2.583194  2.477424    2.640626     2.696552  2.777020   \n4    C50BE3C76571  2.226696  2.125092    2.337645     2.011562  1.953099   \n..            ...       ...       ...         ...          ...       ...   \n778  A4A90A401002  3.609177  3.507446    3.748541     3.751760  3.554485   \n779  CA11FD3CAC43  3.817947  3.590100    3.737780     3.649301  3.512346   \n780  0BB9FAE6E27B  3.458492  3.569832    3.785442     3.649335  3.493684   \n781  ED0A8E614649  3.763970  3.576688    3.776576     3.664949  3.421184   \n782  ACA1A45EE438  3.593573  3.508369    3.370538     3.575652  3.683389   \n\n     conventions  \n0       1.946130  \n1       2.370763  \n2       2.035925  \n3       2.668506  \n4       2.063797  \n..           ...  \n778     3.658903  \n779     3.772147  \n780     3.614173  \n781     3.507264  \n782     3.656973  \n\n[783 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13C400DD9794</td>\n      <td>1.757025</td>\n      <td>1.790037</td>\n      <td>2.166585</td>\n      <td>1.914273</td>\n      <td>1.781655</td>\n      <td>1.946130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D9BC7F4F22F0</td>\n      <td>2.702610</td>\n      <td>2.611169</td>\n      <td>2.959629</td>\n      <td>2.753312</td>\n      <td>2.462531</td>\n      <td>2.370763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3E170458E9A1</td>\n      <td>1.904241</td>\n      <td>1.829573</td>\n      <td>2.326083</td>\n      <td>1.954620</td>\n      <td>1.693608</td>\n      <td>2.035925</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E0BFF1488787</td>\n      <td>2.583194</td>\n      <td>2.477424</td>\n      <td>2.640626</td>\n      <td>2.696552</td>\n      <td>2.777020</td>\n      <td>2.668506</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C50BE3C76571</td>\n      <td>2.226696</td>\n      <td>2.125092</td>\n      <td>2.337645</td>\n      <td>2.011562</td>\n      <td>1.953099</td>\n      <td>2.063797</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>A4A90A401002</td>\n      <td>3.609177</td>\n      <td>3.507446</td>\n      <td>3.748541</td>\n      <td>3.751760</td>\n      <td>3.554485</td>\n      <td>3.658903</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>CA11FD3CAC43</td>\n      <td>3.817947</td>\n      <td>3.590100</td>\n      <td>3.737780</td>\n      <td>3.649301</td>\n      <td>3.512346</td>\n      <td>3.772147</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>0BB9FAE6E27B</td>\n      <td>3.458492</td>\n      <td>3.569832</td>\n      <td>3.785442</td>\n      <td>3.649335</td>\n      <td>3.493684</td>\n      <td>3.614173</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>ED0A8E614649</td>\n      <td>3.763970</td>\n      <td>3.576688</td>\n      <td>3.776576</td>\n      <td>3.664949</td>\n      <td>3.421184</td>\n      <td>3.507264</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>ACA1A45EE438</td>\n      <td>3.593573</td>\n      <td>3.508369</td>\n      <td>3.370538</td>\n      <td>3.575652</td>\n      <td>3.683389</td>\n      <td>3.656973</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running the final text dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/580data/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.975116Z","iopub.execute_input":"2022-11-29T19:43:23.976005Z","iopub.status.idle":"2022-11-29T19:43:23.986184Z","shell.execute_reply.started":"2022-11-29T19:43:23.975965Z","shell.execute_reply":"2022-11-29T19:43:23.985179Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:43:23.987755Z","iopub.execute_input":"2022-11-29T19:43:23.988574Z","iopub.status.idle":"2022-11-29T19:44:04.126898Z","shell.execute_reply.started":"2022-11-29T19:43:23.988533Z","shell.execute_reply":"2022-11-29T19:44:04.125845Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_6 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_6 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_6 (TFOpLambda)   (None, 512, 1)       0           tf.cast_6[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_6 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_6[0][6]         \n                                                                 tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_13 (TFOpLamb (None, 1)            0           tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_12 (TFOpLamb (None, 768)          0           tf.math.multiply_6[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_6 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_13[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_6 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_12[0][0]      \n                                                                 tf.math.maximum_6[0][0]          \n__________________________________________________________________________________________________\ntf.stack_6 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_6[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_6 (TFOpLam (None, 768)          0           tf.stack_6[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_7 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_7 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_7 (TFOpLambda)   (None, 512, 1)       0           tf.cast_7[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_7 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_7[0][12]        \n                                                                 tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_15 (TFOpLamb (None, 1)            0           tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_14 (TFOpLamb (None, 768)          0           tf.math.multiply_7[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_7 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_15[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_7 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_14[0][0]      \n                                                                 tf.math.maximum_7[0][0]          \n__________________________________________________________________________________________________\ntf.stack_7 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_7[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_7 (TFOpLam (None, 768)          0           tf.stack_7[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_8 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_8 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_8 (TFOpLambda)   (None, 512, 1)       0           tf.cast_8[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_8 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_8[0][24]        \n                                                                 tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_17 (TFOpLamb (None, 1)            0           tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_16 (TFOpLamb (None, 1024)         0           tf.math.multiply_8[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_8 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_17[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_8 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_16[0][0]      \n                                                                 tf.math.maximum_8[0][0]          \n__________________________________________________________________________________________________\ntf.stack_8 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_8[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_8 (TFOpLam (None, 1024)         0           tf.stack_8[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(9, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:04.128620Z","iopub.execute_input":"2022-11-29T19:44:04.129022Z","iopub.status.idle":"2022-11-29T19:44:05.681822Z","shell.execute_reply.started":"2022-11-29T19:44:04.128985Z","shell.execute_reply":"2022-11-29T19:44:05.680938Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.46904566786481194\n-----------------------------------\nOverall CV RMSE = 0.47111962335338303\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.4689260943729129\n-----------------------------------\nOverall CV RMSE = 0.47091918460742155\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.46882826151590457\n-----------------------------------\nOverall CV RMSE = 0.4707442564181114\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4687467341350643\n-----------------------------------\nOverall CV RMSE = 0.47059020197937707\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.685791Z","iopub.execute_input":"2022-11-29T19:44:05.689129Z","iopub.status.idle":"2022-11-29T19:44:05.695388Z","shell.execute_reply.started":"2022-11-29T19:44:05.689090Z","shell.execute_reply":"2022-11-29T19:44:05.694433Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.700230Z","iopub.execute_input":"2022-11-29T19:44:05.703024Z","iopub.status.idle":"2022-11-29T19:44:05.726103Z","shell.execute_reply.started":"2022-11-29T19:44:05.702984Z","shell.execute_reply":"2022-11-29T19:44:05.725237Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0  2.840911  2.716250    3.037664     2.856221  2.540590     2.583989\n1  2.744732  2.476981    2.774138     2.407288  2.102781     2.669146\n2  3.472254  3.367005    3.558123     3.524231  3.355400     3.321952\n3  3.246589  3.264534    3.410289     3.413712  3.406351     3.031958\n4  3.672172  3.708660    3.836535     3.743696  3.628289     3.393414\n5  3.765863  3.688655    3.988489     3.757362  3.638810     3.515132\n6  3.478005  3.458483    3.726720     3.631066  3.503116     3.092378\n7  2.686096  2.695479    3.032674     2.900893  2.784126     2.272331\n8  3.545924  3.507163    3.782055     3.673344  3.547880     3.233479","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.840911</td>\n      <td>2.716250</td>\n      <td>3.037664</td>\n      <td>2.856221</td>\n      <td>2.540590</td>\n      <td>2.583989</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.744732</td>\n      <td>2.476981</td>\n      <td>2.774138</td>\n      <td>2.407288</td>\n      <td>2.102781</td>\n      <td>2.669146</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.472254</td>\n      <td>3.367005</td>\n      <td>3.558123</td>\n      <td>3.524231</td>\n      <td>3.355400</td>\n      <td>3.321952</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.246589</td>\n      <td>3.264534</td>\n      <td>3.410289</td>\n      <td>3.413712</td>\n      <td>3.406351</td>\n      <td>3.031958</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.672172</td>\n      <td>3.708660</td>\n      <td>3.836535</td>\n      <td>3.743696</td>\n      <td>3.628289</td>\n      <td>3.393414</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.765863</td>\n      <td>3.688655</td>\n      <td>3.988489</td>\n      <td>3.757362</td>\n      <td>3.638810</td>\n      <td>3.515132</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.478005</td>\n      <td>3.458483</td>\n      <td>3.726720</td>\n      <td>3.631066</td>\n      <td>3.503116</td>\n      <td>3.092378</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.686096</td>\n      <td>2.695479</td>\n      <td>3.032674</td>\n      <td>2.900893</td>\n      <td>2.784126</td>\n      <td>2.272331</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.545924</td>\n      <td>3.507163</td>\n      <td>3.782055</td>\n      <td>3.673344</td>\n      <td>3.547880</td>\n      <td>3.233479</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.730412Z","iopub.execute_input":"2022-11-29T19:44:05.732787Z","iopub.status.idle":"2022-11-29T19:44:05.749471Z","shell.execute_reply.started":"2022-11-29T19:44:05.732740Z","shell.execute_reply":"2022-11-29T19:44:05.748572Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   index       text_id\n0      0  0000C359D63E\n1      1  000BAD50D026\n2      2  00367BB2546B\n3      3            hp\n4      4           tkm\n5      5            va\n6      6            ll\n7      7            sp\n8      8            bp","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0000C359D63E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000BAD50D026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>00367BB2546B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>hp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>tkm</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>va</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>ll</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>sp</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>bp</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.754076Z","iopub.execute_input":"2022-11-29T19:44:05.756405Z","iopub.status.idle":"2022-11-29T19:44:05.781933Z","shell.execute_reply.started":"2022-11-29T19:44:05.756366Z","shell.execute_reply":"2022-11-29T19:44:05.781084Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.840911  2.716250    3.037664     2.856221  2.540590   \n1  000BAD50D026  2.744732  2.476981    2.774138     2.407288  2.102781   \n2  00367BB2546B  3.472254  3.367005    3.558123     3.524231  3.355400   \n3            hp  3.246589  3.264534    3.410289     3.413712  3.406351   \n4           tkm  3.672172  3.708660    3.836535     3.743696  3.628289   \n5            va  3.765863  3.688655    3.988489     3.757362  3.638810   \n6            ll  3.478005  3.458483    3.726720     3.631066  3.503116   \n7            sp  2.686096  2.695479    3.032674     2.900893  2.784126   \n8            bp  3.545924  3.507163    3.782055     3.673344  3.547880   \n\n   conventions  \n0     2.583989  \n1     2.669146  \n2     3.321952  \n3     3.031958  \n4     3.393414  \n5     3.515132  \n6     3.092378  \n7     2.272331  \n8     3.233479  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.840911</td>\n      <td>2.716250</td>\n      <td>3.037664</td>\n      <td>2.856221</td>\n      <td>2.540590</td>\n      <td>2.583989</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.744732</td>\n      <td>2.476981</td>\n      <td>2.774138</td>\n      <td>2.407288</td>\n      <td>2.102781</td>\n      <td>2.669146</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.472254</td>\n      <td>3.367005</td>\n      <td>3.558123</td>\n      <td>3.524231</td>\n      <td>3.355400</td>\n      <td>3.321952</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp</td>\n      <td>3.246589</td>\n      <td>3.264534</td>\n      <td>3.410289</td>\n      <td>3.413712</td>\n      <td>3.406351</td>\n      <td>3.031958</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tkm</td>\n      <td>3.672172</td>\n      <td>3.708660</td>\n      <td>3.836535</td>\n      <td>3.743696</td>\n      <td>3.628289</td>\n      <td>3.393414</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>va</td>\n      <td>3.765863</td>\n      <td>3.688655</td>\n      <td>3.988489</td>\n      <td>3.757362</td>\n      <td>3.638810</td>\n      <td>3.515132</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ll</td>\n      <td>3.478005</td>\n      <td>3.458483</td>\n      <td>3.726720</td>\n      <td>3.631066</td>\n      <td>3.503116</td>\n      <td>3.092378</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sp</td>\n      <td>2.686096</td>\n      <td>2.695479</td>\n      <td>3.032674</td>\n      <td>2.900893</td>\n      <td>2.784126</td>\n      <td>2.272331</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>bp</td>\n      <td>3.545924</td>\n      <td>3.507163</td>\n      <td>3.782055</td>\n      <td>3.673344</td>\n      <td>3.547880</td>\n      <td>3.233479</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running SVR after TF-IDF","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error as mse\nimport math\nfrom sklearn.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.786269Z","iopub.execute_input":"2022-11-29T19:44:05.788588Z","iopub.status.idle":"2022-11-29T19:44:05.855116Z","shell.execute_reply.started":"2022-11-29T19:44:05.788551Z","shell.execute_reply":"2022-11-29T19:44:05.853089Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Running for the train full_text with training all\n# fit the six test as test\nfull_df = np.concatenate((train.full_text.values,test.full_text.values))","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.860294Z","iopub.execute_input":"2022-11-29T19:44:05.864502Z","iopub.status.idle":"2022-11-29T19:44:05.875549Z","shell.execute_reply.started":"2022-11-29T19:44:05.864449Z","shell.execute_reply":"2022-11-29T19:44:05.873212Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tfidf_featurizer = TfidfVectorizer(max_features=10000, max_df=0.95, stop_words='english')\nX_tfidf = tfidf_featurizer.fit_transform(full_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:05.882777Z","iopub.execute_input":"2022-11-29T19:44:05.885316Z","iopub.status.idle":"2022-11-29T19:44:07.101681Z","shell.execute_reply.started":"2022-11-29T19:44:05.885275Z","shell.execute_reply":"2022-11-29T19:44:07.100528Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# SPLIT DATA\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf[0:len(train.full_text)], \n                                                    train[tgtCols].values,\n                                                    test_size=0.10,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.103252Z","iopub.execute_input":"2022-11-29T19:44:07.103662Z","iopub.status.idle":"2022-11-29T19:44:07.117273Z","shell.execute_reply.started":"2022-11-29T19:44:07.103627Z","shell.execute_reply":"2022-11-29T19:44:07.116083Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.118735Z","iopub.execute_input":"2022-11-29T19:44:07.119920Z","iopub.status.idle":"2022-11-29T19:44:07.127752Z","shell.execute_reply.started":"2022-11-29T19:44:07.119854Z","shell.execute_reply":"2022-11-29T19:44:07.126111Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"(3519, 10000)\n(392, 10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = {'C' : 10, \n                'epsilon': 0.1, \n                'gamma' : 1, \n                'kernel' : 'rbf'} ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.129740Z","iopub.execute_input":"2022-11-29T19:44:07.130208Z","iopub.status.idle":"2022-11-29T19:44:07.139261Z","shell.execute_reply.started":"2022-11-29T19:44:07.130172Z","shell.execute_reply":"2022-11-29T19:44:07.138146Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"data_test = X_tfidf[len(train.full_text):]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.147234Z","iopub.execute_input":"2022-11-29T19:44:07.147538Z","iopub.status.idle":"2022-11-29T19:44:07.153061Z","shell.execute_reply.started":"2022-11-29T19:44:07.147511Z","shell.execute_reply":"2022-11-29T19:44:07.151914Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#  \ndf_sum = pd.DataFrame([],index=test.text_id,columns= tgtCols)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.154849Z","iopub.execute_input":"2022-11-29T19:44:07.155615Z","iopub.status.idle":"2022-11-29T19:44:07.166726Z","shell.execute_reply.started":"2022-11-29T19:44:07.155574Z","shell.execute_reply":"2022-11-29T19:44:07.165476Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nrerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(X_test)\n  rerror.append(mse(rf_preds,y_test[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:44:07.168950Z","iopub.execute_input":"2022-11-29T19:44:07.169210Z","iopub.status.idle":"2022-11-29T19:45:09.031109Z","shell.execute_reply.started":"2022-11-29T19:44:07.169180Z","shell.execute_reply":"2022-11-29T19:45:09.029942Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.5654853110480436\n","output_type":"stream"}]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(data_test)\n  df_sum[tgtCols[k]] = rf_preds\n  #error.append(rmse(rf_preds,y_test[:,k],squared=False))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:45:09.032776Z","iopub.execute_input":"2022-11-29T19:45:09.035989Z","iopub.status.idle":"2022-11-29T19:46:04.701408Z","shell.execute_reply.started":"2022-11-29T19:45:09.035955Z","shell.execute_reply":"2022-11-29T19:46:04.700338Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:46:04.702975Z","iopub.execute_input":"2022-11-29T19:46:04.703373Z","iopub.status.idle":"2022-11-29T19:46:04.718628Z","shell.execute_reply.started":"2022-11-29T19:46:04.703334Z","shell.execute_reply":"2022-11-29T19:46:04.717546Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"              cohesion    syntax  vocabulary  phraseology   grammar  \\\ntext_id                                                               \n0000C359D63E  2.967977  2.773655    3.210765     3.110463  2.710440   \n000BAD50D026  2.908865  2.679607    2.817291     2.551884  2.621549   \n00367BB2546B  3.435750  3.411267    3.438713     3.386686  3.252860   \nhp            2.729530  2.716837    2.994042     2.892987  2.854199   \ntkm           2.780051  2.752230    2.979500     2.858091  2.872748   \nva            3.154571  2.945274    3.357305     3.105340  3.125917   \nll            2.928077  2.932519    3.097674     3.000523  3.062610   \nsp            2.751722  2.764752    2.977407     2.968264  3.007767   \nbp            2.819413  2.752877    3.063796     2.971408  2.916289   \n\n              conventions  \ntext_id                    \n0000C359D63E     2.820650  \n000BAD50D026     2.954843  \n00367BB2546B     3.301567  \nhp               2.753378  \ntkm              2.742716  \nva               3.014998  \nll               2.868429  \nsp               2.724754  \nbp               2.870069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n    <tr>\n      <th>text_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000C359D63E</th>\n      <td>2.967977</td>\n      <td>2.773655</td>\n      <td>3.210765</td>\n      <td>3.110463</td>\n      <td>2.710440</td>\n      <td>2.820650</td>\n    </tr>\n    <tr>\n      <th>000BAD50D026</th>\n      <td>2.908865</td>\n      <td>2.679607</td>\n      <td>2.817291</td>\n      <td>2.551884</td>\n      <td>2.621549</td>\n      <td>2.954843</td>\n    </tr>\n    <tr>\n      <th>00367BB2546B</th>\n      <td>3.435750</td>\n      <td>3.411267</td>\n      <td>3.438713</td>\n      <td>3.386686</td>\n      <td>3.252860</td>\n      <td>3.301567</td>\n    </tr>\n    <tr>\n      <th>hp</th>\n      <td>2.729530</td>\n      <td>2.716837</td>\n      <td>2.994042</td>\n      <td>2.892987</td>\n      <td>2.854199</td>\n      <td>2.753378</td>\n    </tr>\n    <tr>\n      <th>tkm</th>\n      <td>2.780051</td>\n      <td>2.752230</td>\n      <td>2.979500</td>\n      <td>2.858091</td>\n      <td>2.872748</td>\n      <td>2.742716</td>\n    </tr>\n    <tr>\n      <th>va</th>\n      <td>3.154571</td>\n      <td>2.945274</td>\n      <td>3.357305</td>\n      <td>3.105340</td>\n      <td>3.125917</td>\n      <td>3.014998</td>\n    </tr>\n    <tr>\n      <th>ll</th>\n      <td>2.928077</td>\n      <td>2.932519</td>\n      <td>3.097674</td>\n      <td>3.000523</td>\n      <td>3.062610</td>\n      <td>2.868429</td>\n    </tr>\n    <tr>\n      <th>sp</th>\n      <td>2.751722</td>\n      <td>2.764752</td>\n      <td>2.977407</td>\n      <td>2.968264</td>\n      <td>3.007767</td>\n      <td>2.724754</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>2.819413</td>\n      <td>2.752877</td>\n      <td>3.063796</td>\n      <td>2.971408</td>\n      <td>2.916289</td>\n      <td>2.870069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}