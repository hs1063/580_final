{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pretrained embeddings inference\n\nIn my experiments, I have extracted embeddings from publicly available NLP transformer models and implemented a hill climbing approach to finding the best combination of all the extracted embeddings. This is explored in the notebooks below\n\nStep 1: Extract embeddings (https://www.kaggle.com/code/illidan7/fb3-save-pretrained-embeddings/notebook)\n\nStep 2: Hill Climb (https://www.kaggle.com/illidan7/fb3-hill-climb-pretrained-embeddings/edit)\n\nStep 3: Submission (You are here)\n\nI have taken one of the combinations found in the Hill Climb process (debertav3large + distilrobertabase) and implemented it here.\n\n\n_____\n\nReferences:\n\n- https://www.kaggle.com/code/cdeotte/rapids-svr-cv-0-450-lb-0-44x\n- https://www.kaggle.com/competitions/petfinder-pawpularity-score/discussion/301686\n- https://www.kaggle.com/code/electro/deberta-layerwiselr-lastlayerreinit-tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DataCollatorWithPadding\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nfrom datasets import Dataset\n\nimport os\nimport gc\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:39:52.065214Z","iopub.execute_input":"2022-11-28T21:39:52.065672Z","iopub.status.idle":"2022-11-28T21:40:01.047710Z","shell.execute_reply.started":"2022-11-28T21:39:52.065596Z","shell.execute_reply":"2022-11-28T21:40:01.046765Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n        'folds': 5,\n        'seed': 101,\n        \n        # Kaggle embeds\n        'debertav3large_npy': '../input/fb3-save-pretrained-embeddings/debertav3large_FB3.npy',\n        'distilrobertabase_npy': '../input/fb3-save-pretrained-embeddings/distilrobertabase_FB3.npy',\n        \n        'debertav3large': '../input/deberta-v3-large/deberta-v3-large/',\n        'distilrobertabase': '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base',\n\n        'batch_size': 4,\n        'max_len': 512\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.049664Z","iopub.execute_input":"2022-11-28T21:40:01.050356Z","iopub.status.idle":"2022-11-28T21:40:01.059389Z","shell.execute_reply.started":"2022-11-28T21:40:01.050294Z","shell.execute_reply":"2022-11-28T21:40:01.057372Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read in data","metadata":{}},{"cell_type":"code","source":"\n#df = pd.read_csv('/kaggle/input/580-final-train/new_train.csv')\n#df = df[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions',\n#           'text_length','verb','wh','connection','adb','pronoun','noun','adj','fw']]\n#df['split'] = np.random.randn(df.shape[0], 1)\n\n#msk = np.random.rand(len(df)) <= 0.7\n\n#train = df[msk]\n#test = df[~msk]\n\n#tgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions',\n#           'text_length','verb','wh','connection','adb','pronoun','noun','adj','fw']\n#print(train.shape)\n#print(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.060863Z","iopub.execute_input":"2022-11-28T21:40:01.061555Z","iopub.status.idle":"2022-11-28T21:40:01.080763Z","shell.execute_reply.started":"2022-11-28T21:40:01.061510Z","shell.execute_reply":"2022-11-28T21:40:01.079800Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\nmsk = np.random.rand(len(df)) <= 0.7\n\ntrain = df[msk]\ntest = df[~msk]\n#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")\n\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.084328Z","iopub.execute_input":"2022-11-28T21:40:01.084596Z","iopub.status.idle":"2022-11-28T21:40:01.326147Z","shell.execute_reply.started":"2022-11-28T21:40:01.084573Z","shell.execute_reply":"2022-11-28T21:40:01.325067Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(2711, 8)\n(1200, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.328294Z","iopub.execute_input":"2022-11-28T21:40:01.328902Z","iopub.status.idle":"2022-11-28T21:40:01.355865Z","shell.execute_reply.started":"2022-11-28T21:40:01.328866Z","shell.execute_reply":"2022-11-28T21:40:01.354834Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     0016926B079C  I think that students would benefit from learn...   \n6     005661280443  Imagine if you could prove other people that y...   \n8     009BCCC61C2A  positive attitude is the key to success. I agr...   \n9     009F4E9310CB  Asking more than one person for and advice hel...   \n11    00BCADB373EF  A positive attitude is the key to success for ...   \n...            ...                                                ...   \n3897  FF8BAC351714  I disagree with the students attend classes fo...   \n3899  FF9469424ED0  All schools have different educational activit...   \n3901  FF9E0379CD98  Some school offer distence learning as a optio...   \n3906  FFD29828A873  I believe using cellphones in class for educat...   \n3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n0          3.5     3.5         3.0          3.0      4.0          3.0  \n6          3.5     4.0         3.5          3.5      4.0          4.0  \n8          3.0     3.0         3.5          3.5      3.0          3.0  \n9          3.0     3.0         3.5          2.5      3.0          2.5  \n11         3.5     3.0         4.0          3.5      3.0          3.0  \n...        ...     ...         ...          ...      ...          ...  \n3897       2.5     2.0         3.0          3.0      2.0          2.5  \n3899       3.5     3.5         4.5          3.5      4.0          4.0  \n3901       3.5     2.5         3.0          3.0      2.0          2.5  \n3906       2.5     3.0         3.0          3.5      2.5          2.5  \n3908       2.5     3.0         3.0          3.0      3.5          3.0  \n\n[1200 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>005661280443</td>\n      <td>Imagine if you could prove other people that y...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>009BCCC61C2A</td>\n      <td>positive attitude is the key to success. I agr...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>009F4E9310CB</td>\n      <td>Asking more than one person for and advice hel...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00BCADB373EF</td>\n      <td>A positive attitude is the key to success for ...</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3897</th>\n      <td>FF8BAC351714</td>\n      <td>I disagree with the students attend classes fo...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3899</th>\n      <td>FF9469424ED0</td>\n      <td>All schools have different educational activit...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3901</th>\n      <td>FF9E0379CD98</td>\n      <td>Some school offer distence learning as a optio...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FFD29828A873</td>\n      <td>I believe using cellphones in class for educat...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>FFDC4011AC9C</td>\n      <td>\"A problem is a chance for you to do your best...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"my_list = df.columns.values.tolist()\nmy_list","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.357359Z","iopub.execute_input":"2022-11-28T21:40:01.357704Z","iopub.status.idle":"2022-11-28T21:40:01.364245Z","shell.execute_reply.started":"2022-11-28T21:40:01.357669Z","shell.execute_reply":"2022-11-28T21:40:01.363295Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['text_id',\n 'full_text',\n 'cohesion',\n 'syntax',\n 'vocabulary',\n 'phraseology',\n 'grammar',\n 'conventions']"},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.365813Z","iopub.execute_input":"2022-11-28T21:40:01.366431Z","iopub.status.idle":"2022-11-28T21:40:01.387351Z","shell.execute_reply.started":"2022-11-28T21:40:01.366371Z","shell.execute_reply":"2022-11-28T21:40:01.386288Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n1     0022683E9EA5  When a problem is a change you have to let it ...   \n2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n3     003885A45F42  The best time in life is when you become yours...   \n4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n5     004AC288D833  Dear Principal,\\r\\n\\r\\nOur school should have ...   \n...            ...                                                ...   \n3904  FFAEAF8D0C90  Soccer, all people like to play soccer, and ot...   \n3905  FFCDB2524616  I agree with Ralph Waldo Emerson's \"\\n\\nTo be ...   \n3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n1          2.5     2.5         3.0          2.0      2.0          2.5  \n2          3.0     3.5         3.0          3.0      3.0          2.5  \n3          4.5     4.5         4.5          4.5      4.0          5.0  \n4          2.5     3.0         3.0          3.0      2.5          2.5  \n5          3.5     4.0         4.0          3.5      3.5          4.0  \n...        ...     ...         ...          ...      ...          ...  \n3904       2.5     2.0         2.5          1.5      2.0          2.0  \n3905       2.5     3.0         3.0          4.0      3.5          3.0  \n3907       4.0     4.0         4.0          4.0      3.5          3.0  \n3909       4.0     4.5         4.5          4.0      4.5          4.5  \n3910       3.5     2.5         3.5          3.0      3.0          3.5  \n\n[2711 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>004AC288D833</td>\n      <td>Dear Principal,\\r\\n\\r\\nOur school should have ...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3904</th>\n      <td>FFAEAF8D0C90</td>\n      <td>Soccer, all people like to play soccer, and ot...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3905</th>\n      <td>FFCDB2524616</td>\n      <td>I agree with Ralph Waldo Emerson's \"\\n\\nTo be ...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>FFD9A83B0849</td>\n      <td>Working alone, students do not have to argue w...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>FFE16D704B16</td>\n      <td>Many people disagree with Albert Schweitzer's ...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>FFED00D6E0BD</td>\n      <td>Do you think that failure is the main thing fo...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>2711 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create folds","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'kfold'] = -1 # Create a new column `fold` containing `-1`s.\ntrain = train.sample(frac=1).reset_index(drop=True) # Shuffle the rows.\ndata_labels = train[tgtCols].values","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.389085Z","iopub.execute_input":"2022-11-28T21:40:01.389502Z","iopub.status.idle":"2022-11-28T21:40:01.405114Z","shell.execute_reply.started":"2022-11-28T21:40:01.389467Z","shell.execute_reply":"2022-11-28T21:40:01.404133Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.obj[key] = value\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.406626Z","iopub.execute_input":"2022-11-28T21:40:01.407662Z","iopub.status.idle":"2022-11-28T21:40:01.433738Z","shell.execute_reply.started":"2022-11-28T21:40:01.407628Z","shell.execute_reply":"2022-11-28T21:40:01.432865Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor fold_, (train_, valid_) in enumerate(mskf.split(X=train, y=data_labels)):\n    train.loc[valid_, 'kfold'] = fold_ + 1","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.438372Z","iopub.execute_input":"2022-11-28T21:40:01.439164Z","iopub.status.idle":"2022-11-28T21:40:01.530371Z","shell.execute_reply.started":"2022-11-28T21:40:01.439132Z","shell.execute_reply":"2022-11-28T21:40:01.529120Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.531838Z","iopub.execute_input":"2022-11-28T21:40:01.532542Z","iopub.status.idle":"2022-11-28T21:40:01.567240Z","shell.execute_reply.started":"2022-11-28T21:40:01.532494Z","shell.execute_reply":"2022-11-28T21:40:01.566269Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     06C9FC1267BB  Do people accomplish more if they are always d...   \n1     77D210B9EC7E  Students will benefit from being able to do th...   \n2     51CE1DCC5307  Some people might have heard this before, \"The...   \n3     9725E454418F  Inteoduction, I planned my paper befoer writin...   \n4     6F0330A6C504  This shows how students could think and have t...   \n...            ...                                                ...   \n2706  221BA383246D  The job I want to pursue is to play in a profe...   \n2707  EDDAE2D4080B  first i did think about in then i writer on pa...   \n2708  E8795A1AA404  When making life decisions it is good to ask s...   \n2709  EB1500B8EA75  Some students who live far away from their sch...   \n2710  CA42D47C0914  Would you like to act like someone else when y...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  kfold  \n0          3.5     3.0         3.5          3.0      3.0          3.0      3  \n1          3.5     3.5         2.5          3.5      3.0          3.0      4  \n2          4.0     4.0         4.0          4.0      3.5          3.5      2  \n3          2.0     2.0         2.0          2.0      2.0          2.5      5  \n4          3.0     3.5         4.0          4.0      3.5          3.5      1  \n...        ...     ...         ...          ...      ...          ...    ...  \n2706       4.5     3.0         3.5          3.5      3.5          4.0      2  \n2707       1.5     1.0         2.0          1.5      2.0          1.5      3  \n2708       3.0     2.5         3.5          3.5      3.0          3.5      1  \n2709       2.5     2.0         3.0          3.0      2.0          2.0      5  \n2710       3.5     3.5         3.5          4.0      3.5          3.0      5  \n\n[2711 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>06C9FC1267BB</td>\n      <td>Do people accomplish more if they are always d...</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>77D210B9EC7E</td>\n      <td>Students will benefit from being able to do th...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51CE1DCC5307</td>\n      <td>Some people might have heard this before, \"The...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9725E454418F</td>\n      <td>Inteoduction, I planned my paper befoer writin...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6F0330A6C504</td>\n      <td>This shows how students could think and have t...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2706</th>\n      <td>221BA383246D</td>\n      <td>The job I want to pursue is to play in a profe...</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2707</th>\n      <td>EDDAE2D4080B</td>\n      <td>first i did think about in then i writer on pa...</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>1.5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2708</th>\n      <td>E8795A1AA404</td>\n      <td>When making life decisions it is good to ask s...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2709</th>\n      <td>EB1500B8EA75</td>\n      <td>Some students who live far away from their sch...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2710</th>\n      <td>CA42D47C0914</td>\n      <td>Would you like to act like someone else when y...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>2711 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['kfold'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.568646Z","iopub.execute_input":"2022-11-28T21:40:01.568956Z","iopub.status.idle":"2022-11-28T21:40:01.579446Z","shell.execute_reply.started":"2022-11-28T21:40:01.568925Z","shell.execute_reply":"2022-11-28T21:40:01.578455Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"1    542\n2    542\n3    542\n4    542\n5    543\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Custom functions","metadata":{}},{"cell_type":"markdown","source":"## Competition metric","metadata":{}},{"cell_type":"markdown","source":"## Data process functions","metadata":{}},{"cell_type":"code","source":"def hf_encode(texts, chkpt):\n    \n    tokenizer = transformers.AutoTokenizer.from_pretrained(CONFIG[chkpt])\n    tokenizer.save_pretrained('./tokenizer/')\n\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=CONFIG['max_len'], \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.581013Z","iopub.execute_input":"2022-11-28T21:40:01.581781Z","iopub.status.idle":"2022-11-28T21:40:01.589850Z","shell.execute_reply.started":"2022-11-28T21:40:01.581747Z","shell.execute_reply":"2022-11-28T21:40:01.588907Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def pickle_dump(path, saveobj):\n    import pickle\n    filehandler = open(path,\"wb\")\n    pickle.dump(saveobj,filehandler)\n#     print(\"File pickled\")\n    filehandler.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.591042Z","iopub.execute_input":"2022-11-28T21:40:01.592037Z","iopub.status.idle":"2022-11-28T21:40:01.600296Z","shell.execute_reply.started":"2022-11-28T21:40:01.592002Z","shell.execute_reply":"2022-11-28T21:40:01.599352Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def pickle_load(path):\n    import pickle\n    file = open(path,'rb')\n    loadobj = pickle.load(file)\n    file.close()\n    return loadobj","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.601712Z","iopub.execute_input":"2022-11-28T21:40:01.602135Z","iopub.status.idle":"2022-11-28T21:40:01.612592Z","shell.execute_reply.started":"2022-11-28T21:40:01.602102Z","shell.execute_reply":"2022-11-28T21:40:01.611632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Transformer embeddings","metadata":{}},{"cell_type":"code","source":"\"\"\"\nclass MeanPool(tf.keras.layers.Layer):\n    def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        return embedding_sum / mask_sum\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.614079Z","iopub.execute_input":"2022-11-28T21:40:01.614527Z","iopub.status.idle":"2022-11-28T21:40:01.628958Z","shell.execute_reply.started":"2022-11-28T21:40:01.614491Z","shell.execute_reply":"2022-11-28T21:40:01.628105Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\nclass MeanPool(tf.keras.layers.Layer):\\n    def call(self, inputs, mask=None):\\n        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\\n        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\\n        return embedding_sum / mask_sum\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def pretrain_embeddings(chkpt, df):\n    cfg = transformers.AutoConfig.from_pretrained(CONFIG[chkpt], output_hidden_states=True)\n    cfg.hidden_dropout_prob = 0\n    cfg.attention_probs_dropout_prob = 0\n    cfg.save_pretrained('./tokenizer/')\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"attention_masks\"\n    )\n    \n    try:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg)\n    except:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg, from_pt=True)\n        \n    output = model(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = output.hidden_states\n    mean_pool = []\n    for hidden_s in hidden_states[-1:]:\n        #def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(attention_masks, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(hidden_s * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        tmp = embedding_sum / mask_sum\n        mean_pool.append(tmp)\n    output = tf.stack(mean_pool,axis=2)\n   \n    #output = tf.stack(\n    #    [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidden_states[-1:]], \n    #    axis=2)\n    \n    output = tf.squeeze(output, axis=-1)\n    \n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n\n    model.compile(optimizer=\"adam\",\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    print(model.summary())\n    dataset = hf_encode(df['full_text'], chkpt)\n    preds = model.predict(dataset, batch_size=CONFIG['batch_size'])\n    \n    del model, dataset\n    _ = gc.collect()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.632136Z","iopub.execute_input":"2022-11-28T21:40:01.632421Z","iopub.status.idle":"2022-11-28T21:40:01.644466Z","shell.execute_reply.started":"2022-11-28T21:40:01.632393Z","shell.execute_reply":"2022-11-28T21:40:01.643577Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"train_dataset = np.load(CONFIG['debertav3large_npy'])\ntrain_dataset = np.concatenate([train_dataset, np.load(CONFIG['distilrobertabase_npy'])], axis=1)\n\ntrain_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.645959Z","iopub.execute_input":"2022-11-28T21:40:01.646844Z","iopub.status.idle":"2022-11-28T21:40:01.950049Z","shell.execute_reply.started":"2022-11-28T21:40:01.646809Z","shell.execute_reply":"2022-11-28T21:40:01.949039Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3911, 1792)"},"metadata":{}}]},{"cell_type":"code","source":"scores = []\nrmse_scores = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('#'*25)\n    print(f'## Fold {fold}')\n    print('#'*25)\n\n    trn_idx = train[train['kfold']!=fold].index.values\n    val_idx = train[train['kfold']==fold].index.values\n\n    X_train = train_dataset[trn_idx,:]\n    X_valid = train_dataset[val_idx,:]\n\n    y_train = train[train['kfold']!=fold][tgtCols].copy()\n    y_valid = train[train['kfold']==fold][tgtCols].copy()\n\n    val_preds = np.zeros((len(val_idx),6))\n\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        clf = SVR(C=1)\n        clf.fit(X_train, y_train[tgt].values)\n        pickle_dump(f\"./SVR_tgt{tgt}_fold{fold}.pkl\", clf)\n        val_preds[:,i] = clf.predict(X_valid)\n   \n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('#'*25)\n    print('Overall CV RMSE =',np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:40:01.952357Z","iopub.execute_input":"2022-11-28T21:40:01.953032Z","iopub.status.idle":"2022-11-28T21:41:42.401486Z","shell.execute_reply.started":"2022-11-28T21:40:01.952991Z","shell.execute_reply":"2022-11-28T21:41:42.400374Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"#########################\n## Fold 1\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.6566137647188007\n#########################\nOverall CV RMSE = 0.656107845037741\n#########################\n## Fold 2\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.6779639445043969\n#########################\nOverall CV RMSE = 0.6630906569204559\n#########################\n## Fold 3\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.6647338592916149\n#########################\nOverall CV RMSE = 0.6646033469011701\n#########################\n## Fold 4\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.660425160143737\n#########################\nOverall CV RMSE = 0.6634618713166004\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_dataset\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:41:42.403086Z","iopub.execute_input":"2022-11-28T21:41:42.403466Z","iopub.status.idle":"2022-11-28T21:41:42.587471Z","shell.execute_reply.started":"2022-11-28T21:41:42.403429Z","shell.execute_reply":"2022-11-28T21:41:42.586297Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model inference","metadata":{}},{"cell_type":"code","source":"#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:41:42.588927Z","iopub.execute_input":"2022-11-28T21:41:42.593705Z","iopub.status.idle":"2022-11-28T21:41:42.597710Z","shell.execute_reply.started":"2022-11-28T21:41:42.593674Z","shell.execute_reply":"2022-11-28T21:41:42.596840Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_dataset = pretrain_embeddings('debertav3large', test)\ntest_dataset = np.concatenate([test_dataset, pretrain_embeddings('distilrobertabase', test)], axis=1)\n\ntest_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:41:42.599370Z","iopub.execute_input":"2022-11-28T21:41:42.599892Z","iopub.status.idle":"2022-11-28T21:45:26.057343Z","shell.execute_reply.started":"2022-11-28T21:41:42.599849Z","shell.execute_reply":"2022-11-28T21:45:26.056262Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-11-28 21:41:42.768811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:42.769926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:42.770638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:42.771505: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-28 21:41:42.771786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:42.772483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:42.773108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:47.145753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:47.146622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:47.147260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-28 21:41:47.147875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast (TFOpLambda)            (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_deberta_v2_model (TFDebertaV TFBaseModelOutput(la 434012160   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 512, 1)       0           tf.cast[0][0]                    \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 512, 1024)    0           tf_deberta_v2_model[0][24]       \n                                                                 tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 1024)         0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\ntf.math.maximum (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv (TFOpLambda)    (None, 1024)         0           tf.math.reduce_sum[0][0]         \n                                                                 tf.math.maximum[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 1024, 1)      0           tf.math.truediv[0][0]            \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 1024)         0           tf.stack[0][0]                   \n==================================================================================================\nTotal params: 434,012,160\nTrainable params: 434,012,160\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n2022-11-28 21:42:23.816500: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_1 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 512, 1)       0           tf.cast_1[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_1 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model[0][6]           \n                                                                 tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_2 (TFOpLambd (None, 768)          0           tf.math.multiply_1[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_1 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_1 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_2[0][0]       \n                                                                 tf.math.maximum_1[0][0]          \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_1[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_1 (TFOpLam (None, 768)          0           tf.stack_1[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(1200, 1792)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('#'*25)\n    print(f'## Fold {fold}')\n    print('#'*25)\n    \n    test_preds = np.zeros((len(test_dataset),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_dataset)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('#'*25)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:45:26.059184Z","iopub.execute_input":"2022-11-28T21:45:26.060591Z","iopub.status.idle":"2022-11-28T21:46:37.299073Z","shell.execute_reply.started":"2022-11-28T21:45:26.060549Z","shell.execute_reply":"2022-11-28T21:46:37.298021Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"#########################\n## Fold 1\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.6578399406550103\n#########################\nOverall CV RMSE = 0.6622252104589444\n#########################\n## Fold 2\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.656116460995859\n#########################\nOverall CV RMSE = 0.6611072815790241\n#########################\n## Fold 3\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.6548854040964652\n#########################\nOverall CV RMSE = 0.6601341263026252\n#########################\n## Fold 4\n#########################\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.65396211142192\n#########################\nOverall CV RMSE = 0.6592919441217241\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:46:37.300434Z","iopub.execute_input":"2022-11-28T21:46:37.301085Z","iopub.status.idle":"2022-11-28T21:46:37.307433Z","shell.execute_reply.started":"2022-11-28T21:46:37.301046Z","shell.execute_reply":"2022-11-28T21:46:37.306279Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:46:37.309133Z","iopub.execute_input":"2022-11-28T21:46:37.309837Z","iopub.status.idle":"2022-11-28T21:46:37.326249Z","shell.execute_reply.started":"2022-11-28T21:46:37.309802Z","shell.execute_reply":"2022-11-28T21:46:37.325132Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"      index       text_id\n0         0  0016926B079C\n1         6  005661280443\n2         8  009BCCC61C2A\n3         9  009F4E9310CB\n4        11  00BCADB373EF\n...     ...           ...\n1195   3897  FF8BAC351714\n1196   3899  FF9469424ED0\n1197   3901  FF9E0379CD98\n1198   3906  FFD29828A873\n1199   3908  FFDC4011AC9C\n\n[1200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0016926B079C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>005661280443</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>009BCCC61C2A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>009F4E9310CB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>00BCADB373EF</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>3897</td>\n      <td>FF8BAC351714</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>3899</td>\n      <td>FF9469424ED0</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>3901</td>\n      <td>FF9E0379CD98</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>3906</td>\n      <td>FFD29828A873</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>3908</td>\n      <td>FFDC4011AC9C</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:46:37.328009Z","iopub.execute_input":"2022-11-28T21:46:37.328365Z","iopub.status.idle":"2022-11-28T21:46:37.346537Z","shell.execute_reply.started":"2022-11-28T21:46:37.328323Z","shell.execute_reply":"2022-11-28T21:46:37.345494Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"      cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0     3.150271  3.008212    3.202044     3.152295  3.031673     3.090434\n1     3.131481  3.041934    3.113607     3.091941  2.971744     3.082702\n2     3.095260  3.060563    3.120512     3.100017  3.020904     3.085684\n3     3.106777  2.971765    3.111706     3.053807  3.046731     3.065468\n4     3.114892  3.100257    3.201369     3.124506  3.112098     3.075693\n...        ...       ...         ...          ...       ...          ...\n1195  3.077533  2.927974    3.101727     3.077560  2.942753     3.068244\n1196  3.127624  3.000497    3.172509     3.117813  3.003409     3.052569\n1197  3.067304  2.965205    3.088830     3.072609  2.978793     3.086108\n1198  3.007043  2.938843    3.073669     3.046476  2.920017     3.034785\n1199  3.142611  2.996589    3.102135     3.091743  2.981188     3.050771\n\n[1200 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.150271</td>\n      <td>3.008212</td>\n      <td>3.202044</td>\n      <td>3.152295</td>\n      <td>3.031673</td>\n      <td>3.090434</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.131481</td>\n      <td>3.041934</td>\n      <td>3.113607</td>\n      <td>3.091941</td>\n      <td>2.971744</td>\n      <td>3.082702</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.095260</td>\n      <td>3.060563</td>\n      <td>3.120512</td>\n      <td>3.100017</td>\n      <td>3.020904</td>\n      <td>3.085684</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.106777</td>\n      <td>2.971765</td>\n      <td>3.111706</td>\n      <td>3.053807</td>\n      <td>3.046731</td>\n      <td>3.065468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.114892</td>\n      <td>3.100257</td>\n      <td>3.201369</td>\n      <td>3.124506</td>\n      <td>3.112098</td>\n      <td>3.075693</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>3.077533</td>\n      <td>2.927974</td>\n      <td>3.101727</td>\n      <td>3.077560</td>\n      <td>2.942753</td>\n      <td>3.068244</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>3.127624</td>\n      <td>3.000497</td>\n      <td>3.172509</td>\n      <td>3.117813</td>\n      <td>3.003409</td>\n      <td>3.052569</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>3.067304</td>\n      <td>2.965205</td>\n      <td>3.088830</td>\n      <td>3.072609</td>\n      <td>2.978793</td>\n      <td>3.086108</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>3.007043</td>\n      <td>2.938843</td>\n      <td>3.073669</td>\n      <td>3.046476</td>\n      <td>2.920017</td>\n      <td>3.034785</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>3.142611</td>\n      <td>2.996589</td>\n      <td>3.102135</td>\n      <td>3.091743</td>\n      <td>2.981188</td>\n      <td>3.050771</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T21:46:37.348052Z","iopub.execute_input":"2022-11-28T21:46:37.348762Z","iopub.status.idle":"2022-11-28T21:46:37.368900Z","shell.execute_reply.started":"2022-11-28T21:46:37.348727Z","shell.execute_reply":"2022-11-28T21:46:37.367894Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"           text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0     0016926B079C  3.150271  3.008212    3.202044     3.152295  3.031673   \n1     005661280443  3.131481  3.041934    3.113607     3.091941  2.971744   \n2     009BCCC61C2A  3.095260  3.060563    3.120512     3.100017  3.020904   \n3     009F4E9310CB  3.106777  2.971765    3.111706     3.053807  3.046731   \n4     00BCADB373EF  3.114892  3.100257    3.201369     3.124506  3.112098   \n...            ...       ...       ...         ...          ...       ...   \n1195  FF8BAC351714  3.077533  2.927974    3.101727     3.077560  2.942753   \n1196  FF9469424ED0  3.127624  3.000497    3.172509     3.117813  3.003409   \n1197  FF9E0379CD98  3.067304  2.965205    3.088830     3.072609  2.978793   \n1198  FFD29828A873  3.007043  2.938843    3.073669     3.046476  2.920017   \n1199  FFDC4011AC9C  3.142611  2.996589    3.102135     3.091743  2.981188   \n\n      conventions  \n0        3.090434  \n1        3.082702  \n2        3.085684  \n3        3.065468  \n4        3.075693  \n...           ...  \n1195     3.068244  \n1196     3.052569  \n1197     3.086108  \n1198     3.034785  \n1199     3.050771  \n\n[1200 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>3.150271</td>\n      <td>3.008212</td>\n      <td>3.202044</td>\n      <td>3.152295</td>\n      <td>3.031673</td>\n      <td>3.090434</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005661280443</td>\n      <td>3.131481</td>\n      <td>3.041934</td>\n      <td>3.113607</td>\n      <td>3.091941</td>\n      <td>2.971744</td>\n      <td>3.082702</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>009BCCC61C2A</td>\n      <td>3.095260</td>\n      <td>3.060563</td>\n      <td>3.120512</td>\n      <td>3.100017</td>\n      <td>3.020904</td>\n      <td>3.085684</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>009F4E9310CB</td>\n      <td>3.106777</td>\n      <td>2.971765</td>\n      <td>3.111706</td>\n      <td>3.053807</td>\n      <td>3.046731</td>\n      <td>3.065468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00BCADB373EF</td>\n      <td>3.114892</td>\n      <td>3.100257</td>\n      <td>3.201369</td>\n      <td>3.124506</td>\n      <td>3.112098</td>\n      <td>3.075693</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>FF8BAC351714</td>\n      <td>3.077533</td>\n      <td>2.927974</td>\n      <td>3.101727</td>\n      <td>3.077560</td>\n      <td>2.942753</td>\n      <td>3.068244</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>FF9469424ED0</td>\n      <td>3.127624</td>\n      <td>3.000497</td>\n      <td>3.172509</td>\n      <td>3.117813</td>\n      <td>3.003409</td>\n      <td>3.052569</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>FF9E0379CD98</td>\n      <td>3.067304</td>\n      <td>2.965205</td>\n      <td>3.088830</td>\n      <td>3.072609</td>\n      <td>2.978793</td>\n      <td>3.086108</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>FFD29828A873</td>\n      <td>3.007043</td>\n      <td>2.938843</td>\n      <td>3.073669</td>\n      <td>3.046476</td>\n      <td>2.920017</td>\n      <td>3.034785</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>FFDC4011AC9C</td>\n      <td>3.142611</td>\n      <td>2.996589</td>\n      <td>3.102135</td>\n      <td>3.091743</td>\n      <td>2.981188</td>\n      <td>3.050771</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 7 columns</p>\n</div>"},"metadata":{}}]}]}